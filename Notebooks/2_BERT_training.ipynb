{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ddc7e02",
   "metadata": {},
   "source": [
    "<h1> Second Round of BERT Training </h1>\n",
    "\n",
    "In this round, I follow the RoBERTa implementation, which uses dynamic masking and whole-text prediction (rather than NSP). Named entity tokens in the dataset have now been replaced with their BIOES tags. I also add regularization in attempt to balance the distribution of samples across targets in the corpus.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97c8c82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "import stanza\n",
    "import spacy \n",
    "import importlib\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "from torch.optim import Adagrad\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, PretrainedConfig\n",
    "from common import ClassificationDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a7542b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = \"/Users/paulp/Library/CloudStorage/OneDrive-UniversityofEasternFinland/UEF/Thesis\"\n",
    "data_dir = os.path.join(project_dir,\"Data\")\n",
    "model_dir = os.path.join(project_dir, \"Models\")\n",
    "\n",
    "os.chdir(data_dir)\n",
    "\n",
    "old_dataset = pd.read_csv('compiled_data_set.csv', index_col = 0)\n",
    "\n",
    "#L1 to integer map for loading categories into BERT\n",
    "with open('target_idx.json') as f:\n",
    "    data = f.read()\n",
    "target_idx = json.loads(data)\n",
    "\n",
    "n_classes = len(target_idx.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9209b589",
   "metadata": {},
   "source": [
    "<h2> Create a New NE-masked Dataset </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b506dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "spec_tokens = ['<?>', '<*>', '<R>', #one of the corpora uses these\n",
    "               '<B-MISC>',\n",
    "               '<I-MISC>',\n",
    "               '<E-MISC>',\n",
    "               '<S-MISC>',\n",
    "               '<B-LOC>',\n",
    "               '<I-LOC>',\n",
    "               '<E-LOC>',\n",
    "               '<S-LOC>',\n",
    "               '<B-PER>', \n",
    "               '<I-PER>', \n",
    "               '<E-PER>', \n",
    "               '<S-PER>', \n",
    "               '<B-ORG>',\n",
    "                '<I-ORG>',\n",
    "                '<E-ORG>',\n",
    "                '<S-ORG>'] # these will mask named entities later if needed\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased', \n",
    "                                          additional_special_tokens = spec_tokens,\n",
    "                                         unk_token = '[UNK]')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8de1cc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('spec_tokens_ne.txt', 'wb') as file:\n",
    "    pickle.dump(spec_tokens, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "120bc673",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('spec_tokens_ne.txt', 'rb') as file:\n",
    "    spec_tokens = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "996ce553",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.034399986267089844,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 24,
       "postfix": null,
       "prefix": "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.4.0.json",
       "rate": null,
       "total": 25998,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09e4460e95dc4f668d680ec6fae4efd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.4.0.json:   0%|   â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-22 11:19:21 INFO: Loading these models for language: en (English):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | spacy   |\n",
      "| mwt       | ewt     |\n",
      "| pos       | ewt     |\n",
      "| lemma     | ewt     |\n",
      "| depparse  | ewt     |\n",
      "| ner       | conll03 |\n",
      "=======================\n",
      "\n",
      "2022-09-22 11:19:21 INFO: Use device: cpu\n",
      "2022-09-22 11:19:21 INFO: Loading: tokenize\n",
      "2022-09-22 11:19:22 INFO: Loading: mwt\n",
      "2022-09-22 11:19:22 INFO: Loading: pos\n",
      "2022-09-22 11:19:22 INFO: Loading: lemma\n",
      "2022-09-22 11:19:22 INFO: Loading: depparse\n",
      "2022-09-22 11:19:22 INFO: Loading: ner\n",
      "2022-09-22 11:19:22 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "processors = {'tokenize':'spacy','ner':'conll03'}\n",
    "tok_ner = stanza.Pipeline('en', processors=processors, package='ewt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "38f3633e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ne_replace(text):\n",
    "    p = tok_ner.process(text)\n",
    "    p = p.to_dict()\n",
    "    new_tokens = []\n",
    "    for sent in p:\n",
    "        for tok in sent:\n",
    "            if tok['ner'] == 'O':\n",
    "                new_tok = tok['text']\n",
    "            else:\n",
    "                new_tok = '<' + tok['ner'] + '>'\n",
    "            new_tokens.append(new_tok)\n",
    "    t = tokenizer.convert_tokens_to_string(new_tokens)\n",
    "    t = re.sub('< ([\\*R\\?]) >', '<\\g<1>>', t)\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "d4e11efa",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Hi Mr Smith, I am writing here to discuss with you if we should add a new group of animals to the new cards. You know that, under your leading, I've got some experience from the African set and Animals of the Americas, so I hope my suggestion might help. Firstly, I think we could reorganize the animals from different levels of concern. We could make four levels, such as extinction, critical, endangerment and vulnerable. Secondly, we could add some rare animals to our cards. I reckon animals such as flying fox, blue whale, snow leopard and Siberian tiger will make our cards more attractive. I also want to have the famous saying Dead as a dodo! on one of the cards. It's very interesting. Thirdly, I suppose the copyright cost for the photos won't be too high, because we already have copyright for many of the animals. Although we don't have a dodo, but I think the cost could be similar or less than our last product: Animals of the African Continent. Finally, I think our cards would be a good seller, because everyone green today!%% Yours, Tommy.\n",
      "     \n",
      "\n",
      " <B-PER> <I-PER> <E-PER> , I am writing here to discuss with you if we should add a new group of animals to the new cards . You know that , under your leading , I 've got some experience from the <S-MISC> set and <B-LOC> <I-LOC> <I-LOC> <E-LOC> , so I hope my suggestion might help . Firstly , I think we could reorganize the animals from different levels of concern . We could make four levels , such as extinction , critical , endangerment and vulnerable . Secondly , we could add some rare animals to our cards . I reckon animals such as flying fox , blue whale , snow leopard and <S-MISC> tiger will make our cards more attractive . I also want to have the famous saying <S-PER> as a dodo ! on one of the cards . It 's very interesting . Thirdly , I suppose the copyright cost for the photos wo n't be too high , because we already have copyright for many of the animals . Although we do n't have a dodo , but I think the cost could be similar or less than our last product : Animals of the <B-LOC> <E-LOC> . Finally , I think our cards would be a good seller , because everyone green today!%% Yours , <S-PER> .\n"
     ]
    }
   ],
   "source": [
    "# test the function\n",
    "q = old_dataset.sample(1)['Text'].item()\n",
    "s = ne_replace(q)\n",
    "print(q, '\\n\\n', s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1305b00",
   "metadata": {},
   "source": [
    "There might be problems with detokenizing back into a string: so far, the detokenized samples have some added spaces, like around apostrophes in contractions and possessives for example, but these mostly retokenize back into a recognizeable BERT-like form. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "fb79891f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new dataset. \n",
    "#This takes a long time to run. Load the new dataset from Data directory instead\n",
    "new_dataset = old_dataset\n",
    "new_dataset['Text'] = new_dataset['Text'].apply(lambda x: ne_replace(x))\n",
    "new_dataset.to_csv('ne_masked_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "30c3feb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from data directory\n",
    "new_dataset = pd.read_csv('ne_masked_dataset.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3908860a",
   "metadata": {},
   "source": [
    "<h1> RoBERTa </h1>\n",
    "\n",
    "<h2> Training </h2>\n",
    "\n",
    "visualizing in exBERT lite is more convenient than using BERTviz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2bf01b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaTokenizer, RobertaModel, RobertaForSequenceClassification, RobertaConfig, RobertaForMaskedLM\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "model = RobertaModel.from_pretrained('roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5def360f",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = RobertaConfig(max_position_embeddings = 256,\n",
    "                      hidden_dropout_prob = 0.05,\n",
    "                      classifier_dropout = 0.05) #try dropout as a strategy of reducing bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ace7ad9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta_pretrain = RobertaForMaskedLM(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4256fb46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Corpus</th>\n",
       "      <th>Target</th>\n",
       "      <th>Text</th>\n",
       "      <th>Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ICLE</td>\n",
       "      <td>GE</td>\n",
       "      <td>I 've been making music now for 20 years . You...</td>\n",
       "      <td>390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ICLE</td>\n",
       "      <td>GE</td>\n",
       "      <td>A quick inspection of the waste - paper basket...</td>\n",
       "      <td>557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ICLE</td>\n",
       "      <td>CN</td>\n",
       "      <td>Recycling of waste has long been a controversi...</td>\n",
       "      <td>587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ICLE</td>\n",
       "      <td>CN</td>\n",
       "      <td>Few years age , government in some cities such...</td>\n",
       "      <td>785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ICLE</td>\n",
       "      <td>JP</td>\n",
       "      <td>Gender discrimination . These Days , we often ...</td>\n",
       "      <td>829</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 Corpus Target  \\\n",
       "0           0   ICLE     GE   \n",
       "1           1   ICLE     GE   \n",
       "2           2   ICLE     CN   \n",
       "3           3   ICLE     CN   \n",
       "4           4   ICLE     JP   \n",
       "\n",
       "                                                Text  Length  \n",
       "0  I 've been making music now for 20 years . You...     390  \n",
       "1  A quick inspection of the waste - paper basket...     557  \n",
       "2  Recycling of waste has long been a controversi...     587  \n",
       "3  Few years age , government in some cities such...     785  \n",
       "4  Gender discrimination . These Days , we often ...     829  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "83b8c51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_text = ''\n",
    "for text in new_dataset['Text']:\n",
    "    no_newline = re.sub('\\n', ' ', text)\n",
    "    train_text = train_text + no_newline + '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "933e1e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = data_text.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "03fc4dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import RandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1134f487",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_dataset(df, sampler, n):\n",
    "    ds = ''\n",
    "    for a in range(n):\n",
    "        text = df['Text'].iloc[next(sampler)]\n",
    "        text = re.sub('\\n', ' ', text)\n",
    "        ds = ds + '\\n\\n' + text\n",
    "    return ds\n",
    "\n",
    "def tr_ts_vl_split(df, tr_size=0.85, vl_size=0.075):\n",
    "    \n",
    "    sampler = RandomSampler(df)\n",
    "    iterator = iter(sampler)\n",
    "    \n",
    "    n_samples = len(sampler)\n",
    "    ts_size = 1.0-tr_size-vl_size\n",
    "    \n",
    "    train_size = round(tr_size*n_samples)\n",
    "    val_size = round(vl_size*n_samples)\n",
    "    test_size = n_samples - train_size - val_size\n",
    "    \n",
    "    train_ds = sample_dataset(df, iterator, train_size)\n",
    "    val_ds = sample_dataset(df, iterator, val_size)\n",
    "    test_ds = sample_dataset(df, iterator, test_size)\n",
    "    \n",
    "    return train_ds, val_ds, test_ds\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "29633538",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, val_ds, test_ds = tr_ts_vl_split(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "98c40eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('roberta_pretrain_train_ds.txt', 'w') as file:\n",
    "    file.write(train_ds)\n",
    "with open('roberta_pretrain_val_ds.txt', 'w') as file:\n",
    "    file.write(val_ds)\n",
    "with open('roberta_pretain_test_ds.txt', 'w') as file:\n",
    "    file.write(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "f6ccb390",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "56019470",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bash: line 4: syntax error near unexpected token `do'\n",
      "bash: line 4: `for SPLIT in train valid test; do \\'\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'b'mkdir -p gpt2_bpe\\nwget -O --no-check-certificate gpt2_bpe/encoder.json https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json \\\\\\nwget -O --no-check-certificate gpt2_bpe/vocab.bpe https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe \\\\\\nfor SPLIT in train valid test; do \\\\\\n    python -m multiprocessing_bpe_encoder \\\\\\n        --encoder-json gpt2_bpe/encoder.json \\\\\\n        --vocab-bpe gpt2_bpe/vocab.bpe \\\\\\n        --inputs ../Data/roberta_pretrain_${SPLIT}_ds.txt \\\\\\n        --outputs ../Data/wikitext-103-raw/wiki.${SPLIT}.bpe \\\\\\ndone\\n'' returned non-zero exit status 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "Input \u001b[0;32mIn [129]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbash\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmkdir -p gpt2_bpe\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mwget -O --no-check-certificate gpt2_bpe/encoder.json https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mwget -O --no-check-certificate gpt2_bpe/vocab.bpe https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mfor SPLIT in train valid test; do \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    python -m multiprocessing_bpe_encoder \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        --encoder-json gpt2_bpe/encoder.json \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        --vocab-bpe gpt2_bpe/vocab.bpe \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        --inputs ../Data/roberta_pretrain_$\u001b[39;49m\u001b[38;5;132;43;01m{SPLIT}\u001b[39;49;00m\u001b[38;5;124;43m_ds.txt \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        --outputs ../Data/wikitext-103-raw/wiki.$\u001b[39;49m\u001b[38;5;132;43;01m{SPLIT}\u001b[39;49;00m\u001b[38;5;124;43m.bpe \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mdone\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/pyto/lib/python3.9/site-packages/IPython/core/interactiveshell.py:2358\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2356\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m   2357\u001b[0m     args \u001b[38;5;241m=\u001b[39m (magic_arg_s, cell)\n\u001b[0;32m-> 2358\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2359\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniforge3/envs/pyto/lib/python3.9/site-packages/IPython/core/magics/script.py:153\u001b[0m, in \u001b[0;36mScriptMagics._make_script_magic.<locals>.named_script_magic\u001b[0;34m(line, cell)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    152\u001b[0m     line \u001b[38;5;241m=\u001b[39m script\n\u001b[0;32m--> 153\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshebang\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcell\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/pyto/lib/python3.9/site-packages/IPython/core/magics/script.py:305\u001b[0m, in \u001b[0;36mScriptMagics.shebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mraise_error \u001b[38;5;129;01mand\u001b[39;00m p\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;66;03m# If we get here and p.returncode is still None, we must have\u001b[39;00m\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;66;03m# killed it but not yet seen its return code. We don't wait for it,\u001b[39;00m\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;66;03m# in case it's stuck in uninterruptible sleep. -9 = SIGKILL\u001b[39;00m\n\u001b[1;32m    304\u001b[0m     rc \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m9\u001b[39m\n\u001b[0;32m--> 305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CalledProcessError(rc, cell)\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command 'b'mkdir -p gpt2_bpe\\nwget -O --no-check-certificate gpt2_bpe/encoder.json https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json \\\\\\nwget -O --no-check-certificate gpt2_bpe/vocab.bpe https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe \\\\\\nfor SPLIT in train valid test; do \\\\\\n    python -m multiprocessing_bpe_encoder \\\\\\n        --encoder-json gpt2_bpe/encoder.json \\\\\\n        --vocab-bpe gpt2_bpe/vocab.bpe \\\\\\n        --inputs ../Data/roberta_pretrain_${SPLIT}_ds.txt \\\\\\n        --outputs ../Data/wikitext-103-raw/wiki.${SPLIT}.bpe \\\\\\ndone\\n'' returned non-zero exit status 2."
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "mkdir -p gpt2_bpe\n",
    "wget -O --no-check-certificate gpt2_bpe/encoder.json https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json \\\n",
    "wget -O --no-check-certificate gpt2_bpe/vocab.bpe https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe \\\n",
    "for SPLIT in train valid test; do \\\n",
    "    python -m multiprocessing_bpe_encoder \\\n",
    "        --encoder-json gpt2_bpe/encoder.json \\\n",
    "        --vocab-bpe gpt2_bpe/vocab.bpe \\\n",
    "        --inputs ../Data/roberta_pretrain_${SPLIT}_ds.txt \\\n",
    "        --outputs ../Data/wikitext-103-raw/wiki.${SPLIT}.bpe \\\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e5270dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta_model = RobertaForSequenceClassification(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1e961bae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaConfig {\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"bos_token_id\": 0,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 256,\n",
       "  \"model_type\": \"roberta\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 1,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.18.0\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 30522\n",
       "}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roberta_model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "90ad3553",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'>' not supported between instances of 'dict' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [37]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m config_revision[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_position_embeddings\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m256\u001b[39m\n\u001b[1;32m      3\u001b[0m config_revision \u001b[38;5;241m=\u001b[39m RobertaConfig(config_revision)\n\u001b[0;32m----> 5\u001b[0m roberta_cls_model \u001b[38;5;241m=\u001b[39m \u001b[43mRobertaForSequenceClassification\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_revision\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/pyto/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py:1173\u001b[0m, in \u001b[0;36mRobertaForSequenceClassification.__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m   1170\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_labels \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mnum_labels\n\u001b[1;32m   1171\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig \u001b[38;5;241m=\u001b[39m config\n\u001b[0;32m-> 1173\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroberta \u001b[38;5;241m=\u001b[39m \u001b[43mRobertaModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_pooling_layer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1174\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier \u001b[38;5;241m=\u001b[39m RobertaClassificationHead(config)\n\u001b[1;32m   1176\u001b[0m \u001b[38;5;66;03m# Initialize weights and apply final processing\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/pyto/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py:719\u001b[0m, in \u001b[0;36mRobertaModel.__init__\u001b[0;34m(self, config, add_pooling_layer)\u001b[0m\n\u001b[1;32m    716\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(config)\n\u001b[1;32m    717\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig \u001b[38;5;241m=\u001b[39m config\n\u001b[0;32m--> 719\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings \u001b[38;5;241m=\u001b[39m \u001b[43mRobertaEmbeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder \u001b[38;5;241m=\u001b[39m RobertaEncoder(config)\n\u001b[1;32m    722\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;241m=\u001b[39m RobertaPooler(config) \u001b[38;5;28;01mif\u001b[39;00m add_pooling_layer \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/pyto/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py:79\u001b[0m, in \u001b[0;36mRobertaEmbeddings.__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, config):\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[0;32m---> 79\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mword_embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEmbedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvocab_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhidden_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition_embeddings \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mEmbedding(config\u001b[38;5;241m.\u001b[39mmax_position_embeddings, config\u001b[38;5;241m.\u001b[39mhidden_size)\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken_type_embeddings \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mEmbedding(config\u001b[38;5;241m.\u001b[39mtype_vocab_size, config\u001b[38;5;241m.\u001b[39mhidden_size)\n",
      "File \u001b[0;32m~/miniforge3/envs/pyto/lib/python3.9/site-packages/torch/nn/modules/sparse.py:129\u001b[0m, in \u001b[0;36mEmbedding.__init__\u001b[0;34m(self, num_embeddings, embedding_dim, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse, _weight, device, dtype)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_dim \u001b[38;5;241m=\u001b[39m embedding_dim\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m padding_idx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 129\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mpadding_idx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m:\n\u001b[1;32m    130\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m padding_idx \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_embeddings, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPadding_idx must be within num_embeddings\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m padding_idx \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mTypeError\u001b[0m: '>' not supported between instances of 'dict' and 'int'"
     ]
    }
   ],
   "source": [
    "config_revision = roberta_cls_model.config.to_dict()\n",
    "config_revision['max_position_embeddings'] = 256\n",
    "config_revision = RobertaConfig(config_revision)\n",
    "\n",
    "roberta_cls_model = RobertaForSequenceClassification(config_revision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "791f4077",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = 'this is a sample string. How well can or can\\'t you tokenize me?'\n",
    "encoded = tokenizer(sample, return_tensors = 'pt')\n",
    "output = model(**encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c3c3372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-0.0370,  0.0704, -0.0398,  ..., -0.0669, -0.0483, -0.0442],\n",
       "         [ 0.0292, -0.1744,  0.0657,  ..., -0.0586,  0.1099, -0.1207],\n",
       "         [ 0.2565,  0.1220,  0.1763,  ..., -0.3393,  0.1181,  0.1021],\n",
       "         ...,\n",
       "         [ 0.0163, -0.0051, -0.0751,  ...,  0.1124,  0.0505, -0.0916],\n",
       "         [ 0.0338, -0.0959,  0.2445,  ..., -0.4090,  0.0130, -0.0446],\n",
       "         [-0.0284,  0.0666, -0.0780,  ..., -0.1201, -0.0458, -0.0832]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-6.6461e-03, -2.0431e-01, -2.1699e-01, -8.1624e-02,  1.1961e-01,\n",
       "          1.9411e-01,  2.5973e-01, -9.3657e-02, -7.2522e-02, -1.4712e-01,\n",
       "          2.1082e-01, -3.0681e-02, -8.7889e-02,  9.2792e-02, -1.3684e-01,\n",
       "          4.7925e-01,  2.1791e-01, -4.5997e-01,  3.6649e-02, -1.1003e-02,\n",
       "         -2.5565e-01,  6.1179e-02,  4.6769e-01,  3.2334e-01,  1.1820e-01,\n",
       "          6.3845e-02, -1.0979e-01, -3.3367e-02,  1.7878e-01,  2.0036e-01,\n",
       "          2.8467e-01,  6.4882e-02,  9.4356e-02,  2.3437e-01, -2.5102e-01,\n",
       "          4.8651e-02, -3.0439e-01,  4.5653e-02,  2.3429e-01, -1.7317e-01,\n",
       "         -9.3027e-02,  1.7387e-01,  2.1012e-01, -1.1729e-01, -9.5217e-02,\n",
       "          3.8355e-01,  2.5660e-01,  2.2339e-02, -1.1732e-01, -7.4171e-02,\n",
       "         -3.4451e-01,  3.5142e-01,  2.7898e-01,  2.1540e-01,  9.7851e-03,\n",
       "          7.0556e-02, -1.4091e-01,  2.5155e-01, -7.9004e-02, -9.7314e-02,\n",
       "         -1.2559e-01, -2.0103e-01,  9.8105e-04, -5.3854e-02,  1.9571e-02,\n",
       "         -1.2519e-01,  7.1777e-02, -1.3651e-01, -1.4495e-01,  5.9511e-02,\n",
       "         -8.7316e-02,  1.5544e-01,  1.7330e-01, -3.0059e-01, -2.9288e-01,\n",
       "          6.4498e-02, -5.7144e-01, -8.7961e-02,  3.0372e-01,  4.2666e-01,\n",
       "         -1.2670e-01,  1.8278e-01,  2.4103e-02,  2.0662e-01, -1.6734e-02,\n",
       "         -7.5804e-02, -2.5223e-02, -1.1762e-01,  1.8552e-01,  2.7412e-01,\n",
       "         -2.2191e-01, -3.8844e-01,  5.2398e-02,  2.7888e-02, -1.0280e-01,\n",
       "          7.5097e-03,  3.2892e-03, -7.5774e-02, -1.8110e-01, -1.5678e-01,\n",
       "          5.6368e-02, -2.6020e-01, -1.3903e-01,  2.8506e-01, -2.6562e-02,\n",
       "         -2.0131e-01, -2.4161e-02,  2.8047e-01,  7.7191e-02, -9.2243e-02,\n",
       "         -1.8759e-01,  4.2397e-01,  2.8294e-01,  2.1449e-02, -5.2274e-03,\n",
       "          1.8517e-01,  1.2610e-01, -2.9159e-01,  4.1769e-01, -3.1822e-01,\n",
       "         -1.6921e-02, -1.1328e-01,  1.1508e-01,  1.5971e-01, -2.0795e-01,\n",
       "          2.7988e-01,  1.4159e-01,  2.6018e-01,  1.9402e-01,  7.3656e-02,\n",
       "         -3.3824e-02,  1.2225e-01, -1.2389e-01,  1.4498e-01,  2.2490e-01,\n",
       "          1.1428e-01,  3.6095e-03, -3.1364e-01, -2.0128e-01,  2.5176e-01,\n",
       "          3.2647e-01,  1.6818e-01, -3.7150e-02,  1.8160e-01,  9.9169e-02,\n",
       "          2.2340e-01,  1.3340e-01, -4.0792e-01,  3.2123e-02,  3.4020e-01,\n",
       "          1.0113e-01,  1.4662e-01, -8.1852e-02, -2.8979e-01, -2.5122e-01,\n",
       "         -9.7172e-02,  5.2636e-02, -3.2441e-01, -1.1201e-01,  3.5499e-01,\n",
       "          3.6863e-02,  3.4026e-04, -1.4686e-01, -2.3612e-01, -1.4121e-02,\n",
       "         -1.1636e-01,  2.0652e-02,  9.8210e-02, -1.0588e-01, -4.0474e-01,\n",
       "         -6.9403e-02, -5.4001e-01, -1.1264e-01,  1.8349e-01, -3.3594e-01,\n",
       "          2.6120e-01, -2.7848e-01,  8.9104e-02,  3.9369e-01,  4.9386e-02,\n",
       "          5.4619e-03, -1.9490e-01, -2.1374e-02,  1.1262e-01,  3.3083e-01,\n",
       "          2.5214e-01, -3.8272e-01,  1.1926e-01,  1.2327e-01,  2.5921e-01,\n",
       "          1.3981e-01, -7.2023e-02, -1.1752e-01,  1.3823e-01, -2.1934e-01,\n",
       "          1.8315e-01, -2.0888e-01,  1.8058e-01, -2.4508e-01, -2.1500e-01,\n",
       "          2.7812e-01, -4.1007e-01, -2.8024e-02,  1.1217e-01,  2.5003e-01,\n",
       "          2.3992e-03, -4.2890e-02, -8.4945e-02,  1.2323e-01,  1.7369e-01,\n",
       "          1.4400e-01, -4.0132e-01,  2.5928e-01, -1.4267e-02, -3.8820e-02,\n",
       "         -3.8946e-02,  1.7803e-01,  2.5375e-01,  7.4256e-02, -4.0261e-01,\n",
       "         -1.4850e-01,  1.1253e-01,  2.7814e-01, -2.2390e-01,  1.3890e-01,\n",
       "         -2.8296e-01, -3.8524e-01, -1.4761e-01,  2.0653e-01,  2.1864e-01,\n",
       "          1.6170e-01, -2.8191e-01,  1.6552e-01, -1.0391e-01, -4.1929e-01,\n",
       "         -3.5835e-01, -1.0391e-01,  2.2646e-01,  1.4844e-01,  1.9763e-01,\n",
       "          2.4540e-01,  2.4234e-02,  1.1989e-01,  1.3566e-01,  1.5472e-01,\n",
       "         -1.4473e-01,  1.8241e-01, -3.4970e-01, -4.2411e-02, -2.7356e-01,\n",
       "         -1.9747e-01, -2.0397e-01,  3.9722e-01, -2.2438e-01,  2.4427e-01,\n",
       "          3.8805e-01, -2.9539e-01, -1.0010e-01,  1.4974e-01,  1.0095e-01,\n",
       "          8.3953e-02, -1.3374e-01,  1.8413e-01,  1.5161e-01, -1.3404e-01,\n",
       "          2.3687e-01, -4.0397e-03,  2.6044e-01,  1.5871e-01,  9.4730e-02,\n",
       "          1.5716e-01,  1.2248e-01, -1.5626e-01,  5.4044e-02,  1.7235e-02,\n",
       "         -3.4553e-02, -2.4411e-01, -1.6116e-01,  2.3079e-01, -4.5009e-02,\n",
       "          3.0385e-02, -1.8124e-01, -1.0040e-01,  2.2383e-02,  4.0363e-01,\n",
       "         -3.6062e-01,  2.5020e-01,  7.1791e-02,  1.4276e-01, -2.1792e-01,\n",
       "         -2.1004e-01,  6.7767e-02,  1.6366e-01, -3.9085e-01,  1.3137e-02,\n",
       "          1.6355e-01,  9.4279e-02,  2.1080e-01,  2.6141e-01,  3.9788e-03,\n",
       "         -1.0736e-01,  4.8209e-01, -1.6492e-01, -1.2526e-01,  2.7080e-01,\n",
       "         -2.8187e-01, -2.7059e-01,  2.5952e-01, -4.9561e-02,  2.9105e-01,\n",
       "          1.3222e-01,  3.7122e-02,  6.0269e-02, -5.9059e-01,  7.8440e-02,\n",
       "         -4.6305e-01,  2.5248e-03,  3.2709e-02, -8.8546e-02, -2.1093e-01,\n",
       "          1.3798e-01,  2.9774e-01, -2.4499e-01, -3.5047e-02,  1.9555e-01,\n",
       "          9.9226e-02, -1.0403e-01,  4.7587e-01, -6.9987e-03,  2.1636e-01,\n",
       "         -5.3790e-02,  2.7310e-01, -1.9182e-01,  2.6103e-01, -2.5735e-01,\n",
       "         -1.0880e-01,  1.0567e-02,  8.7237e-02,  6.3370e-02, -7.7347e-02,\n",
       "         -3.4328e-01,  2.3491e-01, -1.5926e-02, -7.0746e-02, -4.8087e-02,\n",
       "          8.0562e-02,  6.6320e-03,  4.2126e-02,  4.9041e-02,  3.3252e-01,\n",
       "          2.2768e-01, -1.7093e-02, -3.6022e-01, -1.6269e-02, -1.1048e-01,\n",
       "          5.0639e-02,  3.0977e-02, -2.7413e-02,  4.3751e-01, -8.4017e-02,\n",
       "         -1.7556e-02, -1.4344e-01,  2.5066e-01,  2.0605e-01,  1.2991e-01,\n",
       "          1.0982e-01,  7.7427e-02,  1.3930e-01, -5.8897e-02, -1.3880e-02,\n",
       "         -1.5453e-01, -2.1879e-01, -2.7536e-01,  2.1110e-01, -2.3371e-01,\n",
       "         -1.7536e-01,  1.5035e-01,  2.1876e-01, -1.3595e-01,  1.4308e-01,\n",
       "          3.0559e-01,  1.0120e-01, -1.5048e-01,  2.6562e-01, -1.0874e-01,\n",
       "          1.1577e-01,  3.1099e-01, -2.0490e-02,  1.9444e-01,  4.8531e-01,\n",
       "          2.3149e-01, -3.4494e-01, -3.0920e-02, -2.2972e-01,  1.2445e-02,\n",
       "          2.3753e-01, -1.5700e-01,  1.8755e-01,  3.8834e-01,  3.1056e-01,\n",
       "          4.4092e-01,  1.0797e-04, -1.2781e-01,  1.0642e-01,  2.2768e-01,\n",
       "          1.8143e-02, -1.5235e-01, -1.8834e-01,  2.5259e-01,  6.8658e-02,\n",
       "         -1.4557e-01, -2.6783e-02, -1.1798e-01,  4.5222e-02, -1.3313e-01,\n",
       "         -3.9166e-01,  2.5098e-02,  1.9276e-01, -4.6410e-01,  8.5972e-02,\n",
       "         -2.7610e-01,  5.3916e-02, -2.3755e-01,  2.0427e-01, -2.1973e-01,\n",
       "         -1.1301e-01,  4.1049e-01, -7.8619e-02,  3.5211e-02, -1.6935e-01,\n",
       "         -1.2750e-01,  7.7258e-03, -1.7516e-03, -2.7033e-02, -1.1154e-02,\n",
       "          3.3472e-01, -1.1591e-01,  3.0061e-02,  2.7039e-02,  2.0915e-01,\n",
       "         -6.4130e-02,  1.6918e-01,  1.6271e-02, -1.2680e-01, -3.8842e-01,\n",
       "          1.4691e-01, -2.0700e-01, -4.2842e-01, -3.5973e-01,  3.5395e-01,\n",
       "         -1.4188e-01, -2.4926e-01, -2.1078e-01, -2.5415e-01,  7.8117e-02,\n",
       "          1.8053e-01,  4.4799e-01, -3.8222e-01, -7.8959e-02,  4.8166e-01,\n",
       "         -6.9142e-02, -1.8298e-01,  2.8351e-01,  1.9448e-01, -3.2387e-01,\n",
       "          3.2104e-01,  2.5748e-01, -5.6818e-02,  1.8882e-02,  5.1323e-01,\n",
       "          1.4723e-01,  1.9580e-01, -2.1859e-01,  4.5340e-01, -2.1138e-01,\n",
       "          2.9743e-01, -1.4555e-01, -2.1654e-01, -2.0313e-01, -1.5553e-02,\n",
       "          3.3405e-01,  1.8077e-01, -4.1504e-01, -1.0322e-01,  4.0215e-02,\n",
       "          3.6035e-01, -3.7916e-01, -8.0975e-02,  5.1334e-03, -3.3737e-01,\n",
       "          1.2244e-01,  8.7146e-02,  2.1159e-01, -3.8388e-01,  6.4024e-03,\n",
       "          4.0608e-01, -3.0545e-01,  1.2237e-01,  3.1103e-01,  7.0583e-02,\n",
       "          3.4410e-01, -3.8547e-02,  6.6376e-03,  4.7395e-02, -2.4210e-01,\n",
       "         -2.9760e-02,  1.5048e-01,  5.5822e-01,  1.3269e-01, -3.5998e-01,\n",
       "          9.9344e-02,  2.2788e-01, -1.5666e-01,  2.9623e-01, -7.7745e-02,\n",
       "         -5.5297e-02,  2.6877e-01, -4.0267e-02,  1.4061e-01, -8.6531e-02,\n",
       "         -2.2947e-01, -3.1243e-01,  3.7312e-01, -2.0636e-01, -1.1687e-01,\n",
       "         -1.5423e-01, -9.5246e-02, -1.6425e-01,  3.6788e-02, -3.8327e-01,\n",
       "          3.1945e-01,  1.2405e-01, -1.7088e-01, -9.2781e-02, -9.4296e-02,\n",
       "         -1.5968e-01, -2.1756e-01, -2.5543e-01,  4.3182e-01, -1.7359e-01,\n",
       "         -4.3456e-01,  2.4902e-01,  4.0974e-02,  3.5680e-01,  3.5285e-02,\n",
       "          9.4331e-02, -4.2031e-02,  1.3850e-01,  8.3061e-02, -1.3291e-01,\n",
       "          2.6308e-01,  5.7006e-02, -5.5086e-01, -1.2507e-01, -2.1041e-01,\n",
       "          9.6134e-02,  2.2374e-01, -3.5286e-01,  1.2723e-02,  4.6637e-02,\n",
       "          1.3771e-01,  1.5053e-02, -1.0530e-01, -5.3070e-02,  4.0377e-01,\n",
       "          2.2295e-01,  2.9898e-01,  8.7594e-02,  2.4172e-01, -3.5911e-02,\n",
       "         -3.3727e-01,  4.1069e-02,  8.3816e-02, -1.8996e-01,  4.3320e-01,\n",
       "         -9.8103e-02, -3.9508e-01, -6.5207e-02,  4.0760e-01,  1.1237e-01,\n",
       "         -4.4717e-03, -3.9134e-02,  2.1966e-01,  1.7101e-01, -1.2853e-01,\n",
       "          1.6704e-01, -2.7761e-02, -1.3714e-01, -1.2049e-01,  9.6326e-02,\n",
       "         -2.2407e-01,  3.7557e-02, -1.5709e-01, -1.4438e-02, -2.0851e-01,\n",
       "         -3.7126e-03, -2.0551e-01,  2.5673e-01, -3.1729e-01,  1.0477e-01,\n",
       "          6.5278e-02,  2.9771e-01, -3.4976e-01, -1.5012e-01, -5.6469e-02,\n",
       "          1.6047e-01,  2.7852e-01,  3.4682e-01,  2.5842e-02,  2.5322e-03,\n",
       "         -1.7055e-01, -2.4354e-01,  6.4361e-02, -2.0786e-01,  1.4955e-01,\n",
       "          6.8856e-02,  2.4382e-01, -2.9540e-01, -1.8788e-01,  2.3184e-01,\n",
       "         -1.0714e-01, -1.2128e-01,  4.1828e-01,  2.4112e-01,  2.2001e-01,\n",
       "          9.1125e-03,  2.3709e-01,  5.2469e-02, -1.7755e-01, -1.3397e-01,\n",
       "         -2.3760e-01,  9.2658e-02, -9.7463e-02, -5.8348e-02, -6.8796e-02,\n",
       "         -1.2030e-01, -1.9596e-01, -1.6521e-01,  1.3661e-01,  1.2737e-01,\n",
       "          2.9076e-02, -6.0985e-02, -3.4692e-02, -2.6360e-01,  3.1334e-01,\n",
       "          1.6605e-02,  6.7055e-02, -7.8174e-02,  3.3246e-02, -1.4440e-01,\n",
       "          2.2868e-01,  2.2331e-01,  9.9039e-02, -1.8596e-01, -4.5059e-02,\n",
       "         -2.9487e-01, -3.5434e-01,  5.8942e-02,  1.3498e-01,  1.0323e-01,\n",
       "         -9.4601e-02, -2.7130e-01, -3.0128e-03, -1.3474e-01,  1.6376e-01,\n",
       "          1.3386e-02, -1.6831e-01, -9.5566e-02, -7.2490e-02, -4.4675e-02,\n",
       "          8.3706e-02, -2.0026e-01, -1.9889e-01, -1.1872e-01, -7.7391e-02,\n",
       "         -6.2843e-02,  3.3579e-01, -5.3497e-02,  2.6670e-01, -1.4275e-01,\n",
       "         -3.0370e-03, -1.7901e-01,  1.1237e-01, -6.3276e-02,  7.4433e-02,\n",
       "          2.6885e-01, -4.4512e-01, -1.7624e-01, -1.0348e-02, -2.1051e-01,\n",
       "         -1.4361e-01, -8.0951e-02, -2.0358e-02,  2.0693e-01, -3.4241e-01,\n",
       "          1.9123e-01, -1.0681e-01,  1.7571e-01, -8.6522e-02, -2.6052e-01,\n",
       "         -1.5785e-01,  6.8496e-03,  2.5985e-01, -3.4140e-01, -2.2934e-01,\n",
       "         -2.6729e-01, -8.3558e-02, -6.4993e-02, -2.6153e-01,  4.0940e-01,\n",
       "         -1.1341e-01, -8.3507e-02,  1.7550e-02,  4.3108e-01,  1.9426e-01,\n",
       "          1.7173e-01,  2.0406e-01, -1.9889e-02,  4.0480e-02,  1.0709e-01,\n",
       "         -4.5820e-01,  2.3063e-01, -2.1735e-01, -1.3982e-01,  5.1528e-03,\n",
       "          9.4402e-02, -1.9638e-02,  6.8343e-03, -1.2827e-01, -9.0825e-02,\n",
       "          2.2747e-01, -3.6153e-01, -1.6572e-02,  2.7472e-01,  1.4859e-01,\n",
       "         -2.5937e-01,  4.1140e-02,  1.2106e-01,  3.6424e-01,  9.0104e-02,\n",
       "         -2.1234e-01,  1.2104e-01, -3.2599e-01, -3.9282e-02, -1.7448e-01,\n",
       "         -2.8882e-01,  1.6842e-01, -7.2420e-02,  5.9301e-02, -7.5298e-02,\n",
       "         -2.7805e-01,  2.1261e-01, -4.7604e-02, -6.2684e-02,  4.1745e-01,\n",
       "          3.3223e-02, -1.0427e-01,  1.5936e-01,  2.1801e-02,  1.0459e-02,\n",
       "         -9.4382e-02,  2.7718e-01,  1.9815e-01, -2.8529e-01,  1.3013e-01,\n",
       "         -1.2918e-01, -4.4541e-02, -9.1493e-02]], grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d8817a1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of RobertaModel(\n",
       "  (embeddings): RobertaEmbeddings(\n",
       "    (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "    (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "    (token_type_embeddings): Embedding(1, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): RobertaEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): RobertaPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyto_env",
   "language": "python",
   "name": "pyto"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
