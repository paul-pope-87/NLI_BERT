{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffd55d5e",
   "metadata": {},
   "source": [
    "<h1> GNN Initial Training </h1>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f64ab1e",
   "metadata": {},
   "source": [
    "Following a procedure loosely based on:\n",
    "\n",
    "Some background reading and resources:\n",
    "    1. https://distill.pub/2021/gnn-intro/ \n",
    "    2. https://arxiv.org/pdf/1910.02356v2.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7646cb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use pyto_env kernel, pyto env.\n",
    "\n",
    "import os\n",
    "import json\n",
    "import csv\n",
    "import pandas as pd\n",
    "import importlib\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from torchmetrics import F1Score\n",
    "\n",
    "import common\n",
    "from common import plot_confusion_matrix, get_weights\n",
    "\n",
    "import common_metrics\n",
    "from common_metrics import plot_one_vs_one_roc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74ac8f27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'common' from '/Users/paulp/Library/CloudStorage/OneDrive-UniversityofEasternFinland/UEF/Thesis/Notebooks/common.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7582d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = \"/Users/paulp/Library/CloudStorage/OneDrive-UniversityofEasternFinland/UEF/Thesis\"\n",
    "data_dir = os.path.join(project_dir,\"Data\")\n",
    "model_dir = os.path.join(project_dir, \"Models\")\n",
    "\n",
    "# Word embeddings\n",
    "hidden_size = 300\n",
    "glove_file = os.path.join(project_dir, f'Notebooks/glove.6B/glove.6B.{hidden_size}d.txt')\n",
    "\n",
    "\n",
    "os.chdir(data_dir)\n",
    "\n",
    "#L1 to integer map for label encoding\n",
    "with open('target_idx.json') as f:\n",
    "    data = f.read()\n",
    "target_idx = json.loads(data)\n",
    "idx_target = {target_idx[a]:a for a in target_idx.keys()}\n",
    "\n",
    "\n",
    "# additional special tokens\n",
    "with open('spec_tokens_ne.txt', 'rb') as file:\n",
    "    spec_tokens = pickle.load(file)\n",
    "spec_tokens = [a for a in spec_tokens if '-' not in a]\n",
    "\n",
    "# Load from data directory\n",
    "dataset = pd.read_csv('masked_data_set.csv', index_col = 0).reset_index(drop=True)\n",
    "ds_tr = pd.read_csv('train.csv')\n",
    "ds_vl = pd.read_csv('validation.csv')\n",
    "ds_ts = pd.read_csv('test.csv')\n",
    "#ds_tr = pd.concat([ds_tr, ds_vl], axis=0) # just use val set in training and test for validation. fewer operations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04ef0c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['an', 'expert', 'in', 'nlp', ',', '<r>', 'states', 'that', 'in', '<misc>', 'this', 'is', 'not', 'true', '.']\n"
     ]
    }
   ],
   "source": [
    "# tokenizer \n",
    "\n",
    "import spacy\n",
    "from spacy.symbols import ORTH\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Add special case rule\n",
    "for tok in spec_tokens:\n",
    "    special_case = [{ORTH: tok}]\n",
    "    nlp.tokenizer.add_special_case(tok, special_case)\n",
    "    \n",
    "# Check new tokenization\n",
    "print([w.text.lower() for w in nlp(\"An expert in NLP, <R> states that in <MISC> this is not true.\")])  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f532a967",
   "metadata": {},
   "source": [
    "<h1> Data Helper </h1>\n",
    "\n",
    "This class processes the dataframe for compatibility with the model, and provides a batch iterator for sampling by the training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7807621",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_fn(text):\n",
    "    # need lowercase for GloVe vectors\n",
    "    return [w.text.lower() for w in nlp(text)]\n",
    "\n",
    "class GCNDataHelper(object):\n",
    "    '''\n",
    "    customized from source code.\n",
    "    Use with SpaCy tokenizer\n",
    "    \n",
    "    '''\n",
    "    def __init__(self, \n",
    "                 dataset,\n",
    "                 tokenize_fn, \n",
    "                 target_idx,\n",
    "                 device,\n",
    "                 mode='train', \n",
    "                 vocab=None):\n",
    "\n",
    "        self.mode = mode\n",
    "        self.device = device\n",
    "        self.dataset = dataset# pd.DataFrame object\n",
    "        self.tokenizer = tokenize_fn # bert custom trained tokenizer\n",
    "        self.labels_str = target_idx\n",
    "        self.label = self.label_to_onehot()\n",
    "        content, label = self.get_content() \n",
    "        \n",
    "        if vocab is None:\n",
    "            #self.vocab = [] #necessary?\n",
    "            #try:\n",
    "           #     self.get_vocab()\n",
    "            #except FileNotFoundError:\n",
    "            self.build_vocab_and_freq(content, min_count=24)\n",
    "        else:\n",
    "            self.vocab = vocab\n",
    "        \n",
    "        self.d = dict(zip(self.vocab, range(len(self.vocab)))) # integer IDS\n",
    "        self.content = self.docs_as_ids(dataset)\n",
    "    \n",
    "    def docs_as_ids(self, dataset):\n",
    "        content = []\n",
    "        for text in dataset['Text']:\n",
    "            tokens = self.tokenizer(text)\n",
    "            ids = [self.word2id(a) for a in tokens]\n",
    "            content.append(ids)\n",
    "        return content\n",
    "\n",
    "    def label_to_onehot(self): # is this actually one-hots or label index values?\n",
    "        target_indices = [self.labels_str[a] for a in self.dataset['Target']]\n",
    "        return target_indices \n",
    "    \n",
    "    def get_content(self):\n",
    "        label = self.dataset['Target'].tolist()\n",
    "        content = self.dataset['Text'].tolist()\n",
    "        #content, label = zip(content, label)\n",
    "        return content, label\n",
    "    \n",
    "    def word2id(self, word): # text from dataset\n",
    "\n",
    "        '''\n",
    "        return integer IDs for embedding lookup. \n",
    "        '''\n",
    "\n",
    "        try:\n",
    "            result = self.d[word]\n",
    "        except KeyError:\n",
    "            result = self.d['<unk>']\n",
    "\n",
    "        return result\n",
    "\n",
    "    def build_vocab_and_freq(self, dataset, min_count): # returns list of tokens only\n",
    "        '''\n",
    "        assigns a dictionary of frequency counts and list of tokens as vocab.\n",
    "        '''\n",
    "        vocab = []\n",
    "        freq = {}\n",
    "\n",
    "        for c in self.dataset['Text']:\n",
    "            words = self.tokenizer(c)\n",
    "            for word in words:\n",
    "                if word not in vocab:\n",
    "                    vocab.append(word)\n",
    "                    freq[word] = 1\n",
    "                else:\n",
    "                    freq[word] += 1\n",
    "\n",
    "        results = []\n",
    "        for word in freq.keys():\n",
    "            if freq[word] < min_count:\n",
    "                continue\n",
    "            else:\n",
    "                results.append(word)\n",
    "        results.insert(0, '<unk>')\n",
    "        \n",
    "        with open('gcn_vocab.txt', 'w') as f:\n",
    "            f.write('\\n'.join(results))\n",
    "            \n",
    "        with open('gcn_freq.csv', 'w') as f:\n",
    "            writer = csv.writer(f)\n",
    "            r = list(zip(freq.keys(), freq.values()))\n",
    "            writer.writerows(r)\n",
    "            \n",
    "        self.vocab = results\n",
    "\n",
    "    def batch_iter(self, batch_size, num_epoch):\n",
    "        for i in range(num_epoch):\n",
    "            num_per_epoch = int(len(self.content) / batch_size)\n",
    "            for batch_id in range(num_per_epoch):\n",
    "                start = batch_id * batch_size\n",
    "                end = min((batch_id + 1) * batch_size, len(self.content))\n",
    "\n",
    "                content = self.content[start:end]\n",
    "                label = self.label[start:end]\n",
    "\n",
    "                yield content, torch.tensor(label).to(device), i\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6c4265",
   "metadata": {},
   "source": [
    "<h1> PMI - (Positive) Pointwise Mutual Information </h1>\n",
    "\n",
    "More information:\n",
    "https://en.wikipedia.org/wiki/Pointwise_mutual_information\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7813ab21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_PMI(helper, window_size=50):\n",
    "    '''\n",
    "    \n",
    "    calculate Positive Pointwise Mutual Information across the dataset.\n",
    "    Inputs: object of GCNDataHelper class\n",
    "    Outputs: edge weights, edge mappings, and counts number of edges\n",
    "    \n",
    "    '''\n",
    "    len_vocab = len(helper.vocab)\n",
    "    pair_count_matrix = np.zeros((len_vocab, len_vocab), dtype=int)\n",
    "    word_count =np.zeros(len_vocab, dtype=int)\n",
    "    \n",
    "    for sample in helper.content:\n",
    "        for i, word in enumerate(sample):\n",
    "            try:\n",
    "                word_count[word] += 1\n",
    "            except KeyError:\n",
    "                continue\n",
    "            start_index = max(0, i - window_size)\n",
    "            end_index = min(len(sample), i + window_size)\n",
    "            for j in range(start_index, end_index):\n",
    "                if i == j:\n",
    "                    continue\n",
    "                else:\n",
    "                    target_word = sample[j]\n",
    "                    try:\n",
    "                        pair_count_matrix[word, target_word] += 1\n",
    "                    except KeyError:\n",
    "                        continue\n",
    "        \n",
    "    total_count = np.sum(word_count)\n",
    "    word_count = word_count / total_count\n",
    "    pair_count_matrix = pair_count_matrix / total_count\n",
    "    \n",
    "    pmi_matrix = np.zeros((len_vocab, len_vocab), dtype=float)\n",
    "    for i in range(len_vocab):\n",
    "        for j in range(len_vocab):\n",
    "            pmi_matrix[i, j] = np.log(\n",
    "                pair_count_matrix[i, j] / (word_count[i] * word_count[j]) \n",
    "            )\n",
    "    \n",
    "    # removes nan values due to division by zero above\n",
    "    pmi_matrix = np.nan_to_num(pmi_matrix)\n",
    "    \n",
    "    # positive PMI - remove all negative values \n",
    "    pmi_matrix = np.maximum(pmi_matrix, 0.0)\n",
    "\n",
    "    edges_weights = [0.0]\n",
    "    count = 1\n",
    "    edges_mappings = np.zeros((len_vocab, len_vocab), dtype=int)\n",
    "    for i in range(len_vocab):\n",
    "        for j in range(len_vocab):\n",
    "            if pmi_matrix[i, j] != 0:\n",
    "                edges_weights.append(pmi_matrix[i, j])\n",
    "                edges_mappings[i, j] = count\n",
    "                count += 1\n",
    "\n",
    "    edges_weights = np.array(edges_weights)\n",
    "\n",
    "    edges_weights = edges_weights.reshape(-1, 1)\n",
    "    # print(edges_weights.shape)\n",
    "    edges_weights = torch.Tensor(edges_weights)\n",
    "    \n",
    "    return edges_weights, edges_mappings, count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf71ebf6",
   "metadata": {},
   "source": [
    "<h1> Model Class </h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2dea61f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "import tqdm\n",
    "import sys, random\n",
    "import time, datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5657040b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class LayerNorm in module torch.nn.modules.normalization:\n",
      "\n",
      "class LayerNorm(torch.nn.modules.module.Module)\n",
      " |  LayerNorm(normalized_shape: Union[int, List[int], torch.Size], eps: float = 1e-05, elementwise_affine: bool = True, device=None, dtype=None) -> None\n",
      " |  \n",
      " |  Applies Layer Normalization over a mini-batch of inputs as described in\n",
      " |  the paper `Layer Normalization <https://arxiv.org/abs/1607.06450>`__\n",
      " |  \n",
      " |  .. math::\n",
      " |      y = \\frac{x - \\mathrm{E}[x]}{ \\sqrt{\\mathrm{Var}[x] + \\epsilon}} * \\gamma + \\beta\n",
      " |  \n",
      " |  The mean and standard-deviation are calculated over the last `D` dimensions, where `D`\n",
      " |  is the dimension of :attr:`normalized_shape`. For example, if :attr:`normalized_shape`\n",
      " |  is ``(3, 5)`` (a 2-dimensional shape), the mean and standard-deviation are computed over\n",
      " |  the last 2 dimensions of the input (i.e. ``input.mean((-2, -1))``).\n",
      " |  :math:`\\gamma` and :math:`\\beta` are learnable affine transform parameters of\n",
      " |  :attr:`normalized_shape` if :attr:`elementwise_affine` is ``True``.\n",
      " |  The standard-deviation is calculated via the biased estimator, equivalent to\n",
      " |  `torch.var(input, unbiased=False)`.\n",
      " |  \n",
      " |  .. note::\n",
      " |      Unlike Batch Normalization and Instance Normalization, which applies\n",
      " |      scalar scale and bias for each entire channel/plane with the\n",
      " |      :attr:`affine` option, Layer Normalization applies per-element scale and\n",
      " |      bias with :attr:`elementwise_affine`.\n",
      " |  \n",
      " |  This layer uses statistics computed from input data in both training and\n",
      " |  evaluation modes.\n",
      " |  \n",
      " |  Args:\n",
      " |      normalized_shape (int or list or torch.Size): input shape from an expected input\n",
      " |          of size\n",
      " |  \n",
      " |          .. math::\n",
      " |              [* \\times \\text{normalized\\_shape}[0] \\times \\text{normalized\\_shape}[1]\n",
      " |                  \\times \\ldots \\times \\text{normalized\\_shape}[-1]]\n",
      " |  \n",
      " |          If a single integer is used, it is treated as a singleton list, and this module will\n",
      " |          normalize over the last dimension which is expected to be of that specific size.\n",
      " |      eps: a value added to the denominator for numerical stability. Default: 1e-5\n",
      " |      elementwise_affine: a boolean value that when set to ``True``, this module\n",
      " |          has learnable per-element affine parameters initialized to ones (for weights)\n",
      " |          and zeros (for biases). Default: ``True``.\n",
      " |  \n",
      " |  Attributes:\n",
      " |      weight: the learnable weights of the module of shape\n",
      " |          :math:`\\text{normalized\\_shape}` when :attr:`elementwise_affine` is set to ``True``.\n",
      " |          The values are initialized to 1.\n",
      " |      bias:   the learnable bias of the module of shape\n",
      " |              :math:`\\text{normalized\\_shape}` when :attr:`elementwise_affine` is set to ``True``.\n",
      " |              The values are initialized to 0.\n",
      " |  \n",
      " |  Shape:\n",
      " |      - Input: :math:`(N, *)`\n",
      " |      - Output: :math:`(N, *)` (same shape as input)\n",
      " |  \n",
      " |  Examples::\n",
      " |  \n",
      " |      >>> # NLP Example\n",
      " |      >>> batch, sentence_length, embedding_dim = 20, 5, 10\n",
      " |      >>> embedding = torch.randn(batch, sentence_length, embedding_dim)\n",
      " |      >>> layer_norm = nn.LayerNorm(embedding_dim)\n",
      " |      >>> # Activate module\n",
      " |      >>> layer_norm(embedding)\n",
      " |      >>>\n",
      " |      >>> # Image Example\n",
      " |      >>> N, C, H, W = 20, 5, 10, 10\n",
      " |      >>> input = torch.randn(N, C, H, W)\n",
      " |      >>> # Normalize over the last three dimensions (i.e. the channel and spatial dimensions)\n",
      " |      >>> # as shown in the image below\n",
      " |      >>> layer_norm = nn.LayerNorm([C, H, W])\n",
      " |      >>> output = layer_norm(input)\n",
      " |  \n",
      " |  .. image:: ../_static/img/nn/layer_norm.jpg\n",
      " |      :scale: 50 %\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      LayerNorm\n",
      " |      torch.nn.modules.module.Module\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, normalized_shape: Union[int, List[int], torch.Size], eps: float = 1e-05, elementwise_affine: bool = True, device=None, dtype=None) -> None\n",
      " |      Initializes internal Module state, shared by both nn.Module and ScriptModule.\n",
      " |  \n",
      " |  extra_repr(self) -> str\n",
      " |      Set the extra representation of the module\n",
      " |      \n",
      " |      To print customized extra information, you should re-implement\n",
      " |      this method in your own modules. Both single-line and multi-line\n",
      " |      strings are acceptable.\n",
      " |  \n",
      " |  forward(self, input: torch.Tensor) -> torch.Tensor\n",
      " |      Defines the computation performed at every call.\n",
      " |      \n",
      " |      Should be overridden by all subclasses.\n",
      " |      \n",
      " |      .. note::\n",
      " |          Although the recipe for forward pass needs to be defined within\n",
      " |          this function, one should call the :class:`Module` instance afterwards\n",
      " |          instead of this since the former takes care of running the\n",
      " |          registered hooks while the latter silently ignores them.\n",
      " |  \n",
      " |  reset_parameters(self) -> None\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __annotations__ = {'elementwise_affine': <class 'bool'>, 'eps': <class...\n",
      " |  \n",
      " |  __constants__ = ['normalized_shape', 'eps', 'elementwise_affine']\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  __call__ = _call_impl(self, *input, **kwargs)\n",
      " |  \n",
      " |  __delattr__(self, name)\n",
      " |      Implement delattr(self, name).\n",
      " |  \n",
      " |  __dir__(self)\n",
      " |      Default dir() implementation.\n",
      " |  \n",
      " |  __getattr__(self, name: str) -> Union[torch.Tensor, ForwardRef('Module')]\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setattr__(self, name: str, value: Union[torch.Tensor, ForwardRef('Module')]) -> None\n",
      " |      Implement setattr(self, name, value).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  add_module(self, name: str, module: Optional[ForwardRef('Module')]) -> None\n",
      " |      Adds a child module to the current module.\n",
      " |      \n",
      " |      The module can be accessed as an attribute using the given name.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (str): name of the child module. The child module can be\n",
      " |              accessed from this module using the given name\n",
      " |          module (Module): child module to be added to the module.\n",
      " |  \n",
      " |  apply(self: ~T, fn: Callable[[ForwardRef('Module')], NoneType]) -> ~T\n",
      " |      Applies ``fn`` recursively to every submodule (as returned by ``.children()``)\n",
      " |      as well as self. Typical use includes initializing the parameters of a model\n",
      " |      (see also :ref:`nn-init-doc`).\n",
      " |      \n",
      " |      Args:\n",
      " |          fn (:class:`Module` -> None): function to be applied to each submodule\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> @torch.no_grad()\n",
      " |          >>> def init_weights(m):\n",
      " |          >>>     print(m)\n",
      " |          >>>     if type(m) == nn.Linear:\n",
      " |          >>>         m.weight.fill_(1.0)\n",
      " |          >>>         print(m.weight)\n",
      " |          >>> net = nn.Sequential(nn.Linear(2, 2), nn.Linear(2, 2))\n",
      " |          >>> net.apply(init_weights)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          Parameter containing:\n",
      " |          tensor([[1., 1.],\n",
      " |                  [1., 1.]], requires_grad=True)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          Parameter containing:\n",
      " |          tensor([[1., 1.],\n",
      " |                  [1., 1.]], requires_grad=True)\n",
      " |          Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          )\n",
      " |  \n",
      " |  bfloat16(self: ~T) -> ~T\n",
      " |      Casts all floating point parameters and buffers to ``bfloat16`` datatype.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  buffers(self, recurse: bool = True) -> Iterator[torch.Tensor]\n",
      " |      Returns an iterator over module buffers.\n",
      " |      \n",
      " |      Args:\n",
      " |          recurse (bool): if True, then yields buffers of this module\n",
      " |              and all submodules. Otherwise, yields only buffers that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          torch.Tensor: module buffer\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> # xdoctest: +SKIP(\"undefined vars\")\n",
      " |          >>> for buf in model.buffers():\n",
      " |          >>>     print(type(buf), buf.size())\n",
      " |          <class 'torch.Tensor'> (20L,)\n",
      " |          <class 'torch.Tensor'> (20L, 1L, 5L, 5L)\n",
      " |  \n",
      " |  children(self) -> Iterator[ForwardRef('Module')]\n",
      " |      Returns an iterator over immediate children modules.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Module: a child module\n",
      " |  \n",
      " |  cpu(self: ~T) -> ~T\n",
      " |      Moves all model parameters and buffers to the CPU.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  cuda(self: ~T, device: Union[int, torch.device, NoneType] = None) -> ~T\n",
      " |      Moves all model parameters and buffers to the GPU.\n",
      " |      \n",
      " |      This also makes associated parameters and buffers different objects. So\n",
      " |      it should be called before constructing optimizer if the module will\n",
      " |      live on GPU while being optimized.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Args:\n",
      " |          device (int, optional): if specified, all parameters will be\n",
      " |              copied to that device\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  double(self: ~T) -> ~T\n",
      " |      Casts all floating point parameters and buffers to ``double`` datatype.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  eval(self: ~T) -> ~T\n",
      " |      Sets the module in evaluation mode.\n",
      " |      \n",
      " |      This has any effect only on certain modules. See documentations of\n",
      " |      particular modules for details of their behaviors in training/evaluation\n",
      " |      mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\n",
      " |      etc.\n",
      " |      \n",
      " |      This is equivalent with :meth:`self.train(False) <torch.nn.Module.train>`.\n",
      " |      \n",
      " |      See :ref:`locally-disable-grad-doc` for a comparison between\n",
      " |      `.eval()` and several similar mechanisms that may be confused with it.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  float(self: ~T) -> ~T\n",
      " |      Casts all floating point parameters and buffers to ``float`` datatype.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  get_buffer(self, target: str) -> 'Tensor'\n",
      " |      Returns the buffer given by ``target`` if it exists,\n",
      " |      otherwise throws an error.\n",
      " |      \n",
      " |      See the docstring for ``get_submodule`` for a more detailed\n",
      " |      explanation of this method's functionality as well as how to\n",
      " |      correctly specify ``target``.\n",
      " |      \n",
      " |      Args:\n",
      " |          target: The fully-qualified string name of the buffer\n",
      " |              to look for. (See ``get_submodule`` for how to specify a\n",
      " |              fully-qualified string.)\n",
      " |      \n",
      " |      Returns:\n",
      " |          torch.Tensor: The buffer referenced by ``target``\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: If the target string references an invalid\n",
      " |              path or resolves to something that is not a\n",
      " |              buffer\n",
      " |  \n",
      " |  get_extra_state(self) -> Any\n",
      " |      Returns any extra state to include in the module's state_dict.\n",
      " |      Implement this and a corresponding :func:`set_extra_state` for your module\n",
      " |      if you need to store extra state. This function is called when building the\n",
      " |      module's `state_dict()`.\n",
      " |      \n",
      " |      Note that extra state should be pickleable to ensure working serialization\n",
      " |      of the state_dict. We only provide provide backwards compatibility guarantees\n",
      " |      for serializing Tensors; other objects may break backwards compatibility if\n",
      " |      their serialized pickled form changes.\n",
      " |      \n",
      " |      Returns:\n",
      " |          object: Any extra state to store in the module's state_dict\n",
      " |  \n",
      " |  get_parameter(self, target: str) -> 'Parameter'\n",
      " |      Returns the parameter given by ``target`` if it exists,\n",
      " |      otherwise throws an error.\n",
      " |      \n",
      " |      See the docstring for ``get_submodule`` for a more detailed\n",
      " |      explanation of this method's functionality as well as how to\n",
      " |      correctly specify ``target``.\n",
      " |      \n",
      " |      Args:\n",
      " |          target: The fully-qualified string name of the Parameter\n",
      " |              to look for. (See ``get_submodule`` for how to specify a\n",
      " |              fully-qualified string.)\n",
      " |      \n",
      " |      Returns:\n",
      " |          torch.nn.Parameter: The Parameter referenced by ``target``\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: If the target string references an invalid\n",
      " |              path or resolves to something that is not an\n",
      " |              ``nn.Parameter``\n",
      " |  \n",
      " |  get_submodule(self, target: str) -> 'Module'\n",
      " |      Returns the submodule given by ``target`` if it exists,\n",
      " |      otherwise throws an error.\n",
      " |      \n",
      " |      For example, let's say you have an ``nn.Module`` ``A`` that\n",
      " |      looks like this:\n",
      " |      \n",
      " |      .. code-block:: text\n",
      " |      \n",
      " |          A(\n",
      " |              (net_b): Module(\n",
      " |                  (net_c): Module(\n",
      " |                      (conv): Conv2d(16, 33, kernel_size=(3, 3), stride=(2, 2))\n",
      " |                  )\n",
      " |                  (linear): Linear(in_features=100, out_features=200, bias=True)\n",
      " |              )\n",
      " |          )\n",
      " |      \n",
      " |      (The diagram shows an ``nn.Module`` ``A``. ``A`` has a nested\n",
      " |      submodule ``net_b``, which itself has two submodules ``net_c``\n",
      " |      and ``linear``. ``net_c`` then has a submodule ``conv``.)\n",
      " |      \n",
      " |      To check whether or not we have the ``linear`` submodule, we\n",
      " |      would call ``get_submodule(\"net_b.linear\")``. To check whether\n",
      " |      we have the ``conv`` submodule, we would call\n",
      " |      ``get_submodule(\"net_b.net_c.conv\")``.\n",
      " |      \n",
      " |      The runtime of ``get_submodule`` is bounded by the degree\n",
      " |      of module nesting in ``target``. A query against\n",
      " |      ``named_modules`` achieves the same result, but it is O(N) in\n",
      " |      the number of transitive modules. So, for a simple check to see\n",
      " |      if some submodule exists, ``get_submodule`` should always be\n",
      " |      used.\n",
      " |      \n",
      " |      Args:\n",
      " |          target: The fully-qualified string name of the submodule\n",
      " |              to look for. (See above example for how to specify a\n",
      " |              fully-qualified string.)\n",
      " |      \n",
      " |      Returns:\n",
      " |          torch.nn.Module: The submodule referenced by ``target``\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: If the target string references an invalid\n",
      " |              path or resolves to something that is not an\n",
      " |              ``nn.Module``\n",
      " |  \n",
      " |  half(self: ~T) -> ~T\n",
      " |      Casts all floating point parameters and buffers to ``half`` datatype.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  ipu(self: ~T, device: Union[int, torch.device, NoneType] = None) -> ~T\n",
      " |      Moves all model parameters and buffers to the IPU.\n",
      " |      \n",
      " |      This also makes associated parameters and buffers different objects. So\n",
      " |      it should be called before constructing optimizer if the module will\n",
      " |      live on IPU while being optimized.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          device (int, optional): if specified, all parameters will be\n",
      " |              copied to that device\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  load_state_dict(self, state_dict: Mapping[str, Any], strict: bool = True)\n",
      " |      Copies parameters and buffers from :attr:`state_dict` into\n",
      " |      this module and its descendants. If :attr:`strict` is ``True``, then\n",
      " |      the keys of :attr:`state_dict` must exactly match the keys returned\n",
      " |      by this module's :meth:`~torch.nn.Module.state_dict` function.\n",
      " |      \n",
      " |      Args:\n",
      " |          state_dict (dict): a dict containing parameters and\n",
      " |              persistent buffers.\n",
      " |          strict (bool, optional): whether to strictly enforce that the keys\n",
      " |              in :attr:`state_dict` match the keys returned by this module's\n",
      " |              :meth:`~torch.nn.Module.state_dict` function. Default: ``True``\n",
      " |      \n",
      " |      Returns:\n",
      " |          ``NamedTuple`` with ``missing_keys`` and ``unexpected_keys`` fields:\n",
      " |              * **missing_keys** is a list of str containing the missing keys\n",
      " |              * **unexpected_keys** is a list of str containing the unexpected keys\n",
      " |      \n",
      " |      Note:\n",
      " |          If a parameter or buffer is registered as ``None`` and its corresponding key\n",
      " |          exists in :attr:`state_dict`, :meth:`load_state_dict` will raise a\n",
      " |          ``RuntimeError``.\n",
      " |  \n",
      " |  modules(self) -> Iterator[ForwardRef('Module')]\n",
      " |      Returns an iterator over all modules in the network.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Module: a module in the network\n",
      " |      \n",
      " |      Note:\n",
      " |          Duplicate modules are returned only once. In the following\n",
      " |          example, ``l`` will be returned only once.\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> l = nn.Linear(2, 2)\n",
      " |          >>> net = nn.Sequential(l, l)\n",
      " |          >>> for idx, m in enumerate(net.modules()):\n",
      " |          ...     print(idx, '->', m)\n",
      " |      \n",
      " |          0 -> Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          )\n",
      " |          1 -> Linear(in_features=2, out_features=2, bias=True)\n",
      " |  \n",
      " |  named_buffers(self, prefix: str = '', recurse: bool = True) -> Iterator[Tuple[str, torch.Tensor]]\n",
      " |      Returns an iterator over module buffers, yielding both the\n",
      " |      name of the buffer as well as the buffer itself.\n",
      " |      \n",
      " |      Args:\n",
      " |          prefix (str): prefix to prepend to all buffer names.\n",
      " |          recurse (bool): if True, then yields buffers of this module\n",
      " |              and all submodules. Otherwise, yields only buffers that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (str, torch.Tensor): Tuple containing the name and buffer\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> # xdoctest: +SKIP(\"undefined vars\")\n",
      " |          >>> for name, buf in self.named_buffers():\n",
      " |          >>>    if name in ['running_var']:\n",
      " |          >>>        print(buf.size())\n",
      " |  \n",
      " |  named_children(self) -> Iterator[Tuple[str, ForwardRef('Module')]]\n",
      " |      Returns an iterator over immediate children modules, yielding both\n",
      " |      the name of the module as well as the module itself.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (str, Module): Tuple containing a name and child module\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> # xdoctest: +SKIP(\"undefined vars\")\n",
      " |          >>> for name, module in model.named_children():\n",
      " |          >>>     if name in ['conv4', 'conv5']:\n",
      " |          >>>         print(module)\n",
      " |  \n",
      " |  named_modules(self, memo: Optional[Set[ForwardRef('Module')]] = None, prefix: str = '', remove_duplicate: bool = True)\n",
      " |      Returns an iterator over all modules in the network, yielding\n",
      " |      both the name of the module as well as the module itself.\n",
      " |      \n",
      " |      Args:\n",
      " |          memo: a memo to store the set of modules already added to the result\n",
      " |          prefix: a prefix that will be added to the name of the module\n",
      " |          remove_duplicate: whether to remove the duplicated module instances in the result\n",
      " |              or not\n",
      " |      \n",
      " |      Yields:\n",
      " |          (str, Module): Tuple of name and module\n",
      " |      \n",
      " |      Note:\n",
      " |          Duplicate modules are returned only once. In the following\n",
      " |          example, ``l`` will be returned only once.\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> l = nn.Linear(2, 2)\n",
      " |          >>> net = nn.Sequential(l, l)\n",
      " |          >>> for idx, m in enumerate(net.named_modules()):\n",
      " |          ...     print(idx, '->', m)\n",
      " |      \n",
      " |          0 -> ('', Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          ))\n",
      " |          1 -> ('0', Linear(in_features=2, out_features=2, bias=True))\n",
      " |  \n",
      " |  named_parameters(self, prefix: str = '', recurse: bool = True) -> Iterator[Tuple[str, torch.nn.parameter.Parameter]]\n",
      " |      Returns an iterator over module parameters, yielding both the\n",
      " |      name of the parameter as well as the parameter itself.\n",
      " |      \n",
      " |      Args:\n",
      " |          prefix (str): prefix to prepend to all parameter names.\n",
      " |          recurse (bool): if True, then yields parameters of this module\n",
      " |              and all submodules. Otherwise, yields only parameters that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (str, Parameter): Tuple containing the name and parameter\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> # xdoctest: +SKIP(\"undefined vars\")\n",
      " |          >>> for name, param in self.named_parameters():\n",
      " |          >>>    if name in ['bias']:\n",
      " |          >>>        print(param.size())\n",
      " |  \n",
      " |  parameters(self, recurse: bool = True) -> Iterator[torch.nn.parameter.Parameter]\n",
      " |      Returns an iterator over module parameters.\n",
      " |      \n",
      " |      This is typically passed to an optimizer.\n",
      " |      \n",
      " |      Args:\n",
      " |          recurse (bool): if True, then yields parameters of this module\n",
      " |              and all submodules. Otherwise, yields only parameters that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Parameter: module parameter\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> # xdoctest: +SKIP(\"undefined vars\")\n",
      " |          >>> for param in model.parameters():\n",
      " |          >>>     print(type(param), param.size())\n",
      " |          <class 'torch.Tensor'> (20L,)\n",
      " |          <class 'torch.Tensor'> (20L, 1L, 5L, 5L)\n",
      " |  \n",
      " |  register_backward_hook(self, hook: Callable[[ForwardRef('Module'), Union[Tuple[torch.Tensor, ...], torch.Tensor], Union[Tuple[torch.Tensor, ...], torch.Tensor]], Optional[torch.Tensor]]) -> torch.utils.hooks.RemovableHandle\n",
      " |      Registers a backward hook on the module.\n",
      " |      \n",
      " |      This function is deprecated in favor of :meth:`~torch.nn.Module.register_full_backward_hook` and\n",
      " |      the behavior of this function will change in future versions.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_buffer(self, name: str, tensor: Optional[torch.Tensor], persistent: bool = True) -> None\n",
      " |      Adds a buffer to the module.\n",
      " |      \n",
      " |      This is typically used to register a buffer that should not to be\n",
      " |      considered a model parameter. For example, BatchNorm's ``running_mean``\n",
      " |      is not a parameter, but is part of the module's state. Buffers, by\n",
      " |      default, are persistent and will be saved alongside parameters. This\n",
      " |      behavior can be changed by setting :attr:`persistent` to ``False``. The\n",
      " |      only difference between a persistent buffer and a non-persistent buffer\n",
      " |      is that the latter will not be a part of this module's\n",
      " |      :attr:`state_dict`.\n",
      " |      \n",
      " |      Buffers can be accessed as attributes using given names.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (str): name of the buffer. The buffer can be accessed\n",
      " |              from this module using the given name\n",
      " |          tensor (Tensor or None): buffer to be registered. If ``None``, then operations\n",
      " |              that run on buffers, such as :attr:`cuda`, are ignored. If ``None``,\n",
      " |              the buffer is **not** included in the module's :attr:`state_dict`.\n",
      " |          persistent (bool): whether the buffer is part of this module's\n",
      " |              :attr:`state_dict`.\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> # xdoctest: +SKIP(\"undefined vars\")\n",
      " |          >>> self.register_buffer('running_mean', torch.zeros(num_features))\n",
      " |  \n",
      " |  register_forward_hook(self, hook: Callable[..., NoneType]) -> torch.utils.hooks.RemovableHandle\n",
      " |      Registers a forward hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time after :func:`forward` has computed an output.\n",
      " |      It should have the following signature::\n",
      " |      \n",
      " |          hook(module, input, output) -> None or modified output\n",
      " |      \n",
      " |      The input contains only the positional arguments given to the module.\n",
      " |      Keyword arguments won't be passed to the hooks and only to the ``forward``.\n",
      " |      The hook can modify the output. It can modify the input inplace but\n",
      " |      it will not have effect on forward since this is called after\n",
      " |      :func:`forward` is called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_forward_pre_hook(self, hook: Callable[..., NoneType]) -> torch.utils.hooks.RemovableHandle\n",
      " |      Registers a forward pre-hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time before :func:`forward` is invoked.\n",
      " |      It should have the following signature::\n",
      " |      \n",
      " |          hook(module, input) -> None or modified input\n",
      " |      \n",
      " |      The input contains only the positional arguments given to the module.\n",
      " |      Keyword arguments won't be passed to the hooks and only to the ``forward``.\n",
      " |      The hook can modify the input. User can either return a tuple or a\n",
      " |      single modified value in the hook. We will wrap the value into a tuple\n",
      " |      if a single value is returned(unless that value is already a tuple).\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_full_backward_hook(self, hook: Callable[[ForwardRef('Module'), Union[Tuple[torch.Tensor, ...], torch.Tensor], Union[Tuple[torch.Tensor, ...], torch.Tensor]], Optional[torch.Tensor]]) -> torch.utils.hooks.RemovableHandle\n",
      " |      Registers a backward hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time the gradients with respect to a module\n",
      " |      are computed, i.e. the hook will execute if and only if the gradients with\n",
      " |      respect to module outputs are computed. The hook should have the following\n",
      " |      signature::\n",
      " |      \n",
      " |          hook(module, grad_input, grad_output) -> tuple(Tensor) or None\n",
      " |      \n",
      " |      The :attr:`grad_input` and :attr:`grad_output` are tuples that contain the gradients\n",
      " |      with respect to the inputs and outputs respectively. The hook should\n",
      " |      not modify its arguments, but it can optionally return a new gradient with\n",
      " |      respect to the input that will be used in place of :attr:`grad_input` in\n",
      " |      subsequent computations. :attr:`grad_input` will only correspond to the inputs given\n",
      " |      as positional arguments and all kwarg arguments are ignored. Entries\n",
      " |      in :attr:`grad_input` and :attr:`grad_output` will be ``None`` for all non-Tensor\n",
      " |      arguments.\n",
      " |      \n",
      " |      For technical reasons, when this hook is applied to a Module, its forward function will\n",
      " |      receive a view of each Tensor passed to the Module. Similarly the caller will receive a view\n",
      " |      of each Tensor returned by the Module's forward function.\n",
      " |      \n",
      " |      .. warning ::\n",
      " |          Modifying inputs or outputs inplace is not allowed when using backward hooks and\n",
      " |          will raise an error.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_load_state_dict_post_hook(self, hook)\n",
      " |      Registers a post hook to be run after module's ``load_state_dict``\n",
      " |      is called.\n",
      " |      \n",
      " |      It should have the following signature::\n",
      " |          hook(module, incompatible_keys) -> None\n",
      " |      \n",
      " |      The ``module`` argument is the current module that this hook is registered\n",
      " |      on, and the ``incompatible_keys`` argument is a ``NamedTuple`` consisting\n",
      " |      of attributes ``missing_keys`` and ``unexpected_keys``. ``missing_keys``\n",
      " |      is a ``list`` of ``str`` containing the missing keys and\n",
      " |      ``unexpected_keys`` is a ``list`` of ``str`` containing the unexpected keys.\n",
      " |      \n",
      " |      The given incompatible_keys can be modified inplace if needed.\n",
      " |      \n",
      " |      Note that the checks performed when calling :func:`load_state_dict` with\n",
      " |      ``strict=True`` are affected by modifications the hook makes to\n",
      " |      ``missing_keys`` or ``unexpected_keys``, as expected. Additions to either\n",
      " |      set of keys will result in an error being thrown when ``strict=True``, and\n",
      " |      clearning out both missing and unexpected keys will avoid an error.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_module(self, name: str, module: Optional[ForwardRef('Module')]) -> None\n",
      " |      Alias for :func:`add_module`.\n",
      " |  \n",
      " |  register_parameter(self, name: str, param: Optional[torch.nn.parameter.Parameter]) -> None\n",
      " |      Adds a parameter to the module.\n",
      " |      \n",
      " |      The parameter can be accessed as an attribute using given name.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (str): name of the parameter. The parameter can be accessed\n",
      " |              from this module using the given name\n",
      " |          param (Parameter or None): parameter to be added to the module. If\n",
      " |              ``None``, then operations that run on parameters, such as :attr:`cuda`,\n",
      " |              are ignored. If ``None``, the parameter is **not** included in the\n",
      " |              module's :attr:`state_dict`.\n",
      " |  \n",
      " |  requires_grad_(self: ~T, requires_grad: bool = True) -> ~T\n",
      " |      Change if autograd should record operations on parameters in this\n",
      " |      module.\n",
      " |      \n",
      " |      This method sets the parameters' :attr:`requires_grad` attributes\n",
      " |      in-place.\n",
      " |      \n",
      " |      This method is helpful for freezing part of the module for finetuning\n",
      " |      or training parts of a model individually (e.g., GAN training).\n",
      " |      \n",
      " |      See :ref:`locally-disable-grad-doc` for a comparison between\n",
      " |      `.requires_grad_()` and several similar mechanisms that may be confused with it.\n",
      " |      \n",
      " |      Args:\n",
      " |          requires_grad (bool): whether autograd should record operations on\n",
      " |                                parameters in this module. Default: ``True``.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  set_extra_state(self, state: Any)\n",
      " |      This function is called from :func:`load_state_dict` to handle any extra state\n",
      " |      found within the `state_dict`. Implement this function and a corresponding\n",
      " |      :func:`get_extra_state` for your module if you need to store extra state within its\n",
      " |      `state_dict`.\n",
      " |      \n",
      " |      Args:\n",
      " |          state (dict): Extra state from the `state_dict`\n",
      " |  \n",
      " |  share_memory(self: ~T) -> ~T\n",
      " |      See :meth:`torch.Tensor.share_memory_`\n",
      " |  \n",
      " |  state_dict(self, *args, destination=None, prefix='', keep_vars=False)\n",
      " |      Returns a dictionary containing references to the whole state of the module.\n",
      " |      \n",
      " |      Both parameters and persistent buffers (e.g. running averages) are\n",
      " |      included. Keys are corresponding parameter and buffer names.\n",
      " |      Parameters and buffers set to ``None`` are not included.\n",
      " |      \n",
      " |      .. note::\n",
      " |          The returned object is a shallow copy. It contains references\n",
      " |          to the module's parameters and buffers.\n",
      " |      \n",
      " |      .. warning::\n",
      " |          Currently ``state_dict()`` also accepts positional arguments for\n",
      " |          ``destination``, ``prefix`` and ``keep_vars`` in order. However,\n",
      " |          this is being deprecated and keyword arguments will be enforced in\n",
      " |          future releases.\n",
      " |      \n",
      " |      .. warning::\n",
      " |          Please avoid the use of argument ``destination`` as it is not\n",
      " |          designed for end-users.\n",
      " |      \n",
      " |      Args:\n",
      " |          destination (dict, optional): If provided, the state of module will\n",
      " |              be updated into the dict and the same object is returned.\n",
      " |              Otherwise, an ``OrderedDict`` will be created and returned.\n",
      " |              Default: ``None``.\n",
      " |          prefix (str, optional): a prefix added to parameter and buffer\n",
      " |              names to compose the keys in state_dict. Default: ``''``.\n",
      " |          keep_vars (bool, optional): by default the :class:`~torch.Tensor` s\n",
      " |              returned in the state dict are detached from autograd. If it's\n",
      " |              set to ``True``, detaching will not be performed.\n",
      " |              Default: ``False``.\n",
      " |      \n",
      " |      Returns:\n",
      " |          dict:\n",
      " |              a dictionary containing a whole state of the module\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> # xdoctest: +SKIP(\"undefined vars\")\n",
      " |          >>> module.state_dict().keys()\n",
      " |          ['bias', 'weight']\n",
      " |  \n",
      " |  to(self, *args, **kwargs)\n",
      " |      Moves and/or casts the parameters and buffers.\n",
      " |      \n",
      " |      This can be called as\n",
      " |      \n",
      " |      .. function:: to(device=None, dtype=None, non_blocking=False)\n",
      " |         :noindex:\n",
      " |      \n",
      " |      .. function:: to(dtype, non_blocking=False)\n",
      " |         :noindex:\n",
      " |      \n",
      " |      .. function:: to(tensor, non_blocking=False)\n",
      " |         :noindex:\n",
      " |      \n",
      " |      .. function:: to(memory_format=torch.channels_last)\n",
      " |         :noindex:\n",
      " |      \n",
      " |      Its signature is similar to :meth:`torch.Tensor.to`, but only accepts\n",
      " |      floating point or complex :attr:`dtype`\\ s. In addition, this method will\n",
      " |      only cast the floating point or complex parameters and buffers to :attr:`dtype`\n",
      " |      (if given). The integral parameters and buffers will be moved\n",
      " |      :attr:`device`, if that is given, but with dtypes unchanged. When\n",
      " |      :attr:`non_blocking` is set, it tries to convert/move asynchronously\n",
      " |      with respect to the host if possible, e.g., moving CPU Tensors with\n",
      " |      pinned memory to CUDA devices.\n",
      " |      \n",
      " |      See below for examples.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Args:\n",
      " |          device (:class:`torch.device`): the desired device of the parameters\n",
      " |              and buffers in this module\n",
      " |          dtype (:class:`torch.dtype`): the desired floating point or complex dtype of\n",
      " |              the parameters and buffers in this module\n",
      " |          tensor (torch.Tensor): Tensor whose dtype and device are the desired\n",
      " |              dtype and device for all parameters and buffers in this module\n",
      " |          memory_format (:class:`torch.memory_format`): the desired memory\n",
      " |              format for 4D parameters and buffers in this module (keyword\n",
      " |              only argument)\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |      \n",
      " |      Examples::\n",
      " |      \n",
      " |          >>> # xdoctest: +IGNORE_WANT(\"non-deterministic\")\n",
      " |          >>> linear = nn.Linear(2, 2)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1913, -0.3420],\n",
      " |                  [-0.5113, -0.2325]])\n",
      " |          >>> linear.to(torch.double)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1913, -0.3420],\n",
      " |                  [-0.5113, -0.2325]], dtype=torch.float64)\n",
      " |          >>> # xdoctest: +REQUIRES(env:TORCH_DOCTEST_CUDA1)\n",
      " |          >>> gpu1 = torch.device(\"cuda:1\")\n",
      " |          >>> linear.to(gpu1, dtype=torch.half, non_blocking=True)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1914, -0.3420],\n",
      " |                  [-0.5112, -0.2324]], dtype=torch.float16, device='cuda:1')\n",
      " |          >>> cpu = torch.device(\"cpu\")\n",
      " |          >>> linear.to(cpu)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1914, -0.3420],\n",
      " |                  [-0.5112, -0.2324]], dtype=torch.float16)\n",
      " |      \n",
      " |          >>> linear = nn.Linear(2, 2, bias=None).to(torch.cdouble)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.3741+0.j,  0.2382+0.j],\n",
      " |                  [ 0.5593+0.j, -0.4443+0.j]], dtype=torch.complex128)\n",
      " |          >>> linear(torch.ones(3, 2, dtype=torch.cdouble))\n",
      " |          tensor([[0.6122+0.j, 0.1150+0.j],\n",
      " |                  [0.6122+0.j, 0.1150+0.j],\n",
      " |                  [0.6122+0.j, 0.1150+0.j]], dtype=torch.complex128)\n",
      " |  \n",
      " |  to_empty(self: ~T, *, device: Union[str, torch.device]) -> ~T\n",
      " |      Moves the parameters and buffers to the specified device without copying storage.\n",
      " |      \n",
      " |      Args:\n",
      " |          device (:class:`torch.device`): The desired device of the parameters\n",
      " |              and buffers in this module.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  train(self: ~T, mode: bool = True) -> ~T\n",
      " |      Sets the module in training mode.\n",
      " |      \n",
      " |      This has any effect only on certain modules. See documentations of\n",
      " |      particular modules for details of their behaviors in training/evaluation\n",
      " |      mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\n",
      " |      etc.\n",
      " |      \n",
      " |      Args:\n",
      " |          mode (bool): whether to set training mode (``True``) or evaluation\n",
      " |                       mode (``False``). Default: ``True``.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  type(self: ~T, dst_type: Union[torch.dtype, str]) -> ~T\n",
      " |      Casts all parameters and buffers to :attr:`dst_type`.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Args:\n",
      " |          dst_type (type or string): the desired type\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  xpu(self: ~T, device: Union[int, torch.device, NoneType] = None) -> ~T\n",
      " |      Moves all model parameters and buffers to the XPU.\n",
      " |      \n",
      " |      This also makes associated parameters and buffers different objects. So\n",
      " |      it should be called before constructing optimizer if the module will\n",
      " |      live on XPU while being optimized.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          device (int, optional): if specified, all parameters will be\n",
      " |              copied to that device\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  zero_grad(self, set_to_none: bool = False) -> None\n",
      " |      Sets gradients of all model parameters to zero. See similar function\n",
      " |      under :class:`torch.optim.Optimizer` for more context.\n",
      " |      \n",
      " |      Args:\n",
      " |          set_to_none (bool): instead of setting to zero, set the grads to None.\n",
      " |              See :meth:`torch.optim.Optimizer.zero_grad` for details.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  T_destination = ~T_destination\n",
      " |  \n",
      " |  dump_patches = False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(torch.nn.LayerNorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "1024e561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on Mojave-pku implementation \n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "                 helper,\n",
    "                 class_num,\n",
    "                 hidden_size_node,\n",
    "                 n_gram,\n",
    "                 drop_out,\n",
    "                 edges_num,\n",
    "                 edges_matrix,\n",
    "                 embeddings_file,\n",
    "                 device,\n",
    "                 max_length=512,\n",
    "                 trainable_edges=True,\n",
    "                 pmi=None,\n",
    "                 #cuda=True,\n",
    "                 ):\n",
    "        \n",
    "        super(Model, self).__init__()\n",
    "        self.helper = helper\n",
    "        self.device = device\n",
    "        #self.is_cuda = cuda\n",
    "        self.vocab = self.helper.vocab\n",
    "        print(len(self.vocab))\n",
    "        self.seq_edge_w = torch.nn.Embedding(edges_num, 1)\n",
    "        print(edges_num)\n",
    "        print(pmi.shape) # is this edges_mapping?\n",
    "        \n",
    "        self.node_hidden = torch.nn.Embedding(len(self.vocab), hidden_size_node)\n",
    "        self.edges_num = edges_num\n",
    "        if trainable_edges:\n",
    "            self.seq_edge_w = torch.nn.Embedding.from_pretrained(torch.ones(edges_num, 1), freeze=False)\n",
    "        else:\n",
    "            self.seq_edge_w = torch.nn.Embedding.from_pretrained(pmi, freeze=True)\n",
    "        self.hidden_size_node = hidden_size_node\n",
    "        self.node_hidden.weight.data.copy_(torch.tensor(self.load_embeddings(embeddings_file)))\n",
    "        self.node_hidden.weight.requires_grad = True\n",
    "\n",
    "        self.len_vocab = len(self.vocab)\n",
    "        self.ngram = n_gram\n",
    "        self.d = helper.d\n",
    "        self.max_length = max_length\n",
    "        self.edges_matrix = edges_matrix\n",
    "        self.dropout = torch.nn.Dropout(p=drop_out)\n",
    "        self.activation = torch.nn.ReLU()\n",
    "        self.norm = torch.nn.LayerNorm([self.hidden_size_node])\n",
    "        # what does bias = True do below?\n",
    "        self.Linear = torch.nn.Linear(hidden_size_node, class_num, bias=True)\n",
    "\n",
    "    def word2id(self, word):\n",
    "        result = self.helper.word2id(word)\n",
    "        return result\n",
    "    \n",
    "    def load_embeddings(self, embeddings_file): \n",
    "        '''\n",
    "        Retrieves GloVe embeddings for each token in the vocab\n",
    "        '''\n",
    "        embeddings = OrderedDict({a:[] for a in self.vocab})\n",
    "        with open(embeddings_file, 'r') as f:\n",
    "            for line in f:\n",
    "                values = line.split()\n",
    "                word = values[0]\n",
    "                vector = np.asarray(values[1:], \"float32\")\n",
    "                if word in embeddings.keys():\n",
    "                    embeddings[word] = vector\n",
    "                else:\n",
    "                    continue #print(word, ' not in vocabulary.')\n",
    "\n",
    "        for a in embeddings.keys():\n",
    "            if len(embeddings[a]) == 0:\n",
    "                embeddings[a] = embeddings['the']\n",
    "\n",
    "        embeddings = np.array([embeddings[a] for a in embeddings.keys()])\n",
    "\n",
    "        return embeddings\n",
    "\n",
    "    def add_all_edges(self, doc_ids: list, old_to_new: dict):\n",
    "        edges = []\n",
    "        old_edge_id = []\n",
    "\n",
    "        local_vocab = list(set(doc_ids))\n",
    "\n",
    "        for i, src_word_old in enumerate(local_vocab):\n",
    "            src = old_to_new[src_word_old]\n",
    "            for dst_word_old in local_vocab[i:]:\n",
    "                dst = old_to_new[dst_word_old]\n",
    "                edges.append([src, dst])\n",
    "                old_edge_id.append(self.edges_matrix[src_word_old, dst_word_old])\n",
    "\n",
    "            # self circle\n",
    "            edges.append([src, src])\n",
    "            old_edge_id.append(self.edges_matrix[src_word_old, src_word_old])\n",
    "\n",
    "        return edges, old_edge_id\n",
    "\n",
    "    def add_seq_edges(self, doc_ids: list, old_to_new: dict):\n",
    "        edges = []\n",
    "        old_edge_id = []\n",
    "        for index, src_word_old in enumerate(doc_ids):\n",
    "            src = old_to_new[src_word_old]\n",
    "            for i in range(max(0, index - self.ngram), min(index + self.ngram + 1, len(doc_ids))):\n",
    "                dst_word_old = doc_ids[i]\n",
    "                dst = old_to_new[dst_word_old]\n",
    "\n",
    "                # - first connect the new sub_graph\n",
    "                edges.append([src, dst])\n",
    "                # - then get the hidden from parent_graph\n",
    "                old_edge_id.append(self.edges_matrix[src_word_old, dst_word_old]) \n",
    "\n",
    "            # self circle\n",
    "            edges.append([src, src])\n",
    "            old_edge_id.append(self.edges_matrix[src_word_old, src_word_old])\n",
    "\n",
    "        return edges, old_edge_id\n",
    "\n",
    "    def seq_to_graph(self, doc_ids: list) -> dgl.DGLGraph():\n",
    "        '''\n",
    "        input: one document with integer IDs\n",
    "        output: DGL graph object\n",
    "        '''\n",
    "        if len(doc_ids) > self.max_length:\n",
    "            doc_ids = doc_ids[:self.max_length]\n",
    "\n",
    "        local_vocab = set(doc_ids) # unique words in the training sample\n",
    "\n",
    "        old_to_new = dict(zip(local_vocab, range(len(local_vocab))))\n",
    "\n",
    "        #if self.is_cuda:\n",
    "        local_vocab = torch.tensor(list(local_vocab))#.to(device)\n",
    "        #else:\n",
    "        #    local_vocab = torch.tensor(list(local_vocab))\n",
    "\n",
    "        sub_graph = dgl.DGLGraph()#.to(device) dgl.graph()\n",
    "\n",
    "        sub_graph.add_nodes(len(local_vocab))\n",
    "        local_node_hidden = self.node_hidden(local_vocab) # GloVe embeddings \n",
    "\n",
    "        sub_graph.ndata['h'] = local_node_hidden#.to(device)\n",
    "\n",
    "        seq_edges, seq_old_edges_id = self.add_seq_edges(doc_ids, old_to_new)\n",
    "\n",
    "        edges, old_edge_id = [], []\n",
    "        # edges = []\n",
    "\n",
    "        edges.extend(seq_edges)\n",
    "\n",
    "        old_edge_id.extend(seq_old_edges_id)\n",
    "\n",
    "        #if self.is_cuda:\n",
    "        old_edge_id = torch.LongTensor(old_edge_id)#.to(device)\n",
    "        #else:\n",
    "        #    old_edge_id = torch.LongTensor(old_edge_id)\n",
    "\n",
    "        srcs, dsts = zip(*edges)\n",
    "        sub_graph.add_edges(srcs, dsts)\n",
    "        try:\n",
    "            seq_edges_w = self.seq_edge_w(old_edge_id)\n",
    "        except RuntimeError:\n",
    "            print(old_edge_id)\n",
    "        sub_graph.edata['w'] = seq_edges_w\n",
    "        \n",
    "        return sub_graph.to(device)\n",
    "\n",
    "    def forward(self, doc_ids, is_20ng=None, debug = False):\n",
    "        sub_graphs = [self.seq_to_graph(doc) for doc in doc_ids]\n",
    "\n",
    "        batch_graph = dgl.batch(sub_graphs)\n",
    "\n",
    "        batch_graph.update_all(\n",
    "            message_func=dgl.function.src_mul_edge('h', 'w', 'weighted_message'),\n",
    "            reduce_func=dgl.function.max('weighted_message', 'h')\n",
    "        )\n",
    "\n",
    "        h1 = dgl.sum_nodes(batch_graph, feat='h')\n",
    "        norm = self.norm(h1)\n",
    "        drop1 = self.dropout(norm)\n",
    "        act1 = self.activation(drop1)\n",
    "\n",
    "        l = self.Linear(act1)\n",
    "        if debug:\n",
    "            return l, act1, drop1, norm, h1, batch_graph, sub_graphs\n",
    "        else:\n",
    "            return l\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699248b3",
   "metadata": {},
   "source": [
    "Go through the forward pass and add Layer Normalization\n",
    "Is sum_nodes a sufficient operation? Why not put a linear layer here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "e8b50efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample, _, _ = next(train_data_helper.batch_iter(2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "c2637cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "l, act1, drop1, norm, h1, batch_graph, sub_graphs = model(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "41c58fca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 300])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act1.shape # very high values or zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "f04ad3d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.7249,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.5484,  0.0000,  0.0000,\n",
       "          1.1795,  1.1837,  0.0000,  0.0000,  0.0000,  1.5260,  1.6571,  0.0000,\n",
       "          0.0000,  0.6131,  0.9697,  0.0000,  0.0000,  0.7204,  0.0000,  0.0000,\n",
       "          0.0000,  0.4228,  0.0000,  2.0536,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.7786,  1.4657,  2.2753,  1.1049,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  1.5134,  0.1671,  2.4371,  0.0000,  0.0000,  1.6488,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1959,\n",
       "          0.0000,  1.4599,  0.0000,  0.3722,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  6.3884,  0.2336,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  1.0547,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  1.1471,  0.0000,  0.0000,  0.0000,  0.0000,  0.4914,\n",
       "          0.0000,  0.0000,  1.4383,  1.2096,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  1.2584,  0.0000,  0.0000,  0.0000,  0.0000,  0.3120,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.2014,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  6.2024,  0.0000,\n",
       "          0.0000,  0.0000,  2.0668,  0.0000,  0.0000,  0.0000,  1.4539,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  2.0261,\n",
       "          0.0000,  0.0000,  0.0000,  2.4978,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  3.2660,  0.0000,  1.4178,  0.0000,  0.1265,\n",
       "          0.5421,  0.0000,  3.4508,  0.0000,  0.0000,  3.9595,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  2.0195,  0.0698,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  3.2874,  0.0000,  0.2026,\n",
       "          3.0598,  0.0000,  0.0000,  0.2092,  1.0003,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.6227,  0.0000,  1.8722,  0.0000,  0.0000,  0.0000,  0.0000,  0.1493,\n",
       "          0.0000,  0.0000,  0.2364,  0.0000,  0.0000,  0.5375,  4.7272,  2.1459,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.2452,  0.0000,\n",
       "          0.0000,  1.3782,  0.0000,  0.0000,  0.0000,  1.4511,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  4.9614,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.5628,  0.0000,  0.0000,  0.0000,  0.3743,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  2.1109],\n",
       "        [ 0.0000,  0.7122,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0985,  0.0000,  0.1831,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.2569,  0.9240,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.8438,\n",
       "          0.0000,  0.0000,  0.4394,  0.0000,  0.0000,  0.0000,  2.8843,  1.4208,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  2.2655,\n",
       "          0.2983,  0.0000,  1.7437,  0.0000,  2.5195,  0.0000,  1.4191,  1.5460,\n",
       "          0.0000,  0.0000,  0.0000,  1.1055,  0.0000,  0.0000,  0.0000,  0.1954,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  1.9581,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  1.4053,  0.0000,  0.2403,  0.0000,  0.0000,  0.8529,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.2155,  0.0000,  0.0000,\n",
       "          0.0000,  0.3436,  2.3733,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  2.8775,  0.0472,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.3919,\n",
       "          0.0000,  0.0000,  0.0000,  2.6233,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  1.0640,  0.0000,  1.0614,  0.0000,\n",
       "          0.0000,  0.0000,  0.3125,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  2.7292,  0.0000,  0.0000,  0.0000,  1.5525,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.4502,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.2117,  0.0000,  0.0000,  1.4044,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.9019,  1.4219,  0.0000,  0.0000,\n",
       "          0.0478,  0.0000,  0.0000,  0.0000,  0.5617,  2.2457,  0.0000,  2.5663,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1543,  0.5026,\n",
       "         15.8781,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          2.1363,  0.0000,  0.9917,  0.0000,  0.0000,  0.0000,  0.0000,  0.7694,\n",
       "          0.4116,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  1.8801,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  3.4563,  0.0000,  0.0000,  0.0000,  0.0000,  0.4838,\n",
       "          0.0000,  0.0000,  0.0945,  0.0000,  0.0000,  0.3765,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.1790,  0.0000,  0.0000,  0.8598,  0.0696,\n",
       "          0.9017,  0.0000,  0.0000,  0.3386,  0.0000,  0.8495,  0.0000,  0.0000,\n",
       "          0.0733,  0.4329,  0.1223,  0.0000,  0.0000,  1.6899,  0.0000,  1.3812,\n",
       "          0.0000,  0.0000,  0.0000,  0.7635,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.9434,  0.0000,  0.0000,  0.0000,  0.0000,  0.2923, -0.0000,  0.0000,\n",
       "          0.1837,  0.0000,  0.0000,  0.0000]], grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "aad9ca5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-4.3536e-01,  3.6243e-01, -1.3241e+00, -9.7232e-01, -4.7215e-01,\n",
       "          1.7033e-01,  7.4182e-02,  7.7876e-01,  5.6975e-01, -4.6193e+00,\n",
       "          3.7180e-01, -2.0010e-01, -1.2066e+00,  2.7422e-01,  2.6186e-02,\n",
       "          3.7196e-01,  5.8974e-01,  5.9184e-01,  1.4899e-01,  3.0590e-01,\n",
       "          1.1217e-01,  7.6300e-01,  8.2854e-01,  4.9544e-01, -8.6054e-01,\n",
       "          3.0653e-01,  4.8483e-01, -4.7080e-01,  9.1680e-01,  3.6021e-01,\n",
       "         -7.0319e-01,  6.9038e-01, -8.6056e-01,  2.1142e-01, -2.9365e+00,\n",
       "          1.0268e+00, -2.3977e-01, -9.2623e-01, -5.9378e-01,  1.5448e-01,\n",
       "         -3.4534e-02, -6.5374e-01, -2.7875e-01,  5.3590e-01,  3.8928e-01,\n",
       "          7.3284e-01,  1.1377e+00,  5.5245e-01, -1.0027e+00, -6.5386e-01,\n",
       "          5.1745e-02, -7.9026e-01, -4.5558e-01, -8.0277e-02, -1.1798e+00,\n",
       "          7.3760e-01, -2.0995e-01,  1.1770e-01,  7.5672e-01,  8.3537e-02,\n",
       "          1.2185e+00, -3.7468e-01,  1.0478e+00,  8.2440e-01, -5.2329e-01,\n",
       "         -5.5384e-01,  7.4127e-01,  4.0094e-01,  1.8984e-01,  4.9418e-01,\n",
       "          1.5648e-01,  9.7932e-02, -1.0840e+00,  7.2996e-01, -2.9744e-01,\n",
       "          1.8608e-01,  5.9000e-01,  1.3780e-01, -9.3485e-01,  1.3324e-01,\n",
       "         -3.5642e-01,  1.3295e+00,  3.1942e+00,  1.1681e-01, -8.9939e-02,\n",
       "         -3.4492e-01, -5.7168e-02,  7.6648e-01, -5.1527e-01, -7.3888e-01,\n",
       "          6.0666e-01,  5.2737e-01, -1.0189e+00, -1.0880e+00,  1.7248e-01,\n",
       "         -6.6559e-01, -1.0700e+00, -9.5952e-02,  5.2823e-01, -1.5619e+00,\n",
       "         -4.6331e-01, -4.5049e-01, -3.6144e-02, -1.0335e-01, -6.6199e-01,\n",
       "         -4.3831e-01,  5.7355e-01,  1.2228e+00, -6.1631e-01,  1.9789e-01,\n",
       "         -7.0512e-01,  2.4571e-01, -9.8723e-01, -1.4598e-02,  7.1915e-01,\n",
       "          6.0481e-01, -7.8547e-01,  3.4276e-01, -2.1900e-01, -1.5222e+00,\n",
       "         -9.4775e-01, -2.1468e-01,  6.2922e-01,  5.7315e-01, -9.4238e-01,\n",
       "         -5.7211e-01, -2.2830e-01,  1.5599e-01, -4.1132e-01, -1.2408e-01,\n",
       "          7.0185e-01,  1.2955e+00,  2.7764e-02, -3.2138e-01, -9.7085e-01,\n",
       "         -7.8784e-01, -6.7023e-01, -2.1903e-01,  1.9880e-01, -1.0592e-01,\n",
       "          1.0070e-01,  2.7497e-03, -4.0861e-02,  2.0834e-01, -1.0655e+00,\n",
       "          6.3801e-01, -4.6750e-01, -1.4369e-01, -3.9505e-01, -4.4295e-01,\n",
       "          3.1012e+00,  6.2024e-02, -2.1291e-01, -2.8656e-02,  1.0334e+00,\n",
       "          2.6448e-02, -4.8537e-01, -7.5501e-01,  7.2697e-01, -2.9752e-01,\n",
       "         -9.2597e-02, -8.8254e-01, -9.2429e-01, -4.6133e-01, -6.6637e-01,\n",
       "          8.7479e-01, -2.2566e-01,  1.0131e+00, -5.2311e-02,  7.3107e-01,\n",
       "          9.4485e-02,  1.2489e+00, -1.1737e+00,  5.3730e-02, -1.4631e-01,\n",
       "         -1.6628e-01, -6.6954e-01,  5.9758e-01, -2.1972e-01,  1.6330e+00,\n",
       "         -4.4969e-02,  7.0890e-01,  4.8849e-01,  6.3228e-02,  2.7104e-01,\n",
       "         -6.3498e-01,  1.7254e+00,  8.0764e-01,  1.5084e+00,  1.9798e+00,\n",
       "          1.9777e-01,  4.2926e-01,  1.2763e+00, -3.4861e-01, -1.0167e+00,\n",
       "         -6.4221e-01,  1.2829e+00, -3.3002e-01,  7.2691e-02, -2.0537e-01,\n",
       "          8.3151e+00,  3.1763e-02,  3.8218e-01,  9.7125e-01, -9.6633e-02,\n",
       "         -4.0218e-01,  1.0097e+00,  3.4878e-02, -1.6742e-01, -1.0890e+00,\n",
       "         -1.0230e+00, -5.8652e-01,  1.7263e-01,  1.6437e+00,  4.4441e-02,\n",
       "          1.0132e-01,  1.5299e+00,  2.4910e-01,  7.3409e-01,  1.0459e-01,\n",
       "          5.0016e-01, -5.5083e-01, -9.2411e-01,  5.7625e-01, -1.4561e-01,\n",
       "         -1.0904e-01, -6.2912e-02, -9.6523e-01, -3.2765e-01, -5.8799e-01,\n",
       "          2.8865e-01, -9.3551e-01, -3.0334e-01, -1.1242e+00,  1.2293e+00,\n",
       "         -4.1204e-01, -6.4320e-02, -7.7116e-01, -4.8891e-01, -9.0350e-02,\n",
       "          3.1137e-01, -3.7864e-01,  9.3609e-01,  3.9855e-02, -1.7848e+00,\n",
       "         -3.0926e-01,  4.8240e-01,  7.4653e-02, -2.0881e-01, -5.7609e-01,\n",
       "          1.1822e-01, -1.1169e+00, -4.3205e-01,  2.6877e-01,  2.3636e+00,\n",
       "          1.0729e+00, -3.1672e-01, -7.3533e-01,  4.7357e-02,  5.5989e-02,\n",
       "         -1.0675e+00, -7.8685e-01,  1.2258e-01, -3.7565e-01, -5.4873e-01,\n",
       "          6.8910e-01, -1.3432e+00,  4.2273e-01,  3.4957e-01,  7.2554e-01,\n",
       "         -3.5502e-01, -6.0428e-01,  7.9165e-03, -6.3626e-02, -5.1860e-01,\n",
       "         -6.1514e-01, -5.8937e+00,  1.1252e+00,  2.4807e+00,  7.1029e-01,\n",
       "         -6.8192e-01,  3.1368e-01, -2.0567e-01,  2.8141e-01, -5.1637e-01,\n",
       "          1.0394e+00, -2.6910e-01,  1.8715e-01, -4.5490e-01, -7.0848e-01,\n",
       "         -6.1347e-01, -8.4123e-01, -3.3964e-01,  1.7093e-01, -1.4192e-02,\n",
       "          1.7285e+00, -4.7658e-01, -1.2904e-01, -1.0208e+00,  1.0554e+00],\n",
       "        [-8.9814e-01,  3.5608e-01, -3.6043e-01, -2.3856e-02, -5.6894e-01,\n",
       "         -5.5793e-02,  2.9625e-01,  1.2688e-01,  4.9237e-02, -4.5760e+00,\n",
       "          9.1551e-02,  1.4677e-01, -6.1994e-01, -5.9046e-02, -3.7704e-02,\n",
       "          2.7626e-01,  1.9226e-01, -1.9507e-01, -1.3536e-01,  1.9180e-01,\n",
       "         -2.3191e-01,  5.1881e-01,  5.6602e-01,  2.6452e-01, -1.1331e+00,\n",
       "          2.3361e-01, -8.4370e-01,  1.2847e-01,  4.6199e-01, -1.8546e-01,\n",
       "          3.0049e-01,  1.2619e+00, -5.6059e-01,  6.3927e-01, -2.5216e+00,\n",
       "          1.3056e+00,  1.6527e-01, -6.0958e-01, -9.2611e-01,  4.2191e-01,\n",
       "         -1.5169e-01, -5.6975e-01,  2.1968e-01,  1.5665e-01, -1.4543e-01,\n",
       "          2.0682e-01,  1.4421e+00,  7.1042e-01, -5.4288e-01, -3.5063e-01,\n",
       "         -3.2337e-02, -6.1670e-01, -3.3439e-01, -9.1736e-01, -4.1211e-01,\n",
       "          1.1328e+00,  1.4914e-01,  7.8056e-01,  8.7184e-01, -4.0785e-01,\n",
       "          1.2597e+00, -3.3599e-01,  7.0956e-01,  7.7301e-01, -1.0029e+00,\n",
       "         -1.3764e+00, -2.9293e-01,  5.5274e-01, -4.1041e-01, -6.0430e-01,\n",
       "         -3.8785e-01,  9.7680e-02, -3.8998e-01,  8.6072e-01, -3.6502e-01,\n",
       "          9.3152e-02,  9.7904e-01,  5.1560e-01, -1.8281e-01, -4.4239e-01,\n",
       "         -4.7150e-01,  1.3158e+00,  3.0838e+00,  2.6553e-01, -3.4392e-02,\n",
       "         -4.5835e-01, -1.1514e+00,  7.1749e-01, -6.8773e-01,  7.0264e-01,\n",
       "          8.9915e-01,  1.2015e-01, -1.0098e+00, -9.3292e-02,  4.2647e-01,\n",
       "         -1.6888e-02, -8.0644e-01, -3.2408e-01, -2.1145e-01, -1.6195e+00,\n",
       "         -4.3015e-01,  1.0777e-01, -1.3452e-01, -6.1323e-01, -6.3479e-01,\n",
       "          1.7179e-01,  1.1867e+00,  8.2085e-01, -6.4482e-01,  2.5406e-01,\n",
       "         -6.3200e-01, -4.6562e-01, -6.2893e-01, -1.1891e+00,  2.8227e-01,\n",
       "          5.5775e-01,  6.4974e-01,  1.4388e+00,  2.3615e-02, -1.0413e+00,\n",
       "         -1.0734e+00, -2.7192e-01, -1.8694e-01,  1.0614e+00, -5.6409e-01,\n",
       "          2.3966e-01,  2.9478e-01,  1.9597e-01, -3.5391e-01, -3.6582e-02,\n",
       "          9.9489e-01,  1.3117e+00,  6.3592e-01,  2.5211e-01, -9.6632e-01,\n",
       "         -1.0805e+00, -8.4282e-01, -5.0575e-01,  2.2862e-01, -2.9061e-02,\n",
       "          5.3200e-01, -2.9251e-01,  5.3072e-01,  4.2230e-01, -1.1450e+00,\n",
       "          3.5652e-01,  1.5627e-01, -6.0006e-02, -2.9436e-01, -1.3736e-01,\n",
       "          2.6700e+00, -2.4127e-02,  1.7382e-01, -5.0685e-01,  1.3646e+00,\n",
       "         -1.4617e-01, -9.4455e-01, -9.5473e-01,  7.7626e-01, -2.7744e-02,\n",
       "          2.8935e-01, -1.7847e+00, -1.1613e-01, -3.9741e-01, -6.8323e-02,\n",
       "          7.2508e-01, -2.4175e-01, -3.8504e-02, -4.0708e-01, -3.9807e-01,\n",
       "          1.0584e-01,  6.5481e-01, -1.5673e+00,  7.0221e-01, -7.3654e-01,\n",
       "         -5.7753e-02, -1.0515e+00, -3.9984e-01, -6.0590e-01,  2.0577e+00,\n",
       "          4.5096e-01,  7.1094e-01,  1.2673e-01, -3.8390e-01,  2.3921e-02,\n",
       "          2.8691e-01,  1.6844e+00,  2.8203e-01,  2.8086e-01,  1.1229e+00,\n",
       "          1.2839e-01,  1.2831e+00, -1.7630e-01, -7.9481e-01, -7.7070e-01,\n",
       "         -1.6207e-01,  5.5440e-01, -5.2327e-02,  7.7169e-02,  2.5132e-01,\n",
       "          7.9390e+00, -2.0554e-01,  5.8841e-01, -4.0235e-01, -5.4384e-01,\n",
       "         -3.8642e-01, -1.8859e-01, -3.2310e-01,  4.4013e-02, -1.1266e+00,\n",
       "         -6.5302e-02, -3.9955e-01, -1.6974e-01,  1.0122e+00,  3.4162e-01,\n",
       "         -1.7047e-01,  1.0681e+00, -5.5344e-01,  4.9587e-01, -3.3061e-01,\n",
       "          1.5823e+00, -3.1989e-01, -1.1154e+00,  3.8471e-01,  2.0579e-01,\n",
       "          3.0677e-01, -1.8865e-01, -3.5476e-01, -2.1957e-01, -9.9536e-01,\n",
       "          2.1670e-02, -4.7297e-01, -5.2303e-01,  7.8440e-02,  9.4007e-01,\n",
       "          2.0482e-01, -2.1208e-02, -7.7840e-02, -4.0977e-01,  3.6276e-01,\n",
       "         -3.4637e-01, -1.0887e-01,  1.7281e+00, -2.5305e-01, -1.9485e+00,\n",
       "         -8.1869e-02,  5.8508e-01,  2.4192e-01, -7.6180e-01, -2.1383e-01,\n",
       "          4.7226e-02, -4.2535e-01, -9.5355e-02,  1.8825e-01,  3.0784e+00,\n",
       "         -3.2346e-02, -4.0690e-01, -1.4977e+00, -2.7917e-02,  8.9505e-02,\n",
       "         -1.4748e-01, -5.5894e-01,  4.2989e-01,  3.4798e-02,  4.5087e-01,\n",
       "         -2.5563e-02, -3.9954e-01,  1.6931e-01,  4.3174e-01,  4.2475e-01,\n",
       "         -5.3959e-01, -3.4937e-01,  3.6633e-02,  2.1645e-01,  6.1136e-02,\n",
       "         -4.2468e-01, -7.3859e+00,  8.4493e-01,  2.2039e+00,  6.9060e-01,\n",
       "         -1.0749e+00,  3.0052e-02, -2.8379e-01,  3.8174e-01, -5.8031e-01,\n",
       "          1.3348e+00,  7.8937e-01, -1.2305e-01,  4.7171e-01, -7.4788e-01,\n",
       "         -3.6915e-01, -3.1398e-01, -5.6350e-01,  1.4615e-01, -1.1841e-02,\n",
       "          1.4790e+00,  9.1864e-02, -1.2052e+00, -2.6356e-01,  1.1197e+00]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "49ce4a14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8707,  0.7249, -2.6481, -1.9446, -0.9443,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000, -0.0000,  0.0000, -0.4002, -0.0000,  0.5484,  0.0000,  0.0000,\n",
       "          1.1795,  1.1837,  0.0000,  0.0000,  0.0000,  1.5260,  1.6571,  0.0000,\n",
       "         -0.0000,  0.6131,  0.9697, -0.0000,  0.0000,  0.7204, -0.0000,  0.0000,\n",
       "         -0.0000,  0.4228, -5.8730,  2.0536, -0.4795, -1.8525, -1.1876,  0.0000,\n",
       "         -0.0691, -0.0000, -0.5575,  0.0000,  0.7786,  1.4657,  2.2753,  1.1049,\n",
       "         -2.0054, -1.3077,  0.0000, -1.5805, -0.0000, -0.0000, -2.3597,  0.0000,\n",
       "         -0.0000,  0.0000,  1.5134,  0.1671,  2.4371, -0.0000,  0.0000,  1.6488,\n",
       "         -0.0000, -0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1959,\n",
       "         -2.1680,  1.4599, -0.0000,  0.3722,  0.0000,  0.0000, -0.0000,  0.0000,\n",
       "         -0.0000,  0.0000,  6.3884,  0.2336, -0.0000, -0.6898, -0.1143,  0.0000,\n",
       "         -1.0305, -1.4778,  0.0000,  1.0547, -2.0378, -0.0000,  0.0000, -0.0000,\n",
       "         -2.1399, -0.0000,  0.0000, -3.1238, -0.0000, -0.0000, -0.0723, -0.2067,\n",
       "         -0.0000, -0.8766,  1.1471,  0.0000, -1.2326,  0.0000, -0.0000,  0.4914,\n",
       "         -1.9745, -0.0292,  1.4383,  1.2096, -1.5709,  0.0000, -0.0000, -0.0000,\n",
       "         -1.8955, -0.4294,  1.2584,  0.0000, -0.0000, -0.0000, -0.0000,  0.3120,\n",
       "         -0.8226, -0.0000,  0.0000,  0.0000,  0.0000, -0.0000, -1.9417, -0.0000,\n",
       "         -1.3405, -0.0000,  0.0000, -0.2118,  0.2014,  0.0000, -0.0817,  0.0000,\n",
       "         -0.0000,  0.0000, -0.0000, -0.2874, -0.7901, -0.0000,  6.2024,  0.0000,\n",
       "         -0.0000, -0.0573,  2.0668,  0.0000, -0.9707, -1.5100,  1.4539, -0.5950,\n",
       "         -0.0000, -1.7651, -0.0000, -0.0000, -1.3327,  0.0000, -0.4513,  2.0261,\n",
       "         -0.0000,  0.0000,  0.0000,  2.4978, -2.3475,  0.0000, -0.2926, -0.0000,\n",
       "         -0.0000,  0.0000, -0.0000,  3.2660, -0.0000,  1.4178,  0.0000,  0.1265,\n",
       "          0.5421, -0.0000,  3.4508,  0.0000,  0.0000,  3.9595,  0.0000,  0.0000,\n",
       "          0.0000, -0.6972, -2.0334, -0.0000,  0.0000, -0.6600,  0.0000, -0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000, -0.1933, -0.8044,  2.0195,  0.0698,\n",
       "         -0.3348, -2.1780, -0.0000, -0.0000,  0.0000,  3.2874,  0.0000,  0.2026,\n",
       "          3.0598,  0.0000,  0.0000,  0.2092,  1.0003, -0.0000, -1.8482,  0.0000,\n",
       "         -0.0000, -0.0000, -0.1258, -0.0000, -0.6553, -0.0000,  0.0000, -0.0000,\n",
       "         -0.6067, -2.2485,  0.0000, -0.8241, -0.0000, -0.0000, -0.9778, -0.0000,\n",
       "          0.6227, -0.0000,  1.8722,  0.0000, -0.0000, -0.0000,  0.0000,  0.1493,\n",
       "         -0.0000, -0.0000,  0.2364, -0.0000, -0.0000,  0.5375,  4.7272,  2.1459,\n",
       "         -0.0000, -1.4707,  0.0000,  0.0000, -0.0000, -1.5737,  0.2452, -0.7513,\n",
       "         -0.0000,  1.3782, -2.6863,  0.0000,  0.0000,  1.4511, -0.7100, -1.2086,\n",
       "          0.0000, -0.0000, -0.0000, -1.2303, -0.0000,  0.0000,  4.9614,  0.0000,\n",
       "         -0.0000,  0.0000, -0.4113,  0.5628, -0.0000,  0.0000, -0.5382,  0.3743,\n",
       "         -0.9098, -0.0000, -1.2269, -1.6825, -0.0000,  0.0000, -0.0284,  0.0000,\n",
       "         -0.0000, -0.2581, -0.0000,  2.1109],\n",
       "        [-0.0000,  0.7122, -0.7209, -0.0000, -0.0000, -0.0000,  0.0000,  0.0000,\n",
       "          0.0985, -9.1520,  0.1831,  0.0000, -1.2399, -0.1181, -0.0000,  0.0000,\n",
       "          0.0000, -0.3901, -0.2707,  0.0000, -0.4638,  0.0000,  0.0000,  0.0000,\n",
       "         -2.2663,  0.0000, -1.6874,  0.2569,  0.9240, -0.0000,  0.0000,  0.0000,\n",
       "         -1.1212,  0.0000, -5.0433,  0.0000,  0.0000, -0.0000, -0.0000,  0.8438,\n",
       "         -0.3034, -1.1395,  0.4394,  0.0000, -0.2909,  0.0000,  2.8843,  1.4208,\n",
       "         -0.0000, -0.7013, -0.0000, -0.0000, -0.0000, -1.8347, -0.0000,  2.2655,\n",
       "          0.2983,  0.0000,  1.7437, -0.8157,  2.5195, -0.0000,  1.4191,  1.5460,\n",
       "         -2.0059, -2.7528, -0.5859,  1.1055, -0.0000, -1.2086, -0.0000,  0.1954,\n",
       "         -0.7800,  0.0000, -0.0000,  0.0000,  1.9581,  0.0000, -0.0000, -0.0000,\n",
       "         -0.9430,  0.0000,  0.0000,  0.0000, -0.0688, -0.9167, -0.0000,  0.0000,\n",
       "         -1.3755,  1.4053,  0.0000,  0.2403, -0.0000, -0.0000,  0.8529, -0.0338,\n",
       "         -0.0000, -0.0000, -0.0000, -0.0000, -0.8603,  0.2155, -0.0000, -0.0000,\n",
       "         -0.0000,  0.3436,  2.3733,  0.0000, -0.0000,  0.0000, -0.0000, -0.9312,\n",
       "         -0.0000, -0.0000,  0.0000,  0.0000,  0.0000,  2.8775,  0.0472, -2.0826,\n",
       "         -0.0000, -0.0000, -0.3739,  0.0000, -0.0000,  0.0000,  0.0000,  0.3919,\n",
       "         -0.0000, -0.0732,  0.0000,  2.6233,  0.0000,  0.0000, -0.0000, -0.0000,\n",
       "         -0.0000, -0.0000,  0.0000, -0.0000,  1.0640, -0.0000,  1.0614,  0.0000,\n",
       "         -0.0000,  0.0000,  0.3125, -0.0000, -0.5887, -0.2747,  0.0000, -0.0000,\n",
       "          0.0000, -0.0000,  2.7292, -0.0000, -1.8891, -0.0000,  1.5525, -0.0555,\n",
       "          0.0000, -0.0000, -0.0000, -0.7948, -0.1366,  1.4502, -0.0000, -0.0000,\n",
       "         -0.8142, -0.7961,  0.2117,  0.0000, -3.1346,  1.4044, -1.4731, -0.0000,\n",
       "         -0.0000, -0.0000, -1.2118,  0.0000,  0.9019,  1.4219,  0.0000, -0.7678,\n",
       "          0.0478,  0.0000,  0.0000,  0.0000,  0.5617,  2.2457,  0.0000,  2.5663,\n",
       "         -0.0000, -1.5896, -0.0000, -0.3241,  0.0000, -0.0000,  0.1543,  0.5026,\n",
       "         15.8781, -0.0000,  0.0000, -0.8047, -0.0000, -0.7728, -0.0000, -0.0000,\n",
       "          0.0000, -2.2533, -0.0000, -0.7991, -0.3395,  0.0000,  0.0000, -0.0000,\n",
       "          2.1363, -0.0000,  0.9917, -0.6612,  0.0000, -0.6398, -2.2308,  0.7694,\n",
       "          0.4116,  0.0000, -0.3773, -0.0000, -0.4391, -0.0000,  0.0000, -0.0000,\n",
       "         -1.0461,  0.0000,  1.8801,  0.0000, -0.0000, -0.1557, -0.8195,  0.0000,\n",
       "         -0.6927, -0.2177,  3.4563, -0.0000, -0.0000, -0.0000,  0.0000,  0.4838,\n",
       "         -1.5236, -0.4277,  0.0945, -0.0000, -0.0000,  0.3765,  0.0000, -0.0000,\n",
       "         -0.0000, -2.9954, -0.0000,  0.1790, -0.2950, -1.1179,  0.8598,  0.0696,\n",
       "          0.9017, -0.0000, -0.0000,  0.3386,  0.0000,  0.8495, -1.0792, -0.0000,\n",
       "          0.0733,  0.4329,  0.1223, -0.0000, -0.0000,  1.6899,  0.0000,  1.3812,\n",
       "         -0.0000,  0.0000, -0.5676,  0.7635, -1.1606,  0.0000,  0.0000, -0.0000,\n",
       "          0.9434, -0.0000, -0.0000, -0.6280, -1.1270,  0.2923, -0.0000,  0.0000,\n",
       "          0.1837, -2.4105, -0.5271,  0.0000]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "ccd450fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(309)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(act1 == 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "f4296624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 300])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "4739f7f8",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  92.7139,  118.2343,   64.2856,   75.5373,   91.5371,  112.0891,\n",
       "          109.0136,  131.5521,  124.8662,  -41.1248,  118.5339,  100.2397,\n",
       "           68.0442,  115.4125,  107.4782,  118.5392,  125.5055,  125.5728,\n",
       "          111.4066,  116.4260,  110.2287,  131.0481,  133.1445,  122.4891,\n",
       "           79.1129,  116.4462,  122.1497,   91.5801,  135.9678,  118.1634,\n",
       "           84.1465,  128.7252,   79.1121,  113.4036,   12.7047,  139.4874,\n",
       "           98.9706,   77.0116,   87.6461,  111.5823,  105.5359,   85.7282,\n",
       "           97.7238,  123.7835,  119.0933,  130.0832,  143.0329,  124.3129,\n",
       "           74.5646,   85.7243,  108.2958,   81.3611,   92.0671,  104.0726,\n",
       "           68.8989,  130.2355,   99.9246,  110.4055,  130.8472,  109.3128,\n",
       "          145.6199,   94.6549,  140.1584,  133.0121,   89.9010,   88.9239,\n",
       "          130.3529,  119.4663,  112.7132,  122.4487,  111.6463,  109.7733,\n",
       "           71.9654,  129.9912,   97.1257,  112.5929,  125.5140,  111.0485,\n",
       "           76.7359,  110.9029,   95.2390,  149.1683,  208.8195,  110.3770,\n",
       "          103.7635,   95.6069,  104.8118,  131.1594,   90.1577,   83.0045,\n",
       "          126.0468,  123.5105,   74.0477,   71.8369,  112.1580,   85.3492,\n",
       "           72.4135,  103.5712,  123.5382,   56.6771,   91.8198,   92.2298,\n",
       "          105.4844,  103.3346,   85.4641,   92.6195,  124.9877,  145.7559,\n",
       "           86.9256,  112.9707,   84.0844,  114.5005,   75.0602,  106.1736,\n",
       "          129.6454,  125.9877,   81.5143,  117.6049,   99.6349,   57.9472,\n",
       "           76.3232,   99.7732,  126.7687,  124.9750,   76.4950,   88.3395,\n",
       "           99.3376,  111.6305,   93.4828,  102.6713,  129.0920,  148.0834,\n",
       "          107.5287,   96.3598,   75.5840,   81.4385,   85.2006,   99.6341,\n",
       "          113.0000,  103.2523,  109.8618,  106.7285,  105.3335,  113.3052,\n",
       "           72.5559,  127.0499,   91.6856,  102.0442,   94.0033,   92.4711,\n",
       "          205.8442,  108.6246,   99.8299,  105.7239,  139.6978,  107.4866,\n",
       "           91.1143,   82.4887,  129.8954,   97.1231,  103.6785,   78.4091,\n",
       "           77.0735,   91.8832,   85.3242,  134.6240,   99.4220,  139.0472,\n",
       "          104.9672,  130.0268,  109.6630,  146.5921,   69.0943,  108.3593,\n",
       "          101.9602,  101.3214,   85.2226,  125.7565,   99.6120,  158.8792,\n",
       "          105.2020,  129.3175,  122.2668,  108.6632,  115.3108,   86.3283,\n",
       "          161.8342,  132.4760,  154.8919,  169.9712,  112.9669,  120.3720,\n",
       "          147.4686,   95.4890,   74.1169,   86.0970,  147.6801,   96.0837,\n",
       "          108.9659,  100.0710,  372.6299,  107.6566,  118.8659,  137.7097,\n",
       "          103.5494,   93.7752,  138.9412,  107.7563,  101.2849,   71.8051,\n",
       "           73.9153,   87.8785,  112.1627,  159.2207,  108.0622,  109.8816,\n",
       "          155.5807,  114.6090,  130.1233,  109.9862,  122.6402,   89.0200,\n",
       "           77.0794,  125.0743,  101.9827,  103.1524,  104.6281,   75.7639,\n",
       "           96.1595,   87.8314,  115.8741,   76.7146,   96.9371,   70.6779,\n",
       "          145.9650,   93.4598,  104.5830,   81.9721,   91.0010,  103.7504,\n",
       "          116.6011,   94.5283,  136.5849,  107.9155,   49.5463,   96.7476,\n",
       "          122.0720,  109.0286,   99.9609,   88.2122,  110.4223,   70.9125,\n",
       "           92.8198,  115.2383,  182.2494,  140.9625,   96.5091,   83.1183,\n",
       "          108.1555,  108.4316,   72.4935,   81.4702,  110.5617,   94.6239,\n",
       "           89.0873,  128.6839,   63.6743,  120.1634,  117.8228,  129.8498,\n",
       "           95.2839,   87.3105,  106.8938,  104.6052,   90.0511,   86.9630,\n",
       "          -81.8935,  142.6345,  185.9958,  129.3619,   84.8267,  116.6749,\n",
       "          100.0613,  115.6424,   90.1225,  139.8910,   98.0323,  112.6273,\n",
       "           92.0889,   83.9772,   87.0163,   79.7307,   95.7758,  112.1083,\n",
       "          106.1866,  161.9318,   91.3952,  102.5126,   73.9857,  140.4027],\n",
       "        [  92.2339,  142.9164,  113.9625,  127.5633,  105.5366,  126.2728,\n",
       "          140.4989,  133.6545,  130.5170,  -56.3868,  132.2269,  134.4582,\n",
       "          103.4760,  126.1414,  127.0038,  139.6908,  136.2964,  120.6448,\n",
       "          123.0574,  136.2780,  119.1561,  149.4925,  151.3999,  139.2168,\n",
       "           82.7380,  137.9676,   94.4337,  133.7187,  147.1964,  121.0328,\n",
       "          140.6701,  179.5190,  105.8741,  154.3600,   26.6283,  181.2866,\n",
       "          135.2060,  103.8946,   91.1035,  145.5767,  122.3975,  105.5039,\n",
       "          137.4046,  134.8574,  122.6506,  136.8849,  186.8032,  157.2352,\n",
       "          106.5900,  114.3584,  127.2207,  103.6065,  115.0146,   91.4570,\n",
       "          111.8743,  174.3020,  134.5540,  160.0695,  163.7583,  112.0465,\n",
       "          179.4328,  114.9501,  157.2003,  159.7643,   87.9991,   72.9081,\n",
       "          116.6903,  150.8636,  111.9427,  104.1079,  112.8546,  132.4746,\n",
       "          112.7685,  163.3088,  113.7772,  132.2916,  168.0901,  149.3625,\n",
       "          121.1400,  110.6506,  109.4744,  181.6969,  253.1439,  139.2575,\n",
       "          127.1376,  110.0054,   81.9987,  157.5210,  100.7365,  156.9210,\n",
       "          164.8619,  133.3826,   87.7209,  124.7575,  145.7607,  127.8449,\n",
       "           95.9392,  115.4313,  119.9829,   63.0828,  111.1450,  132.8824,\n",
       "          123.0913,  103.7471,  102.8757,  135.4693,  176.4799,  161.6976,\n",
       "          102.4703,  138.7937,  102.9884,  109.7117,  103.1126,   80.4777,\n",
       "          139.9340,  151.0658,  154.7832,  186.6672,  129.4817,   86.4481,\n",
       "           85.1525,  117.5390,  120.9730,  171.4178,  105.7326,  138.2120,\n",
       "          140.4393,  136.4466,  114.2262,  127.0491,  168.7306,  181.5311,\n",
       "          154.2248,  138.7151,   89.4785,   84.8634,   94.4695,  108.0903,\n",
       "          137.7657,  127.3530,  150.0252,  116.7070,  149.9735,  145.5926,\n",
       "           82.2581,  142.9341,  134.8421,  126.1025,  116.6326,  122.9766,\n",
       "          236.4220,  127.5524,  135.5515,  108.0456,  183.6700,  122.6206,\n",
       "           90.3585,   89.9470,  159.8958,  127.4062,  140.2199,   56.4088,\n",
       "          123.8345,  112.4681,  125.7665,  157.8278,  118.7582,  126.9714,\n",
       "          112.0775,  112.4414,  132.8042,  154.9881,   65.1929,  156.9034,\n",
       "           98.7641,  126.1936,   86.0382,  112.3701,  104.0431,  211.6795,\n",
       "          146.7506,  157.2562,  133.6486,  113.0143,  129.4940,  140.1215,\n",
       "          196.5924,  139.9241,  139.8768,  173.9021,  133.7157,  180.3783,\n",
       "          121.4031,   96.4092,   97.3837,  121.9781,  150.9305,  126.4129,\n",
       "          131.6458,  138.6831,  449.3409,  120.2216,  152.3050,  112.2687,\n",
       "          106.5508,  112.9124,  120.9067,  115.4711,  130.3059,   83.0005,\n",
       "          125.8885,  112.3817,  121.6682,  169.4292,  142.3320,  121.6388,\n",
       "          171.6905,  106.1632,  148.5652,  115.1676,  192.4678,  115.6006,\n",
       "           83.4536,  144.0736,  136.8434,  140.9238,  120.9042,  114.1918,\n",
       "          119.6545,   88.3050,  129.4031,  109.4147,  107.3917,  131.6971,\n",
       "          166.5152,  136.8039,  127.6704,  125.3819,  111.9687,  143.1864,\n",
       "          114.5307,  124.1279,  198.3605,  118.3017,   49.7898,  125.2191,\n",
       "          152.1703,  138.3033,   97.7431,  119.8864,  130.4358,  111.3390,\n",
       "          124.6741,  136.1343,  252.9252,  127.2203,  112.0846,   68.0067,\n",
       "          127.3993,  132.1443,  122.5677,  105.9408,  145.8989,  129.9336,\n",
       "          146.7469,  127.4944,  112.3822,  135.3692,  145.9740,  145.6915,\n",
       "          106.7227,  114.4095,  130.0077,  137.2742,  130.9978,  111.3660,\n",
       "         -169.9333,  162.6706,  217.5874,  156.4344,   85.0921,  129.7418,\n",
       "          117.0594,  143.9532,  105.0772,  182.4646,  160.4257,  123.5550,\n",
       "          147.5889,   98.3057,  113.6103,  115.8394,  105.7564,  134.4333,\n",
       "          128.0489,  188.2952,  132.2396,   79.8241,  117.8769,  173.7760]],\n",
       "       grad_fn=<SegmentReduceBackward>)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "ed6fcce8",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on DGLHeteroGraph in module dgl.heterograph object:\n",
      "\n",
      "class DGLHeteroGraph(builtins.object)\n",
      " |  DGLHeteroGraph(gidx=[], ntypes=['_N'], etypes=['_E'], node_frames=None, edge_frames=None, **deprecate_kwargs)\n",
      " |  \n",
      " |  Class for storing graph structure and node/edge feature data.\n",
      " |  \n",
      " |  There are a few ways to create a DGLGraph:\n",
      " |  \n",
      " |  * To create a homogeneous graph from Tensor data, use :func:`dgl.graph`.\n",
      " |  * To create a heterogeneous graph from Tensor data, use :func:`dgl.heterograph`.\n",
      " |  * To create a graph from other data sources, use ``dgl.*`` create ops. See\n",
      " |    :ref:`api-graph-create-ops`.\n",
      " |  \n",
      " |  Read the user guide chapter :ref:`guide-graph` for an in-depth explanation about its\n",
      " |  usage.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __contains__(self, vid)\n",
      " |      **DEPRECATED**: please directly call :func:`has_nodes`.\n",
      " |  \n",
      " |  __copy__(self)\n",
      " |      Shallow copy implementation.\n",
      " |  \n",
      " |  __getitem__(self, key)\n",
      " |      Return the relation slice of this graph.\n",
      " |      \n",
      " |      You can get a relation slice with ``self[srctype, etype, dsttype]``, where\n",
      " |      ``srctype``, ``etype``, and ``dsttype`` can be either a string or a full\n",
      " |      slice (``:``) representing wildcard (i.e. any source/edge/destination type).\n",
      " |      \n",
      " |      A relation slice is a homogeneous (with one node type and one edge type) or\n",
      " |      bipartite (with two node types and one edge type) graph, transformed from\n",
      " |      the original heterogeneous graph.\n",
      " |      \n",
      " |      If there is only one canonical edge type found, then the returned relation\n",
      " |      slice would be a subgraph induced from the original graph.  That is, it is\n",
      " |      equivalent to ``self.edge_type_subgraph(etype)``.  The node and edge features\n",
      " |      of the returned graph would be shared with thew original graph.\n",
      " |      \n",
      " |      If there are multiple canonical edge types found, then the source/edge/destination\n",
      " |      node types would be a *concatenation* of original node/edge types.  The\n",
      " |      new source/destination node type would have the concatenation determined by\n",
      " |      :func:`dgl.combine_names() <dgl.combine_names>` called on original source/destination\n",
      " |      types as its name.  The source/destination node would be formed by concatenating the\n",
      " |      common features of the original source/destination types.  Therefore they are not\n",
      " |      shared with the original graph.  Edge type is similar.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      key : str or tuple\n",
      " |          Either a string representing the edge type name, or a tuple in the form of\n",
      " |          ``(srctype, etype, dsttype)`` where ``srctype``, ``etype``, ``dsttype`` can be either\n",
      " |          strings representing type names or a full slice object (`:`).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DGLGraph\n",
      " |          The relation slice.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This function returns a new graph.  Changing the content of this graph does not reflect\n",
      " |      onto the original graph.\n",
      " |      \n",
      " |      If the graph combines multiple node types or edge types together, it will have the\n",
      " |      mapping of node/edge types and IDs from the new graph to the original graph.\n",
      " |      The mappings have the name ``dgl.NTYPE``, ``dgl.NID``, ``dgl.ETYPE`` and ``dgl.EID``,\n",
      " |      similar to the function :func:`dgl.to_homogenenous`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> g = dgl.heterograph({\n",
      " |      ...     ('A1', 'AB1', 'B'): ([0, 1, 2], [1, 2, 3]),\n",
      " |      ...     ('A1', 'AB2', 'B'): ([1, 2, 3], [3, 4, 5]),\n",
      " |      ...     ('A2', 'AB2', 'B'): ([1, 3, 5], [2, 4, 6])})\n",
      " |      >>> new_g = g['A1', :, 'B']         # combines all edge types between A1 and B\n",
      " |      >>> new_g\n",
      " |      Graph(num_nodes={'A1': 4, 'B': 7},\n",
      " |            num_edges={('A1', 'AB1+AB2', 'B'): 6},\n",
      " |            metagraph=[('A1', 'B', 'AB1+AB2')])\n",
      " |      >>> new_g.edges()\n",
      " |      (tensor([0, 1, 2, 1, 2, 3]), tensor([1, 2, 3, 3, 4, 5]))\n",
      " |      >>> new_g2 = g[:, 'AB2', 'B']        # combines all node types that are source of AB2\n",
      " |      >>> new_g2\n",
      " |      Graph(num_nodes={'A1+A2': 10, 'B': 7},\n",
      " |            num_edges={('A1+A2', 'AB2+AB2', 'B'): 6},\n",
      " |            metagraph=[('A1+A2', 'B', 'AB2+AB2')])\n",
      " |      >>> new_g2.edges()\n",
      " |      (tensor([1, 2, 3, 5, 7, 9]), tensor([3, 4, 5, 2, 4, 6]))\n",
      " |      \n",
      " |      If a combination of multiple node types and edge types occur, one can find\n",
      " |      the mapping to the original node type and IDs like the following:\n",
      " |      \n",
      " |      >>> new_g1.edges['AB1+AB2'].data[dgl.EID]\n",
      " |      tensor([0, 1, 2, 0, 1, 2])\n",
      " |      >>> new_g1.edges['AB1+AB2'].data[dgl.ETYPE]\n",
      " |      tensor([0, 0, 0, 1, 1, 1])\n",
      " |      >>> new_g2.nodes['A1+A2'].data[dgl.NID]\n",
      " |      tensor([0, 1, 2, 3, 0, 1, 2, 3, 4, 5])\n",
      " |      >>> new_g2.nodes['A1+A2'].data[dgl.NTYPE]\n",
      " |      tensor([0, 0, 0, 0, 1, 1, 1, 1, 1, 1])\n",
      " |  \n",
      " |  __init__(self, gidx=[], ntypes=['_N'], etypes=['_E'], node_frames=None, edge_frames=None, **deprecate_kwargs)\n",
      " |      Internal constructor for creating a DGLGraph.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      gidx : HeteroGraphIndex\n",
      " |          Graph index object.\n",
      " |      ntypes : list of str, pair of list of str\n",
      " |          Node type list. ``ntypes[i]`` stores the name of node type i.\n",
      " |          If a pair is given, the graph created is a uni-directional bipartite graph,\n",
      " |          and its SRC node types and DST node types are given as in the pair.\n",
      " |      etypes : list of str\n",
      " |          Edge type list. ``etypes[i]`` stores the name of edge type i.\n",
      " |      node_frames : list[Frame], optional\n",
      " |          Node feature storage. If None, empty frame is created.\n",
      " |          Otherwise, ``node_frames[i]`` stores the node features\n",
      " |          of node type i. (default: None)\n",
      " |      edge_frames : list[Frame], optional\n",
      " |          Edge feature storage. If None, empty frame is created.\n",
      " |          Otherwise, ``edge_frames[i]`` stores the edge features\n",
      " |          of edge type i. (default: None)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  add_edge(self, u, v, data=None, etype=None)\n",
      " |      Add one edge to the graph.\n",
      " |      \n",
      " |      DEPRECATED: please use ``add_edges``.\n",
      " |  \n",
      " |  add_edges(self, u, v, data=None, etype=None)\n",
      " |      Add multiple new edges for the specified edge type\n",
      " |      \n",
      " |      The i-th new edge will be from ``u[i]`` to ``v[i]``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      u : int, tensor, numpy.ndarray, list\n",
      " |          Source node IDs, ``u[i]`` gives the source node for the i-th new edge.\n",
      " |      v : int, tensor, numpy.ndarray, list\n",
      " |          Destination node IDs, ``v[i]`` gives the destination node for the i-th new edge.\n",
      " |      data : dict, optional\n",
      " |          Feature data of the added edges. The i-th row of the feature data\n",
      " |          corresponds to the i-th new edge.\n",
      " |      etype : str or tuple of str, optional\n",
      " |          The type of the new edges. Can be omitted if there is\n",
      " |          only one edge type in the graph.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      \n",
      " |      * Inplace update is applied to the current graph.\n",
      " |      * If end nodes of adding edges does not exists, add_nodes is invoked\n",
      " |        to add new nodes. The node features of the new nodes will be created\n",
      " |        by initializers defined with :func:`set_n_initializer` (default\n",
      " |        initializer fills zeros). In certain cases, it is recommanded to\n",
      " |        add_nodes first and then add_edges.\n",
      " |      * If the key of ``data`` does not contain some existing feature fields,\n",
      " |        those features for the new edges will be created by initializers\n",
      " |        defined with :func:`set_n_initializer` (default initializer fills zeros).\n",
      " |      * If the key of ``data`` contains new feature fields, those features for\n",
      " |        the old edges will be created by initializers defined with\n",
      " |        :func:`set_n_initializer` (default initializer fills zeros).\n",
      " |      * This function discards the batch information. Please use\n",
      " |        :func:`dgl.DGLGraph.set_batch_num_nodes`\n",
      " |        and :func:`dgl.DGLGraph.set_batch_num_edges` on the transformed graph\n",
      " |        to maintain the information.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      **Homogeneous Graphs or Heterogeneous Graphs with A Single Edge Type**\n",
      " |      \n",
      " |      >>> g = dgl.graph((torch.tensor([0, 1]), torch.tensor([1, 2])))\n",
      " |      >>> g.num_edges()\n",
      " |      2\n",
      " |      >>> g.add_edges(torch.tensor([1, 3]), torch.tensor([0, 1]))\n",
      " |      >>> g.num_edges()\n",
      " |      4\n",
      " |      \n",
      " |      Since ``u`` or ``v`` contains a non-existing node ID, the nodes are\n",
      " |      added implicitly.\n",
      " |      >>> g.num_nodes()\n",
      " |      4\n",
      " |      \n",
      " |      If the graph has some edge features and new edges are added without\n",
      " |      features, their features will be created by initializers defined\n",
      " |      with :func:`set_n_initializer`.\n",
      " |      \n",
      " |      >>> g.edata['h'] = torch.ones(4, 1)\n",
      " |      >>> g.add_edges(torch.tensor([1]), torch.tensor([1]))\n",
      " |      >>> g.edata['h']\n",
      " |      tensor([[1.], [1.], [1.], [1.], [0.]])\n",
      " |      \n",
      " |      We can also assign features for the new edges in adding new edges.\n",
      " |      \n",
      " |      >>> g.add_edges(torch.tensor([0, 0]), torch.tensor([2, 2]),\n",
      " |      ...             {'h': torch.tensor([[1.], [2.]]), 'w': torch.ones(2, 1)})\n",
      " |      >>> g.edata['h']\n",
      " |      tensor([[1.], [1.], [1.], [1.], [0.], [1.], [2.]])\n",
      " |      \n",
      " |      Since ``data`` contains new feature fields, the features for old edges\n",
      " |      will be created by initializers defined with :func:`set_n_initializer`.\n",
      " |      \n",
      " |      >>> g.edata['w']\n",
      " |      tensor([[0.], [0.], [0.], [0.], [0.], [1.], [1.]])\n",
      " |      \n",
      " |      **Heterogeneous Graphs with Multiple Edge Types**\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({\n",
      " |      ...     ('user', 'plays', 'game'): (torch.tensor([0, 1, 1, 2]),\n",
      " |      ...                                 torch.tensor([0, 0, 1, 1])),\n",
      " |      ...     ('developer', 'develops', 'game'): (torch.tensor([0, 1]),\n",
      " |      ...                                         torch.tensor([0, 1]))\n",
      " |      ...     })\n",
      " |      >>> g.add_edges(torch.tensor([3]), torch.tensor([3]))\n",
      " |      DGLError: Edge type name must be specified\n",
      " |      if there are more than one edge types.\n",
      " |      >>> g.number_of_edges('plays')\n",
      " |      4\n",
      " |      >>> g.add_edges(torch.tensor([3]), torch.tensor([3]), etype='plays')\n",
      " |      >>> g.number_of_edges('plays')\n",
      " |      5\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      add_nodes\n",
      " |      remove_nodes\n",
      " |      remove_edges\n",
      " |  \n",
      " |  add_nodes(self, num, data=None, ntype=None)\n",
      " |      Add new nodes of the same node type\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      num : int\n",
      " |          Number of nodes to add.\n",
      " |      data : dict, optional\n",
      " |          Feature data of the added nodes.\n",
      " |      ntype : str, optional\n",
      " |          The type of the new nodes. Can be omitted if there is\n",
      " |          only one node type in the graph.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      \n",
      " |      * Inplace update is applied to the current graph.\n",
      " |      * If the key of ``data`` does not contain some existing feature fields,\n",
      " |        those features for the new nodes will be created by initializers\n",
      " |        defined with :func:`set_n_initializer` (default initializer fills zeros).\n",
      " |      * If the key of ``data`` contains new feature fields, those features for\n",
      " |        the old nodes will be created by initializers defined with\n",
      " |        :func:`set_n_initializer` (default initializer fills zeros).\n",
      " |      * This function discards the batch information. Please use\n",
      " |        :func:`dgl.DGLGraph.set_batch_num_nodes`\n",
      " |        and :func:`dgl.DGLGraph.set_batch_num_edges` on the transformed graph\n",
      " |        to maintain the information.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      **Homogeneous Graphs or Heterogeneous Graphs with A Single Node Type**\n",
      " |      \n",
      " |      >>> g = dgl.graph((torch.tensor([0, 1]), torch.tensor([1, 2])))\n",
      " |      >>> g.num_nodes()\n",
      " |      3\n",
      " |      >>> g.add_nodes(2)\n",
      " |      >>> g.num_nodes()\n",
      " |      5\n",
      " |      \n",
      " |      If the graph has some node features and new nodes are added without\n",
      " |      features, their features will be created by initializers defined\n",
      " |      with :func:`set_n_initializer`.\n",
      " |      \n",
      " |      >>> g.ndata['h'] = torch.ones(5, 1)\n",
      " |      >>> g.add_nodes(1)\n",
      " |      >>> g.ndata['h']\n",
      " |      tensor([[1.], [1.], [1.], [1.], [1.], [0.]])\n",
      " |      \n",
      " |      We can also assign features for the new nodes in adding new nodes.\n",
      " |      \n",
      " |      >>> g.add_nodes(1, {'h': torch.ones(1, 1), 'w': torch.ones(1, 1)})\n",
      " |      >>> g.ndata['h']\n",
      " |      tensor([[1.], [1.], [1.], [1.], [1.], [0.], [1.]])\n",
      " |      \n",
      " |      Since ``data`` contains new feature fields, the features for old nodes\n",
      " |      will be created by initializers defined with :func:`set_n_initializer`.\n",
      " |      \n",
      " |      >>> g.ndata['w']\n",
      " |      tensor([[0.], [0.], [0.], [0.], [0.], [0.], [1.]])\n",
      " |      \n",
      " |      \n",
      " |      **Heterogeneous Graphs with Multiple Node Types**\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({\n",
      " |      ...     ('user', 'plays', 'game'): (torch.tensor([0, 1, 1, 2]),\n",
      " |      ...                                 torch.tensor([0, 0, 1, 1])),\n",
      " |      ...     ('developer', 'develops', 'game'): (torch.tensor([0, 1]),\n",
      " |      ...                                         torch.tensor([0, 1]))\n",
      " |      ...     })\n",
      " |      >>> g.add_nodes(2)\n",
      " |      DGLError: Node type name must be specified\n",
      " |      if there are more than one node types.\n",
      " |      >>> g.num_nodes('user')\n",
      " |      3\n",
      " |      >>> g.add_nodes(2, ntype='user')\n",
      " |      >>> g.num_nodes('user')\n",
      " |      5\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      remove_nodes\n",
      " |      add_edges\n",
      " |      remove_edges\n",
      " |  \n",
      " |  add_self_loop(g, edge_feat_names=None, fill_data=1.0, etype=None)\n",
      " |      Alias of :func:`dgl.add_self_loop`.\n",
      " |  \n",
      " |  adj(self, transpose=False, ctx=device(type='cpu'), scipy_fmt=None, etype=None)\n",
      " |      Return the adjacency matrix of edges of the given edge type.\n",
      " |      \n",
      " |      By default, a row of returned adjacency matrix represents the\n",
      " |      source of an edge and the column represents the destination.\n",
      " |      \n",
      " |      When transpose is True, a row represents the destination and a column\n",
      " |      represents the source.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      transpose : bool, optional\n",
      " |          A flag to transpose the returned adjacency matrix. (Default: False)\n",
      " |      ctx : context, optional\n",
      " |          The context of returned adjacency matrix. (Default: cpu)\n",
      " |      scipy_fmt : str, optional\n",
      " |          If specified, return a scipy sparse matrix in the given format.\n",
      " |          Otherwise, return a backend dependent sparse tensor. (Default: None)\n",
      " |      etype : str or (str, str, str), optional\n",
      " |          The type names of the edges. The allowed type name formats are:\n",
      " |      \n",
      " |          * ``(str, str, str)`` for source node type, edge type and destination node type.\n",
      " |          * or one ``str`` edge type name if the name can uniquely identify a\n",
      " |            triplet format in the graph.\n",
      " |      \n",
      " |          Can be omitted if the graph has only one type of edges.\n",
      " |      \n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      SparseTensor or scipy.sparse.spmatrix\n",
      " |          Adjacency matrix.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      Instantiate a heterogeneous graph.\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({\n",
      " |      ...     ('user', 'follows', 'user'): ([0, 1], [0, 1]),\n",
      " |      ...     ('developer', 'develops', 'game'): ([0, 1], [0, 2])\n",
      " |      ... })\n",
      " |      \n",
      " |      Get a backend dependent sparse tensor. Here we use PyTorch for example.\n",
      " |      \n",
      " |      >>> g.adj(etype='develops')\n",
      " |      tensor(indices=tensor([[0, 1],\n",
      " |                             [0, 2]]),\n",
      " |             values=tensor([1., 1.]),\n",
      " |             size=(2, 3), nnz=2, layout=torch.sparse_coo)\n",
      " |      \n",
      " |      Get a scipy coo sparse matrix.\n",
      " |      \n",
      " |      >>> g.adj(scipy_fmt='coo', etype='develops')\n",
      " |      <2x3 sparse matrix of type '<class 'numpy.int64'>'\n",
      " |         with 2 stored elements in COOrdinate format>\n",
      " |  \n",
      " |  adj_sparse(self, fmt, etype=None)\n",
      " |      Return the adjacency matrix of edges of the given edge type as tensors of\n",
      " |      a sparse matrix representation.\n",
      " |      \n",
      " |      By default, a row of returned adjacency matrix represents the\n",
      " |      source of an edge and the column represents the destination.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      fmt : str\n",
      " |          Either ``coo``, ``csr`` or ``csc``.\n",
      " |      etype : str or (str, str, str), optional\n",
      " |          The type names of the edges. The allowed type name formats are:\n",
      " |      \n",
      " |          * ``(str, str, str)`` for source node type, edge type and destination node type.\n",
      " |          * or one ``str`` edge type name if the name can uniquely identify a\n",
      " |            triplet format in the graph.\n",
      " |      \n",
      " |          Can be omitted if the graph has only one type of edges.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      tuple[Tensor]\n",
      " |          If :attr:`fmt` is ``coo``, returns a pair of source and destination node ID\n",
      " |          tensors.\n",
      " |      \n",
      " |          If :attr:`fmt` is ``csr`` or ``csc``, return the CSR or CSC representation\n",
      " |          of the adjacency matrix as a triplet of tensors\n",
      " |          ``(indptr, indices, edge_ids)``.  Namely ``edge_ids`` could be an empty\n",
      " |          tensor with 0 elements, in which case the edge IDs are consecutive\n",
      " |          integers starting from 0.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> g = dgl.graph(([0, 1, 2], [1, 2, 3]))\n",
      " |      >>> g.adj_sparse('coo')\n",
      " |      (tensor([0, 1, 2]), tensor([1, 2, 3]))\n",
      " |      >>> g.adj_sparse('csr')\n",
      " |      (tensor([0, 1, 2, 3, 3]), tensor([1, 2, 3]), tensor([0, 1, 2]))\n",
      " |  \n",
      " |  adjacency_matrix(self, transpose=False, ctx=device(type='cpu'), scipy_fmt=None, etype=None)\n",
      " |      Alias of :meth:`adj`\n",
      " |  \n",
      " |  adjacency_matrix_scipy(self, transpose=False, fmt='csr', return_edge_ids=None)\n",
      " |      DEPRECATED: please use ``dgl.adjacency_matrix(transpose, scipy_fmt=fmt)``.\n",
      " |  \n",
      " |  all_edges(self, form='uv', order='eid', etype=None)\n",
      " |      Return all edges with the specified edge type.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      form : str, optional\n",
      " |          The return form, which can be one of the following:\n",
      " |      \n",
      " |          - ``'eid'``: The returned result is a 1D tensor :math:`EID`, representing\n",
      " |            the IDs of all edges.\n",
      " |          - ``'uv'`` (default): The returned result is a 2-tuple of 1D tensors :math:`(U, V)`,\n",
      " |            representing the source and destination nodes of all edges. For each :math:`i`,\n",
      " |            :math:`(U[i], V[i])` forms an edge.\n",
      " |          - ``'all'``: The returned result is a 3-tuple of 1D tensors :math:`(U, V, EID)`,\n",
      " |            representing the source nodes, destination nodes and IDs of all edges.\n",
      " |            For each :math:`i`, :math:`(U[i], V[i])` forms an edge with ID :math:`EID[i]`.\n",
      " |      order : str, optional\n",
      " |          The order of the returned edges, which can be one of the following:\n",
      " |      \n",
      " |          - ``'srcdst'``: The edges are sorted first by their source node IDs and then\n",
      " |            by their destination node IDs to break ties.\n",
      " |          - ``'eid'`` (default): The edges are sorted by their IDs.\n",
      " |      etype : str or tuple of str, optional\n",
      " |          The edge type for query, which can be an edge type (str) or a canonical edge type\n",
      " |          (3-tuple of str). When an edge type appears in multiple canonical edge types, one\n",
      " |          must use a canonical edge type. If the graph has multiple edge types, one must\n",
      " |          specify the argument. Otherwise, it can be omitted.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Tensor or (Tensor, Tensor) or (Tensor, Tensor, Tensor)\n",
      " |          All edges of the specified edge type. For a description of the returned result,\n",
      " |          see the description of :attr:`form`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      Create a homogeneous graph.\n",
      " |      \n",
      " |      >>> g = dgl.graph((torch.tensor([0, 0, 1, 1]), torch.tensor([1, 0, 2, 3])))\n",
      " |      \n",
      " |      Query for edges.\n",
      " |      \n",
      " |      >>> g.all_edges()\n",
      " |      (tensor([0, 0, 1, 1]), tensor([1, 0, 2, 3]))\n",
      " |      \n",
      " |      Specify a different value for :attr:`form` and :attr:`order`.\n",
      " |      \n",
      " |      >>> g.all_edges(form='all', order='srcdst')\n",
      " |      (tensor([0, 0, 1, 1]), tensor([0, 1, 2, 3]), tensor([1, 0, 2, 3]))\n",
      " |      \n",
      " |      For a graph of multiple edge types, it is required to specify the edge type in query.\n",
      " |      \n",
      " |      >>> hg = dgl.heterograph({\n",
      " |      ...     ('user', 'follows', 'user'): (torch.tensor([0, 1]), torch.tensor([1, 2])),\n",
      " |      ...     ('user', 'plays', 'game'): (torch.tensor([3, 4]), torch.tensor([5, 6]))\n",
      " |      ... })\n",
      " |      >>> hg.all_edges(etype='plays')\n",
      " |      (tensor([3, 4]), tensor([5, 6]))\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      edges\n",
      " |      in_edges\n",
      " |      out_edges\n",
      " |  \n",
      " |  apply_edges(self, func, edges='__ALL__', etype=None, inplace=False)\n",
      " |      Update the features of the specified edges by the provided function.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : dgl.function.BuiltinFunction or callable\n",
      " |          The function to generate new edge features. It must be either\n",
      " |          a :ref:`api-built-in` or a :ref:`apiudf`.\n",
      " |      edges : edges\n",
      " |          The edges to update features on. The allowed input formats are:\n",
      " |      \n",
      " |          * ``int``: A single edge ID.\n",
      " |          * Int Tensor: Each element is an edge ID.  The tensor must have the same device type\n",
      " |            and ID data type as the graph's.\n",
      " |          * iterable[int]: Each element is an edge ID.\n",
      " |          * (Tensor, Tensor): The node-tensors format where the i-th elements\n",
      " |            of the two tensors specify an edge.\n",
      " |          * (iterable[int], iterable[int]): Similar to the node-tensors format but\n",
      " |            stores edge endpoints in python iterables.\n",
      " |      \n",
      " |          Default value specifies all the edges in the graph.\n",
      " |      \n",
      " |      etype : str or (str, str, str), optional\n",
      " |          The type name of the edges. The allowed type name formats are:\n",
      " |      \n",
      " |          * ``(str, str, str)`` for source node type, edge type and destination node type.\n",
      " |          * or one ``str`` edge type name if the name can uniquely identify a\n",
      " |            triplet format in the graph.\n",
      " |      \n",
      " |          Can be omitted if the graph has only one type of edges.\n",
      " |      \n",
      " |      inplace: bool, optional\n",
      " |          **DEPRECATED**.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      DGL recommends using DGL's bulit-in function for the :attr:`func` argument,\n",
      " |      because DGL will invoke efficient kernels that avoids copying node features to\n",
      " |      edge features in this case.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      **Homogeneous graph**\n",
      " |      \n",
      " |      >>> g = dgl.graph(([0, 1, 2, 3], [1, 2, 3, 4]))\n",
      " |      >>> g.ndata['h'] = torch.ones(5, 2)\n",
      " |      >>> g.apply_edges(lambda edges: {'x' : edges.src['h'] + edges.dst['h']})\n",
      " |      >>> g.edata['x']\n",
      " |      tensor([[2., 2.],\n",
      " |              [2., 2.],\n",
      " |              [2., 2.],\n",
      " |              [2., 2.]])\n",
      " |      \n",
      " |      Use built-in function\n",
      " |      \n",
      " |      >>> import dgl.function as fn\n",
      " |      >>> g.apply_edges(fn.u_add_v('h', 'h', 'x'))\n",
      " |      >>> g.edata['x']\n",
      " |      tensor([[2., 2.],\n",
      " |              [2., 2.],\n",
      " |              [2., 2.],\n",
      " |              [2., 2.]])\n",
      " |      \n",
      " |      **Heterogeneous graph**\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({('user', 'plays', 'game'): ([0, 1, 1, 2], [0, 0, 2, 1])})\n",
      " |      >>> g.edges[('user', 'plays', 'game')].data['h'] = torch.ones(4, 5)\n",
      " |      >>> g.apply_edges(lambda edges: {'h': edges.data['h'] * 2})\n",
      " |      >>> g.edges[('user', 'plays', 'game')].data['h']\n",
      " |      tensor([[2., 2., 2., 2., 2.],\n",
      " |              [2., 2., 2., 2., 2.],\n",
      " |              [2., 2., 2., 2., 2.],\n",
      " |              [2., 2., 2., 2., 2.]])\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      apply_nodes\n",
      " |  \n",
      " |  apply_nodes(self, func, v='__ALL__', ntype=None, inplace=False)\n",
      " |      Update the features of the specified nodes by the provided function.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : callable\n",
      " |          The function to update node features. It must be\n",
      " |          a :ref:`apiudf`.\n",
      " |      v : node IDs\n",
      " |          The node IDs. The allowed formats are:\n",
      " |      \n",
      " |          * ``int``: A single node.\n",
      " |          * Int Tensor: Each element is a node ID. The tensor must have the same device type\n",
      " |            and ID data type as the graph's.\n",
      " |          * iterable[int]: Each element is a node ID.\n",
      " |      \n",
      " |          If not given (default), use all the nodes in the graph.\n",
      " |      ntype : str, optional\n",
      " |          The node type name. Can be omitted if there is\n",
      " |          only one type of nodes in the graph.\n",
      " |      inplace : bool, optional\n",
      " |          **DEPRECATED**.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      **Homogeneous graph**\n",
      " |      \n",
      " |      >>> g = dgl.graph(([0, 1, 2, 3], [1, 2, 3, 4]))\n",
      " |      >>> g.ndata['h'] = torch.ones(5, 2)\n",
      " |      >>> g.apply_nodes(lambda nodes: {'x' : nodes.data['h'] * 2})\n",
      " |      >>> g.ndata['x']\n",
      " |      tensor([[2., 2.],\n",
      " |              [2., 2.],\n",
      " |              [2., 2.],\n",
      " |              [2., 2.],\n",
      " |              [2., 2.]])\n",
      " |      \n",
      " |      **Heterogeneous graph**\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({('user', 'follows', 'user'): ([0, 1], [1, 2])})\n",
      " |      >>> g.nodes['user'].data['h'] = torch.ones(3, 5)\n",
      " |      >>> g.apply_nodes(lambda nodes: {'h': nodes.data['h'] * 2}, ntype='user')\n",
      " |      >>> g.nodes['user'].data['h']\n",
      " |      tensor([[2., 2., 2., 2., 2.],\n",
      " |              [2., 2., 2., 2., 2.],\n",
      " |              [2., 2., 2., 2., 2.]])\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      apply_edges\n",
      " |  \n",
      " |  astype(self, idtype)\n",
      " |      Cast this graph to use another ID type.\n",
      " |      \n",
      " |      Features are copied (shallow copy) to the new graph.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      idtype : Data type object.\n",
      " |          New ID type. Can only be int32 or int64.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DGLHeteroGraph\n",
      " |          Graph in the new ID type.\n",
      " |  \n",
      " |  batch_num_edges(self, etype=None)\n",
      " |      Return the number of edges for each graph in the batch with the specified edge type.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      etype : str or tuple of str, optional\n",
      " |          The edge type for query, which can be an edge type (str) or a canonical edge type\n",
      " |          (3-tuple of str). When an edge type appears in multiple canonical edge types, one\n",
      " |          must use a canonical edge type. If the graph has multiple edge types, one must\n",
      " |          specify the argument. Otherwise, it can be omitted.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Tensor\n",
      " |          The number of edges with the specified type for each graph in the batch. The i-th\n",
      " |          element of it is the number of edges with the specified type for the i-th graph.\n",
      " |          If the graph is not a batched one, it will return a list of length 1 that holds\n",
      " |          the number of edges in the graph.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      Query for homogeneous graphs.\n",
      " |      \n",
      " |      >>> g1 = dgl.graph((torch.tensor([0, 1, 2]), torch.tensor([1, 2, 3])))\n",
      " |      >>> g1.batch_num_edges()\n",
      " |      tensor([3])\n",
      " |      >>> g2 = dgl.graph((torch.tensor([0, 0, 0, 1]), torch.tensor([0, 1, 2, 0])))\n",
      " |      >>> bg = dgl.batch([g1, g2])\n",
      " |      >>> bg.batch_num_edges()\n",
      " |      tensor([3, 4])\n",
      " |      \n",
      " |      Query for heterogeneous graphs.\n",
      " |      \n",
      " |      >>> hg1 = dgl.heterograph({\n",
      " |      ...       ('user', 'plays', 'game') : (torch.tensor([0, 1]), torch.tensor([0, 0]))})\n",
      " |      >>> hg2 = dgl.heterograph({\n",
      " |      ...       ('user', 'plays', 'game') : (torch.tensor([0, 0]), torch.tensor([1, 0]))})\n",
      " |      >>> bg = dgl.batch([hg1, hg2])\n",
      " |      >>> bg.batch_num_edges('plays')\n",
      " |      tensor([2, 2])\n",
      " |  \n",
      " |  batch_num_nodes(self, ntype=None)\n",
      " |      Return the number of nodes for each graph in the batch with the specified node type.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      ntype : str, optional\n",
      " |          The node type for query. If the graph has multiple node types, one must\n",
      " |          specify the argument. Otherwise, it can be omitted. If the graph is not a batched\n",
      " |          one, it will return a list of length 1 that holds the number of nodes in the graph.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Tensor\n",
      " |          The number of nodes with the specified type for each graph in the batch. The i-th\n",
      " |          element of it is the number of nodes with the specified type for the i-th graph.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      Query for homogeneous graphs.\n",
      " |      \n",
      " |      >>> g1 = dgl.graph((torch.tensor([0, 1, 2]), torch.tensor([1, 2, 3])))\n",
      " |      >>> g1.batch_num_nodes()\n",
      " |      tensor([4])\n",
      " |      >>> g2 = dgl.graph((torch.tensor([0, 0, 0, 1]), torch.tensor([0, 1, 2, 0])))\n",
      " |      >>> bg = dgl.batch([g1, g2])\n",
      " |      >>> bg.batch_num_nodes()\n",
      " |      tensor([4, 3])\n",
      " |      \n",
      " |      Query for heterogeneous graphs.\n",
      " |      \n",
      " |      >>> hg1 = dgl.heterograph({\n",
      " |      ...       ('user', 'plays', 'game') : (torch.tensor([0, 1]), torch.tensor([0, 0]))})\n",
      " |      >>> hg2 = dgl.heterograph({\n",
      " |      ...       ('user', 'plays', 'game') : (torch.tensor([0, 0]), torch.tensor([1, 0]))})\n",
      " |      >>> bg = dgl.batch([hg1, hg2])\n",
      " |      >>> bg.batch_num_nodes('user')\n",
      " |      tensor([2, 1])\n",
      " |  \n",
      " |  clone(self)\n",
      " |      Return a heterograph object that is a clone of current graph.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DGLHeteroGraph\n",
      " |          The graph object that is a clone of current graph.\n",
      " |  \n",
      " |  cpu(self)\n",
      " |      Return a new copy of this graph on CPU.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DGLHeteroGraph\n",
      " |          Graph on CPU.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      to\n",
      " |  \n",
      " |  create_formats_(self)\n",
      " |      Create all sparse matrices allowed for the graph.\n",
      " |      \n",
      " |      By default, we create sparse matrices for a graph only when necessary.\n",
      " |      In some cases we may want to create them immediately (e.g. in a\n",
      " |      multi-process data loader), which can be achieved via this API.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      **Homographs or Heterographs with A Single Edge Type**\n",
      " |      \n",
      " |      >>> g = dgl.graph(([0, 0, 1], [2, 3, 2]))\n",
      " |      >>> g.format()\n",
      " |      {'created': ['coo'], 'not created': ['csr', 'csc']}\n",
      " |      >>> g.create_formats_()\n",
      " |      >>> g.format()\n",
      " |      {'created': ['coo', 'csr', 'csc'], 'not created': []}\n",
      " |      \n",
      " |      **Heterographs with Multiple Edge Types**\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({\n",
      " |      ...     ('user', 'plays', 'game'): (torch.tensor([0, 1, 1, 2]),\n",
      " |      ...                                 torch.tensor([0, 0, 1, 1])),\n",
      " |      ...     ('developer', 'develops', 'game'): (torch.tensor([0, 1]),\n",
      " |      ...                                         torch.tensor([0, 1]))\n",
      " |      ...     })\n",
      " |      >>> g.format()\n",
      " |      {'created': ['coo'], 'not created': ['csr', 'csc']}\n",
      " |      >>> g.create_formats_()\n",
      " |      >>> g.format()\n",
      " |      {'created': ['coo', 'csr', 'csc'], 'not created': []}\n",
      " |  \n",
      " |  edge_attr_schemes(self, etype=None)\n",
      " |      Return the edge feature schemes for the specified type.\n",
      " |      \n",
      " |      The scheme of a feature describes the shape and data type of it.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      etype : str or (str, str, str), optional\n",
      " |          The type names of the edges. The allowed type name formats are:\n",
      " |      \n",
      " |          * ``(str, str, str)`` for source node type, edge type and destination node type.\n",
      " |          * or one ``str`` edge type name if the name can uniquely identify a\n",
      " |            triplet format in the graph.\n",
      " |      \n",
      " |          Can be omitted if the graph has only one type of edges.\n",
      " |      \n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      dict[str, Scheme]\n",
      " |          A dictionary mapping a feature name to its associated feature scheme.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      Query for a homogeneous graph.\n",
      " |      \n",
      " |      >>> g = dgl.graph((torch.tensor([0, 1]), torch.tensor([1, 2])))\n",
      " |      >>> g.edata['h1'] = torch.randn(2, 1)\n",
      " |      >>> g.edata['h2'] = torch.randn(2, 2)\n",
      " |      >>> g.edge_attr_schemes()\n",
      " |      {'h1': Scheme(shape=(1,), dtype=torch.float32),\n",
      " |       'h2': Scheme(shape=(2,), dtype=torch.float32)}\n",
      " |      \n",
      " |      Query for a heterogeneous graph of multiple edge types.\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({('user', 'plays', 'game'):\n",
      " |      ...                      (torch.tensor([1, 2]), torch.tensor([3, 4])),\n",
      " |      ...                      ('user', 'follows', 'user'):\n",
      " |      ...                      (torch.tensor([3, 4]), torch.tensor([5, 6]))})\n",
      " |      >>> g.edges['plays'].data['h1'] = torch.randn(2, 1)\n",
      " |      >>> g.edges['plays'].data['h2'] = torch.randn(2, 2)\n",
      " |      >>> g.edge_attr_schemes('plays')\n",
      " |      {'h1': Scheme(shape=(1,), dtype=torch.float32),\n",
      " |       'h2': Scheme(shape=(2,), dtype=torch.float32)}\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      node_attr_schemes\n",
      " |  \n",
      " |  edge_id(self, u, v, force_multi=None, return_uv=False, etype=None)\n",
      " |      Return the edge ID, or an array of edge IDs, between source node\n",
      " |      `u` and destination node `v`, with the specified edge type\n",
      " |      \n",
      " |      **DEPRECATED**: See edge_ids\n",
      " |  \n",
      " |  edge_ids(self, u, v, force_multi=None, return_uv=False, etype=None)\n",
      " |      Return the edge ID(s) given the two endpoints of the edge(s).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      u : node IDs\n",
      " |          The source node IDs of the edges. The allowed formats are:\n",
      " |      \n",
      " |          * ``int``: A single node.\n",
      " |          * Int Tensor: Each element is a node ID. The tensor must have the same device type\n",
      " |            and ID data type as the graph's.\n",
      " |          * iterable[int]: Each element is a node ID.\n",
      " |      \n",
      " |      v : node IDs\n",
      " |          The destination node IDs of the edges. The allowed formats are:\n",
      " |      \n",
      " |          * ``int``: A single node.\n",
      " |          * Int Tensor: Each element is a node ID. The tensor must have the same device type\n",
      " |            and ID data type as the graph's.\n",
      " |          * iterable[int]: Each element is a node ID.\n",
      " |      force_multi : bool, optional\n",
      " |          **DEPRECATED**, use :attr:`return_uv` instead. Whether to allow the graph to be a\n",
      " |          multigraph, i.e. there can be multiple edges from one node to another.\n",
      " |      return_uv : bool, optional\n",
      " |          Whether to return the source and destination node IDs along with the edges. If\n",
      " |          False (default), it assumes that the graph is a simple graph and there is only\n",
      " |          one edge from one node to another. If True, there can be multiple edges found\n",
      " |          from one node to another.\n",
      " |      etype : str or (str, str, str), optional\n",
      " |          The type names of the edges. The allowed type name formats are:\n",
      " |      \n",
      " |          * ``(str, str, str)`` for source node type, edge type and destination node type.\n",
      " |          * or one ``str`` edge type name if the name can uniquely identify a\n",
      " |            triplet format in the graph.\n",
      " |      \n",
      " |          Can be omitted if the graph has only one type of edges.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Tensor, or (Tensor, Tensor, Tensor)\n",
      " |      \n",
      " |          * If ``return_uv=False``, it returns the edge IDs in a tensor, where the i-th\n",
      " |            element is the ID of the edge ``(u[i], v[i])``.\n",
      " |          * If ``return_uv=True``, it returns a tuple of three 1D tensors ``(eu, ev, e)``.\n",
      " |            ``e[i]`` is the ID of an edge from ``eu[i]`` to ``ev[i]``. It returns all edges\n",
      " |            (including parallel edges) from ``eu[i]`` to ``ev[i]`` in this case.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If the graph is a simple graph, ``return_uv=False``, and there are no edges\n",
      " |      between some pairs of node(s), it will raise an error.\n",
      " |      \n",
      " |      If the graph is a multigraph, ``return_uv=False``, and there are multiple edges\n",
      " |      between some pairs of node(s), it returns an arbitrary one from them.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      Create a homogeneous graph.\n",
      " |      \n",
      " |      >>> g = dgl.graph((torch.tensor([0, 0, 1, 1, 1]), torch.tensor([1, 0, 2, 3, 2])))\n",
      " |      \n",
      " |      Query for the edges.\n",
      " |      \n",
      " |      >>> g.edge_ids(0, 0)\n",
      " |      1\n",
      " |      >>> g.edge_ids(torch.tensor([1, 0]), torch.tensor([3, 1]))\n",
      " |      tensor([3, 0])\n",
      " |      \n",
      " |      Get all edges for pairs of nodes.\n",
      " |      \n",
      " |      >>> g.edge_ids(torch.tensor([1, 0]), torch.tensor([3, 1]), return_uv=True)\n",
      " |      (tensor([1, 0]), tensor([3, 1]), tensor([3, 0]))\n",
      " |      \n",
      " |      If the graph has multiple edge types, one need to specify the edge type.\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({\n",
      " |      ...     ('user', 'follows', 'user'): (torch.tensor([0, 1]), torch.tensor([1, 2])),\n",
      " |      ...     ('user', 'follows', 'game'): (torch.tensor([0, 1, 2]), torch.tensor([1, 2, 3])),\n",
      " |      ...     ('user', 'plays', 'game'): (torch.tensor([1, 3]), torch.tensor([2, 3]))\n",
      " |      ... })\n",
      " |      >>> g.edge_ids(torch.tensor([1]), torch.tensor([2]), etype='plays')\n",
      " |      tensor([0])\n",
      " |      \n",
      " |      Use a canonical edge type instead when there is ambiguity for an edge type.\n",
      " |      \n",
      " |      >>> g.edge_ids(torch.tensor([0, 1]), torch.tensor([1, 2]),\n",
      " |      ...            etype=('user', 'follows', 'user'))\n",
      " |      tensor([0, 1])\n",
      " |      >>> g.edge_ids(torch.tensor([1, 2]), torch.tensor([2, 3]),\n",
      " |      ...            etype=('user', 'follows', 'game'))\n",
      " |      tensor([1, 2])\n",
      " |  \n",
      " |  edge_subgraph(graph, edges, *, relabel_nodes=True, store_ids=True, output_device=None, **deprecated_kwargs)\n",
      " |      Alias of :func:`dgl.edge_subgraph`.\n",
      " |  \n",
      " |  edge_type_subgraph(graph, etypes, output_device=None)\n",
      " |      Alias of :func:`dgl.edge_type_subgraph`.\n",
      " |  \n",
      " |  filter_edges(self, predicate, edges='__ALL__', etype=None)\n",
      " |      Return the IDs of the edges with the given edge type that satisfy\n",
      " |      the given predicate.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      predicate : callable\n",
      " |          A function of signature ``func(edges) -> Tensor``.\n",
      " |          ``edges`` are :class:`dgl.EdgeBatch` objects.\n",
      " |          Its output tensor should be a 1D boolean tensor with\n",
      " |          each element indicating whether the corresponding edge in\n",
      " |          the batch satisfies the predicate.\n",
      " |      edges : edges\n",
      " |          The edges to send and receive messages on. The allowed input formats are:\n",
      " |      \n",
      " |          * ``int``: A single edge ID.\n",
      " |          * Int Tensor: Each element is an edge ID.  The tensor must have the same device type\n",
      " |            and ID data type as the graph's.\n",
      " |          * iterable[int]: Each element is an edge ID.\n",
      " |          * (Tensor, Tensor): The node-tensors format where the i-th elements\n",
      " |            of the two tensors specify an edge.\n",
      " |          * (iterable[int], iterable[int]): Similar to the node-tensors format but\n",
      " |            stores edge endpoints in python iterables.\n",
      " |      \n",
      " |          By default, it considers all the edges.\n",
      " |      etype : str or (str, str, str), optional\n",
      " |          The type name of the edges. The allowed type name formats are:\n",
      " |      \n",
      " |          * ``(str, str, str)`` for source node type, edge type and destination node type.\n",
      " |          * or one ``str`` edge type name if the name can uniquely identify a\n",
      " |            triplet format in the graph.\n",
      " |      \n",
      " |          Can be omitted if the graph has only one type of edges.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Tensor\n",
      " |          A 1D tensor that contains the ID(s) of the edge(s) that satisfy the predicate.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      Define a predicate function.\n",
      " |      \n",
      " |      >>> def edges_with_feature_one(edges):\n",
      " |      ...     # Whether an edge has feature 1\n",
      " |      ...     return (edges.data['h'] == 1.).squeeze(1)\n",
      " |      \n",
      " |      Filter edges for a homogeneous graph.\n",
      " |      \n",
      " |      >>> g = dgl.graph((torch.tensor([0, 1, 2]), torch.tensor([1, 2, 3])))\n",
      " |      >>> g.edata['h'] = torch.tensor([[0.], [1.], [1.]])\n",
      " |      >>> print(g.filter_edges(edges_with_feature_one))\n",
      " |      tensor([1, 2])\n",
      " |      \n",
      " |      Filter on edges with IDs 0 and 1\n",
      " |      \n",
      " |      >>> print(g.filter_edges(edges_with_feature_one, edges=torch.tensor([0, 1])))\n",
      " |      tensor([1])\n",
      " |      \n",
      " |      Filter edges for a heterogeneous graph.\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({\n",
      " |      ...     ('user', 'plays', 'game'): (torch.tensor([0, 1, 1, 2]),\n",
      " |      ...                                 torch.tensor([0, 0, 1, 1])),\n",
      " |      ...     ('user', 'follows', 'user'): (torch.tensor([0, 1]), torch.tensor([1, 2]))})\n",
      " |      >>> g.edges['plays'].data['h'] = torch.tensor([[0.], [1.], [1.], [0.]])\n",
      " |      >>> # Filter for 'plays' nodes\n",
      " |      >>> print(g.filter_edges(edges_with_feature_one, etype='plays'))\n",
      " |      tensor([1, 2])\n",
      " |  \n",
      " |  filter_nodes(self, predicate, nodes='__ALL__', ntype=None)\n",
      " |      Return the IDs of the nodes with the given node type that satisfy\n",
      " |      the given predicate.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      predicate : callable\n",
      " |          A function of signature ``func(nodes) -> Tensor``.\n",
      " |          ``nodes`` are :class:`dgl.NodeBatch` objects.\n",
      " |          Its output tensor should be a 1D boolean tensor with\n",
      " |          each element indicating whether the corresponding node in\n",
      " |          the batch satisfies the predicate.\n",
      " |      nodes : node ID(s), optional\n",
      " |          The node(s) for query. The allowed formats are:\n",
      " |      \n",
      " |          - Tensor: A 1D tensor that contains the node(s) for query, whose data type\n",
      " |            and device should be the same as the :py:attr:`idtype` and device of the graph.\n",
      " |          - iterable[int] : Similar to the tensor, but stores node IDs in a sequence\n",
      " |            (e.g. list, tuple, numpy.ndarray).\n",
      " |      \n",
      " |          By default, it considers all nodes.\n",
      " |      ntype : str, optional\n",
      " |          The node type for query. If the graph has multiple node types, one must\n",
      " |          specify the argument. Otherwise, it can be omitted.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Tensor\n",
      " |          A 1D tensor that contains the ID(s) of the node(s) that satisfy the predicate.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      Define a predicate function.\n",
      " |      \n",
      " |      >>> def nodes_with_feature_one(nodes):\n",
      " |      ...     # Whether a node has feature 1\n",
      " |      ...     return (nodes.data['h'] == 1.).squeeze(1)\n",
      " |      \n",
      " |      Filter nodes for a homogeneous graph.\n",
      " |      \n",
      " |      >>> g = dgl.graph((torch.tensor([0, 1, 2]), torch.tensor([1, 2, 3])))\n",
      " |      >>> g.ndata['h'] = torch.tensor([[0.], [1.], [1.], [0.]])\n",
      " |      >>> print(g.filter_nodes(nodes_with_feature_one))\n",
      " |      tensor([1, 2])\n",
      " |      \n",
      " |      Filter on nodes with IDs 0 and 1\n",
      " |      \n",
      " |      >>> print(g.filter_nodes(nodes_with_feature_one, nodes=torch.tensor([0, 1])))\n",
      " |      tensor([1])\n",
      " |      \n",
      " |      Filter nodes for a heterogeneous graph.\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({\n",
      " |      ...     ('user', 'plays', 'game'): (torch.tensor([0, 1, 1, 2]),\n",
      " |      ...                                 torch.tensor([0, 0, 1, 1]))})\n",
      " |      >>> g.nodes['user'].data['h'] = torch.tensor([[0.], [1.], [1.]])\n",
      " |      >>> g.nodes['game'].data['h'] = torch.tensor([[0.], [1.]])\n",
      " |      >>> # Filter for 'user' nodes\n",
      " |      >>> print(g.filter_nodes(nodes_with_feature_one, ntype='user'))\n",
      " |      tensor([1, 2])\n",
      " |  \n",
      " |  find_edges(self, eid, etype=None)\n",
      " |      Return the source and destination node ID(s) given the edge ID(s).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      eid : edge ID(s)\n",
      " |          The edge IDs. The allowed formats are:\n",
      " |      \n",
      " |          * ``int``: A single ID.\n",
      " |          * Int Tensor: Each element is an ID. The tensor must have the same device type\n",
      " |            and ID data type as the graph's.\n",
      " |          * iterable[int]: Each element is an ID.\n",
      " |      \n",
      " |      etype : str or (str, str, str), optional\n",
      " |          The type names of the edges. The allowed type name formats are:\n",
      " |      \n",
      " |          * ``(str, str, str)`` for source node type, edge type and destination node type.\n",
      " |          * or one ``str`` edge type name if the name can uniquely identify a\n",
      " |            triplet format in the graph.\n",
      " |      \n",
      " |          Can be omitted if the graph has only one type of edges.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Tensor\n",
      " |          The source node IDs of the edges. The i-th element is the source node ID of\n",
      " |          the i-th edge.\n",
      " |      Tensor\n",
      " |          The destination node IDs of the edges. The i-th element is the destination node\n",
      " |          ID of the i-th edge.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      Create a homogeneous graph.\n",
      " |      \n",
      " |      >>> g = dgl.graph((torch.tensor([0, 0, 1, 1]), torch.tensor([1, 0, 2, 3])))\n",
      " |      \n",
      " |      Find edges of IDs 0 and 2.\n",
      " |      \n",
      " |      >>> g.find_edges(torch.tensor([0, 2]))\n",
      " |      (tensor([0, 1]), tensor([1, 2]))\n",
      " |      \n",
      " |      For a graph of multiple edge types, it is required to specify the edge type in query.\n",
      " |      \n",
      " |      >>> hg = dgl.heterograph({\n",
      " |      ...     ('user', 'follows', 'user'): (torch.tensor([0, 1]), torch.tensor([1, 2])),\n",
      " |      ...     ('user', 'plays', 'game'): (torch.tensor([3, 4]), torch.tensor([5, 6]))\n",
      " |      ... })\n",
      " |      >>> hg.find_edges(torch.tensor([1, 0]), 'plays')\n",
      " |      (tensor([4, 3]), tensor([6, 5]))\n",
      " |  \n",
      " |  formats(self, formats=None)\n",
      " |      Get a cloned graph with the specified sparse format(s) or query\n",
      " |      for the usage status of sparse formats\n",
      " |      \n",
      " |      The API copies both the graph structure and the features.\n",
      " |      \n",
      " |      If the input graph has multiple edge types, they will have the same\n",
      " |      sparse format.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      formats : str or list of str or None\n",
      " |      \n",
      " |          * If formats is None, return the usage status of sparse formats\n",
      " |          * Otherwise, it can be ``'coo'``/``'csr'``/``'csc'`` or a sublist of\n",
      " |            them, specifying the sparse formats to use.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      dict or DGLGraph\n",
      " |      \n",
      " |          * If formats is None, the result will be a dict recording the usage\n",
      " |            status of sparse formats.\n",
      " |          * Otherwise, a DGLGraph will be returned, which is a clone of the\n",
      " |            original graph with the specified sparse format(s) ``formats``.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      **Homographs or Heterographs with A Single Edge Type**\n",
      " |      \n",
      " |      >>> g = dgl.graph(([0, 0, 1], [2, 3, 2]))\n",
      " |      >>> g.ndata['h'] = torch.ones(4, 1)\n",
      " |      >>> # Check status of format usage\n",
      " |      >>> g.formats()\n",
      " |      {'created': ['coo'], 'not created': ['csr', 'csc']}\n",
      " |      >>> # Get a clone of the graph with 'csr' format\n",
      " |      >>> csr_g = g.formats('csr')\n",
      " |      >>> # Only allowed formats will be displayed in the status query\n",
      " |      >>> csr_g.formats()\n",
      " |      {'created': ['csr'], 'not created': []}\n",
      " |      >>> # Features are copied as well\n",
      " |      >>> csr_g.ndata['h']\n",
      " |      tensor([[1.],\n",
      " |              [1.],\n",
      " |              [1.],\n",
      " |              [1.]])\n",
      " |      \n",
      " |      **Heterographs with Multiple Edge Types**\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({\n",
      " |      ...     ('user', 'plays', 'game'): (torch.tensor([0, 1, 1, 2]),\n",
      " |      ...                                 torch.tensor([0, 0, 1, 1])),\n",
      " |      ...     ('developer', 'develops', 'game'): (torch.tensor([0, 1]),\n",
      " |      ...                                         torch.tensor([0, 1]))\n",
      " |      ...     })\n",
      " |      >>> g.formats()\n",
      " |      {'created': ['coo'], 'not created': ['csr', 'csc']}\n",
      " |      >>> # Get a clone of the graph with 'csr' format\n",
      " |      >>> csr_g = g.formats('csr')\n",
      " |      >>> # Only allowed formats will be displayed in the status query\n",
      " |      >>> csr_g.formats()\n",
      " |      {'created': ['csr'], 'not created': []}\n",
      " |  \n",
      " |  from_networkx(self, nx_graph, node_attrs=None, edge_attrs=None)\n",
      " |      DEPRECATED: please use\n",
      " |      \n",
      " |          ``dgl.from_networkx(nx_graph, node_attrs, edge_attrs)``\n",
      " |      \n",
      " |      which will return a new graph created from the networkx graph.\n",
      " |  \n",
      " |  from_scipy_sparse_matrix(self, spmat, multigraph=None)\n",
      " |      DEPRECATED: please use\n",
      " |      \n",
      " |          ``dgl.from_scipy(spmat)``\n",
      " |      \n",
      " |      which will return a new graph created from the scipy matrix.\n",
      " |  \n",
      " |  get_edge_storage(self, key, etype=None)\n",
      " |      Get storage object of edge feature of type :attr:`etype` and name :attr:`key`.\n",
      " |  \n",
      " |  get_etype_id(self, etype)\n",
      " |      Return the id of the given edge type.\n",
      " |      \n",
      " |      etype can also be None. If so, there should be only one edge type in the\n",
      " |      graph.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      etype : str or tuple of str\n",
      " |          Edge type\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      int\n",
      " |  \n",
      " |  get_node_storage(self, key, ntype=None)\n",
      " |      Get storage object of node feature of type :attr:`ntype` and name :attr:`key`.\n",
      " |  \n",
      " |  get_ntype_id(self, ntype)\n",
      " |      Return the ID of the given node type.\n",
      " |      \n",
      " |      ntype can also be None. If so, there should be only one node type in the\n",
      " |      graph.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      ntype : str\n",
      " |          Node type\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      int\n",
      " |  \n",
      " |  get_ntype_id_from_dst(self, ntype)\n",
      " |      Internal function to return the ID of the given DST node type.\n",
      " |      \n",
      " |      ntype can also be None. If so, there should be only one node type in the\n",
      " |      DST category. Callable even when the self graph is not uni-bipartite.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      ntype : str\n",
      " |          Node type\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      int\n",
      " |  \n",
      " |  get_ntype_id_from_src(self, ntype)\n",
      " |      Internal function to return the ID of the given SRC node type.\n",
      " |      \n",
      " |      ntype can also be None. If so, there should be only one node type in the\n",
      " |      SRC category. Callable even when the self graph is not uni-bipartite.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      ntype : str\n",
      " |          Node type\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      int\n",
      " |  \n",
      " |  global_uniform_negative_sampling(g, num_samples, exclude_self_loops=True, replace=False, etype=None, redundancy=None)\n",
      " |      Alias of :func:`dgl.global_uniform_negative_sampling`.\n",
      " |  \n",
      " |  group_apply_edges(self, group_by, func, edges='__ALL__', etype=None, inplace=False)\n",
      " |      **DEPRECATED**: The API is removed in 0.5.\n",
      " |  \n",
      " |  has_edge_between(self, u, v, etype=None)\n",
      " |      Whether the graph has edges of type ``etype``.\n",
      " |      \n",
      " |      **DEPRECATED**: please use :func:`~DGLGraph.has_edge_between`.\n",
      " |  \n",
      " |  has_edges_between(self, u, v, etype=None)\n",
      " |      Return whether the graph contains the given edges.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      u : node IDs\n",
      " |          The source node IDs of the edges. The allowed formats are:\n",
      " |      \n",
      " |          * ``int``: A single node.\n",
      " |          * Int Tensor: Each element is a node ID. The tensor must have the same device type\n",
      " |            and ID data type as the graph's.\n",
      " |          * iterable[int]: Each element is a node ID.\n",
      " |      \n",
      " |      v : node IDs\n",
      " |          The destination node IDs of the edges. The allowed formats are:\n",
      " |      \n",
      " |          * ``int``: A single node.\n",
      " |          * Int Tensor: Each element is a node ID. The tensor must have the same device type\n",
      " |            and ID data type as the graph's.\n",
      " |          * iterable[int]: Each element is a node ID.\n",
      " |      \n",
      " |      etype : str or (str, str, str), optional\n",
      " |          The type names of the edges. The allowed type name formats are:\n",
      " |      \n",
      " |          * ``(str, str, str)`` for source node type, edge type and destination node type.\n",
      " |          * or one ``str`` edge type name if the name can uniquely identify a\n",
      " |            triplet format in the graph.\n",
      " |      \n",
      " |          Can be omitted if the graph has only one type of edges.\n",
      " |      \n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      bool or bool Tensor\n",
      " |          A tensor of bool flags where each element is True if the node is in the graph.\n",
      " |          If the input is a single node, return one bool value.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      Create a homogeneous graph.\n",
      " |      \n",
      " |      >>> g = dgl.graph((torch.tensor([0, 0, 1, 1]), torch.tensor([1, 0, 2, 3])))\n",
      " |      \n",
      " |      Query for the edges.\n",
      " |      \n",
      " |      >>> g.has_edges_between(1, 2)\n",
      " |      True\n",
      " |      >>> g.has_edges_between(torch.tensor([1, 2]), torch.tensor([2, 3]))\n",
      " |      tensor([ True, False])\n",
      " |      \n",
      " |      If the graph has multiple edge types, one need to specify the edge type.\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({\n",
      " |      ...     ('user', 'follows', 'user'): (torch.tensor([0, 1]), torch.tensor([1, 2])),\n",
      " |      ...     ('user', 'follows', 'game'): (torch.tensor([0, 1, 2]), torch.tensor([1, 2, 3])),\n",
      " |      ...     ('user', 'plays', 'game'): (torch.tensor([1, 3]), torch.tensor([2, 3]))\n",
      " |      ... })\n",
      " |      >>> g.has_edges_between(torch.tensor([1, 2]), torch.tensor([2, 3]), 'plays')\n",
      " |      tensor([ True, False])\n",
      " |      \n",
      " |      Use a canonical edge type instead when there is ambiguity for an edge type.\n",
      " |      \n",
      " |      >>> g.has_edges_between(torch.tensor([1, 2]), torch.tensor([2, 3]),\n",
      " |      ...                     ('user', 'follows', 'user'))\n",
      " |      tensor([ True, False])\n",
      " |      >>> g.has_edges_between(torch.tensor([1, 2]), torch.tensor([2, 3]),\n",
      " |      ...                     ('user', 'follows', 'game'))\n",
      " |      tensor([True, True])\n",
      " |  \n",
      " |  has_node(self, vid, ntype=None)\n",
      " |      Whether the graph has a particular node of a given type.\n",
      " |      \n",
      " |      **DEPRECATED**: see :func:`~DGLGraph.has_nodes`\n",
      " |  \n",
      " |  has_nodes(self, vid, ntype=None)\n",
      " |      Return whether the graph contains the given nodes.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      vid : node ID(s)\n",
      " |          The nodes IDs. The allowed nodes ID formats are:\n",
      " |      \n",
      " |          * ``int``: The ID of a single node.\n",
      " |          * Int Tensor: Each element is a node ID. The tensor must have the same device type\n",
      " |            and ID data type as the graph's.\n",
      " |          * iterable[int]: Each element is a node ID.\n",
      " |      \n",
      " |      ntype : str, optional\n",
      " |          The node type name. Can be omitted if there is\n",
      " |          only one type of nodes in the graph.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      bool or bool Tensor\n",
      " |          A tensor of bool flags where each element is True if the node is in the graph.\n",
      " |          If the input is a single node, return one bool value.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      Create a graph with two node types -- 'user' and 'game'.\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({\n",
      " |      ...     ('user', 'follows', 'user'): (torch.tensor([0, 1]), torch.tensor([1, 2])),\n",
      " |      ...     ('user', 'plays', 'game'): (torch.tensor([3, 4]), torch.tensor([0, 1]))\n",
      " |      ... })\n",
      " |      \n",
      " |      Query for the nodes.\n",
      " |      \n",
      " |      >>> g.has_nodes(0, 'user')\n",
      " |      True\n",
      " |      >>> g.has_nodes(3, 'game')\n",
      " |      False\n",
      " |      >>> g.has_nodes(torch.tensor([3, 0, 1]), 'game')\n",
      " |      tensor([False,  True,  True])\n",
      " |  \n",
      " |  in_degree(self, v, etype=None)\n",
      " |      Return the in-degree of node ``v`` with edges of type ``etype``.\n",
      " |      \n",
      " |      **DEPRECATED**: Please use in_degrees\n",
      " |  \n",
      " |  in_degrees(self, v='__ALL__', etype=None)\n",
      " |      Return the in-degree(s) of the given nodes.\n",
      " |      \n",
      " |      It computes the in-degree(s) w.r.t. to the edges of the given edge type.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      v : node IDs\n",
      " |          The node IDs. The allowed formats are:\n",
      " |      \n",
      " |          * ``int``: A single node.\n",
      " |          * Int Tensor: Each element is a node ID. The tensor must have the same device type\n",
      " |            and ID data type as the graph's.\n",
      " |          * iterable[int]: Each element is a node ID.\n",
      " |      \n",
      " |          If not given, return the in-degrees of all the nodes.\n",
      " |      etype : str or (str, str, str), optional\n",
      " |          The type name of the edges. The allowed type name formats are:\n",
      " |      \n",
      " |          * ``(str, str, str)`` for source node type, edge type and destination node type.\n",
      " |          * or one ``str`` edge type name if the name can uniquely identify a\n",
      " |            triplet format in the graph.\n",
      " |      \n",
      " |          Can be omitted if the graph has only one type of edges.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      int or Tensor\n",
      " |          The in-degree(s) of the node(s) in a Tensor. The i-th element is the in-degree\n",
      " |          of the i-th input node. If :attr:`v` is an ``int``, return an ``int`` too.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      Create a homogeneous graph.\n",
      " |      \n",
      " |      >>> g = dgl.graph((torch.tensor([0, 0, 1, 1]), torch.tensor([1, 1, 2, 3])))\n",
      " |      \n",
      " |      Query for all nodes.\n",
      " |      \n",
      " |      >>> g.in_degrees()\n",
      " |      tensor([0, 2, 1, 1])\n",
      " |      \n",
      " |      Query for nodes 1 and 2.\n",
      " |      \n",
      " |      >>> g.in_degrees(torch.tensor([1, 2]))\n",
      " |      tensor([2, 1])\n",
      " |      \n",
      " |      For a graph of multiple edge types, it is required to specify the edge type in query.\n",
      " |      \n",
      " |      >>> hg = dgl.heterograph({\n",
      " |      ...     ('user', 'follows', 'user'): (torch.tensor([0, 1]), torch.tensor([1, 2])),\n",
      " |      ...     ('user', 'plays', 'game'): (torch.tensor([3, 4]), torch.tensor([5, 6]))\n",
      " |      ... })\n",
      " |      >>> hg.in_degrees(torch.tensor([1, 0]), etype='follows')\n",
      " |      tensor([1, 0])\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      out_degrees\n",
      " |  \n",
      " |  in_edges(self, v, form='uv', etype=None)\n",
      " |      Return the incoming edges of the given nodes.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      v : node ID(s)\n",
      " |          The node IDs. The allowed formats are:\n",
      " |      \n",
      " |          * ``int``: A single node.\n",
      " |          * Int Tensor: Each element is a node ID. The tensor must have the same device type\n",
      " |            and ID data type as the graph's.\n",
      " |          * iterable[int]: Each element is a node ID.\n",
      " |      form : str, optional\n",
      " |          The result format, which can be one of the following:\n",
      " |      \n",
      " |          - ``'eid'``: The returned result is a 1D tensor :math:`EID`, representing\n",
      " |            the IDs of all edges.\n",
      " |          - ``'uv'`` (default): The returned result is a 2-tuple of 1D tensors :math:`(U, V)`,\n",
      " |            representing the source and destination nodes of all edges. For each :math:`i`,\n",
      " |            :math:`(U[i], V[i])` forms an edge.\n",
      " |          - ``'all'``: The returned result is a 3-tuple of 1D tensors :math:`(U, V, EID)`,\n",
      " |            representing the source nodes, destination nodes and IDs of all edges.\n",
      " |            For each :math:`i`, :math:`(U[i], V[i])` forms an edge with ID :math:`EID[i]`.\n",
      " |      etype : str or (str, str, str), optional\n",
      " |          The type names of the edges. The allowed type name formats are:\n",
      " |      \n",
      " |          * ``(str, str, str)`` for source node type, edge type and destination node type.\n",
      " |          * or one ``str`` edge type name if the name can uniquely identify a\n",
      " |            triplet format in the graph.\n",
      " |      \n",
      " |          Can be omitted if the graph has only one type of edges.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Tensor or (Tensor, Tensor) or (Tensor, Tensor, Tensor)\n",
      " |          All incoming edges of the nodes with the specified type. For a description of the\n",
      " |          returned result, see the description of :attr:`form`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      Create a homogeneous graph.\n",
      " |      \n",
      " |      >>> g = dgl.graph((torch.tensor([0, 0, 1, 1]), torch.tensor([1, 0, 2, 3])))\n",
      " |      \n",
      " |      Query for the nodes 1 and 0.\n",
      " |      \n",
      " |      >>> g.in_edges(torch.tensor([1, 0]))\n",
      " |      (tensor([0, 0]), tensor([1, 0]))\n",
      " |      \n",
      " |      Specify a different value for :attr:`form`.\n",
      " |      \n",
      " |      >>> g.in_edges(torch.tensor([1, 0]), form='all')\n",
      " |      (tensor([0, 0]), tensor([1, 0]), tensor([0, 1]))\n",
      " |      \n",
      " |      For a graph of multiple edge types, it is required to specify the edge type in query.\n",
      " |      \n",
      " |      >>> hg = dgl.heterograph({\n",
      " |      ...     ('user', 'follows', 'user'): (torch.tensor([0, 1]), torch.tensor([1, 2])),\n",
      " |      ...     ('user', 'plays', 'game'): (torch.tensor([3, 4]), torch.tensor([5, 6]))\n",
      " |      ... })\n",
      " |      >>> hg.in_edges(torch.tensor([1, 0]), etype='follows')\n",
      " |      (tensor([0]), tensor([1]))\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      edges\n",
      " |      out_edges\n",
      " |  \n",
      " |  in_subgraph(graph, nodes, *, relabel_nodes=False, store_ids=True, output_device=None)\n",
      " |      Alias of :func:`dgl.in_subgraph`.\n",
      " |  \n",
      " |  inc(self, typestr, ctx=device(type='cpu'), etype=None)\n",
      " |      Return the incidence matrix representation of edges with the given\n",
      " |      edge type.\n",
      " |      \n",
      " |      An incidence matrix is an n-by-m sparse matrix, where n is\n",
      " |      the number of nodes and m is the number of edges. Each nnz\n",
      " |      value indicating whether the edge is incident to the node\n",
      " |      or not.\n",
      " |      \n",
      " |      There are three types of incidence matrices :math:`I`:\n",
      " |      \n",
      " |      * ``in``:\n",
      " |      \n",
      " |          - :math:`I[v, e] = 1` if :math:`e` is the in-edge of :math:`v`\n",
      " |            (or :math:`v` is the dst node of :math:`e`);\n",
      " |          - :math:`I[v, e] = 0` otherwise.\n",
      " |      \n",
      " |      * ``out``:\n",
      " |      \n",
      " |          - :math:`I[v, e] = 1` if :math:`e` is the out-edge of :math:`v`\n",
      " |            (or :math:`v` is the src node of :math:`e`);\n",
      " |          - :math:`I[v, e] = 0` otherwise.\n",
      " |      \n",
      " |      * ``both`` (only if source and destination node type are the same):\n",
      " |      \n",
      " |          - :math:`I[v, e] = 1` if :math:`e` is the in-edge of :math:`v`;\n",
      " |          - :math:`I[v, e] = -1` if :math:`e` is the out-edge of :math:`v`;\n",
      " |          - :math:`I[v, e] = 0` otherwise (including self-loop).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      typestr : str\n",
      " |          Can be either ``in``, ``out`` or ``both``\n",
      " |      ctx : context, optional\n",
      " |          The context of returned incidence matrix. (Default: cpu)\n",
      " |      etype : str or (str, str, str), optional\n",
      " |          The type names of the edges. The allowed type name formats are:\n",
      " |      \n",
      " |          * ``(str, str, str)`` for source node type, edge type and destination node type.\n",
      " |          * or one ``str`` edge type name if the name can uniquely identify a\n",
      " |            triplet format in the graph.\n",
      " |      \n",
      " |          Can be omitted if the graph has only one type of edges.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Framework SparseTensor\n",
      " |          The incidence matrix.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      \n",
      " |      >>> g = dgl.graph(([0, 1], [0, 2]))\n",
      " |      >>> g.inc('in')\n",
      " |      tensor(indices=tensor([[0, 2],\n",
      " |                             [0, 1]]),\n",
      " |             values=tensor([1., 1.]),\n",
      " |             size=(3, 2), nnz=2, layout=torch.sparse_coo)\n",
      " |      >>> g.inc('out')\n",
      " |      tensor(indices=tensor([[0, 1],\n",
      " |                             [0, 1]]),\n",
      " |             values=tensor([1., 1.]),\n",
      " |             size=(3, 2), nnz=2, layout=torch.sparse_coo)\n",
      " |      >>> g.inc('both')\n",
      " |      tensor(indices=tensor([[1, 2],\n",
      " |                             [1, 1]]),\n",
      " |             values=tensor([-1.,  1.]),\n",
      " |             size=(3, 2), nnz=2, layout=torch.sparse_coo)\n",
      " |  \n",
      " |  incidence_matrix = inc(self, typestr, ctx=device(type='cpu'), etype=None)\n",
      " |  \n",
      " |  int(self)\n",
      " |      Cast the graph to one with idtype int32\n",
      " |      \n",
      " |      If the graph already has idtype int32, the function directly returns it. Otherwise,\n",
      " |      it returns a cloned graph of idtype int32 with features copied (shallow copy).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DGLGraph\n",
      " |          The graph of idtype int32.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      Create a graph of idtype int64.\n",
      " |      \n",
      " |      >>> # (0, 1), (0, 2), (1, 2)\n",
      " |      >>> g = dgl.graph((torch.tensor([0, 0, 1]), torch.tensor([1, 2, 2])))\n",
      " |      >>> g.ndata['feat'] = torch.ones(3, 1)\n",
      " |      >>> g.idtype\n",
      " |      torch.int64\n",
      " |      \n",
      " |      Cast the graph to one of idtype int32.\n",
      " |      \n",
      " |      >>> # A cloned graph with an idtype of int32\n",
      " |      >>> g_int = g.int()\n",
      " |      >>> g_int.idtype\n",
      " |      torch.int32\n",
      " |      >>> # The idtype of the original graph does not change.\n",
      " |      >>> g.idtype\n",
      " |      torch.int64\n",
      " |      >>> g_int.edges()\n",
      " |      (tensor([0, 0, 1], dtype=torch.int32), tensor([1, 2, 2], dtype=torch.int32))\n",
      " |      >>> g_int.ndata\n",
      " |      {'feat': tensor([[1.],\n",
      " |                       [1.],\n",
      " |                       [1.]])}\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      long\n",
      " |      idtype\n",
      " |  \n",
      " |  is_pinned(self)\n",
      " |      Check if the graph structure is pinned to the page-locked memory.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      bool\n",
      " |          True if the graph structure is pinned.\n",
      " |  \n",
      " |  khop_in_subgraph(graph, nodes, k, *, relabel_nodes=True, store_ids=True, output_device=None)\n",
      " |      Alias of :func:`dgl.khop_in_subgraph`.\n",
      " |  \n",
      " |  khop_out_subgraph(graph, nodes, k, *, relabel_nodes=True, store_ids=True, output_device=None)\n",
      " |      Alias of :func:`dgl.khop_out_subgraph`.\n",
      " |  \n",
      " |  line_graph(g, backtracking=True, shared=False)\n",
      " |      Alias of :func:`dgl.line_graph`.\n",
      " |  \n",
      " |  local_scope(self)\n",
      " |      Enter a local scope context for the graph.\n",
      " |      \n",
      " |      By entering a local scope, any out-place mutation to the feature data will\n",
      " |      not reflect to the original graph, thus making it easier to use in a function scope\n",
      " |      (e.g. forward computation of a model).\n",
      " |      \n",
      " |      If set, the local scope will use same initializers for node features and\n",
      " |      edge features.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Inplace operations do reflect to the original graph. This function also has little\n",
      " |      overhead when the number of feature tensors in this graph is small.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      Create a function for computation on graphs.\n",
      " |      \n",
      " |      >>> def foo(g):\n",
      " |      ...     with g.local_scope():\n",
      " |      ...         g.edata['h'] = torch.ones((g.num_edges(), 3))\n",
      " |      ...         g.edata['h2'] = torch.ones((g.num_edges(), 3))\n",
      " |      ...         return g.edata['h']\n",
      " |      \n",
      " |      ``local_scope`` avoids changing the graph features when exiting the function.\n",
      " |      \n",
      " |      >>> g = dgl.graph((torch.tensor([0, 1, 1]), torch.tensor([0, 0, 2])))\n",
      " |      >>> g.edata['h'] = torch.zeros((g.num_edges(), 3))\n",
      " |      >>> newh = foo(g)\n",
      " |      >>> print(g.edata['h'])  # still get tensor of all zeros\n",
      " |      tensor([[0., 0., 0.],\n",
      " |              [0., 0., 0.],\n",
      " |              [0., 0., 0.]])\n",
      " |      >>> 'h2' in g.edata      # new feature set in the function scope is not found\n",
      " |      False\n",
      " |      \n",
      " |      In-place operations will still reflect to the original graph.\n",
      " |      \n",
      " |      >>> def foo(g):\n",
      " |      ...     with g.local_scope():\n",
      " |      ...         # in-place operation\n",
      " |      ...         g.edata['h'] += 1\n",
      " |      ...         return g.edata['h']\n",
      " |      \n",
      " |      >>> g = dgl.graph((torch.tensor([0, 1, 1]), torch.tensor([0, 0, 2])))\n",
      " |      >>> g.edata['h'] = torch.zeros((g.num_edges(), 1))\n",
      " |      >>> newh = foo(g)\n",
      " |      >>> print(g.edata['h'])  # the result changes\n",
      " |      tensor([[1.],\n",
      " |              [1.],\n",
      " |              [1.]])\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      local_var\n",
      " |  \n",
      " |  local_var(self)\n",
      " |      Return a graph object for usage in a local function scope.\n",
      " |      \n",
      " |      The returned graph object shares the feature data and graph structure of this graph.\n",
      " |      However, any out-place mutation to the feature data will not reflect to this graph,\n",
      " |      thus making it easier to use in a function scope (e.g. forward computation of a model).\n",
      " |      \n",
      " |      If set, the local graph object will use same initializers for node features and\n",
      " |      edge features.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DGLGraph\n",
      " |          The graph object for a local variable.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Inplace operations do reflect to the original graph. This function also has little\n",
      " |      overhead when the number of feature tensors in this graph is small.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      Create a function for computation on graphs.\n",
      " |      \n",
      " |      >>> def foo(g):\n",
      " |      ...     g = g.local_var()\n",
      " |      ...     g.edata['h'] = torch.ones((g.num_edges(), 3))\n",
      " |      ...     g.edata['h2'] = torch.ones((g.num_edges(), 3))\n",
      " |      ...     return g.edata['h']\n",
      " |      \n",
      " |      ``local_var`` avoids changing the graph features when exiting the function.\n",
      " |      \n",
      " |      >>> g = dgl.graph((torch.tensor([0, 1, 1]), torch.tensor([0, 0, 2])))\n",
      " |      >>> g.edata['h'] = torch.zeros((g.num_edges(), 3))\n",
      " |      >>> newh = foo(g)\n",
      " |      >>> print(g.edata['h'])  # still get tensor of all zeros\n",
      " |      tensor([[0., 0., 0.],\n",
      " |              [0., 0., 0.],\n",
      " |              [0., 0., 0.]])\n",
      " |      >>> 'h2' in g.edata      # new feature set in the function scope is not found\n",
      " |      False\n",
      " |      \n",
      " |      In-place operations will still reflect to the original graph.\n",
      " |      \n",
      " |      >>> def foo(g):\n",
      " |      ...     g = g.local_var()\n",
      " |      ...     # in-place operation\n",
      " |      ...     g.edata['h'] += 1\n",
      " |      ...     return g.edata['h']\n",
      " |      \n",
      " |      >>> g = dgl.graph((torch.tensor([0, 1, 1]), torch.tensor([0, 0, 2])))\n",
      " |      >>> g.edata['h'] = torch.zeros((g.num_edges(), 1))\n",
      " |      >>> newh = foo(g)\n",
      " |      >>> print(g.edata['h'])  # the result changes\n",
      " |      tensor([[1.],\n",
      " |              [1.],\n",
      " |              [1.]])\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      local_scope\n",
      " |  \n",
      " |  long(self)\n",
      " |      Cast the graph to one with idtype int64\n",
      " |      \n",
      " |      If the graph already has idtype int64, the function directly returns it. Otherwise,\n",
      " |      it returns a cloned graph of idtype int64 with features copied (shallow copy).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DGLGraph\n",
      " |          The graph of idtype int64.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      Create a graph of idtype int32.\n",
      " |      \n",
      " |      >>> # (0, 1), (0, 2), (1, 2)\n",
      " |      >>> g = dgl.graph((torch.tensor([0, 0, 1]).int(), torch.tensor([1, 2, 2]).int()))\n",
      " |      >>> g.ndata['feat'] = torch.ones(3, 1)\n",
      " |      >>> g.idtype\n",
      " |      torch.int32\n",
      " |      \n",
      " |      Cast the graph to one of idtype int64.\n",
      " |      \n",
      " |      >>> # A cloned graph with an idtype of int64\n",
      " |      >>> g_long = g.long()\n",
      " |      >>> g_long.idtype\n",
      " |      torch.int64\n",
      " |      >>> # The idtype of the original graph does not change.\n",
      " |      >>> g.idtype\n",
      " |      torch.int32\n",
      " |      >>> g_long.edges()\n",
      " |      (tensor([0, 0, 1]), tensor([1, 2, 2]))\n",
      " |      >>> g_long.ndata\n",
      " |      {'feat': tensor([[1.],\n",
      " |                       [1.],\n",
      " |                       [1.]])}\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      int\n",
      " |      idtype\n",
      " |  \n",
      " |  metagraph(self)\n",
      " |      Return the metagraph of the heterograph.\n",
      " |      \n",
      " |      The metagraph (or network schema) of a heterogeneous network specifies type constraints\n",
      " |      on the sets of nodes and edges between the nodes. For a formal definition, refer to\n",
      " |      `Yizhou et al. <https://www.kdd.org/exploration_files/V14-02-03-Sun.pdf>`_.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      networkx.MultiDiGraph\n",
      " |          The metagraph.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({\n",
      " |      ...     ('user', 'follows', 'user'): (torch.tensor([0, 1]), torch.tensor([1, 2])),\n",
      " |      ...     ('user', 'follows', 'game'): (torch.tensor([0, 1, 2]), torch.tensor([1, 2, 3])),\n",
      " |      ...     ('user', 'plays', 'game'): (torch.tensor([1, 3]), torch.tensor([2, 3]))\n",
      " |      ... })\n",
      " |      >>> meta_g = g.metagraph()\n",
      " |      >>> meta_g.nodes()\n",
      " |      NodeView(('user', 'game'))\n",
      " |      >>> meta_g.edges()\n",
      " |      OutMultiEdgeDataView([('user', 'user'), ('user', 'game'), ('user', 'game')])\n",
      " |  \n",
      " |  multi_pull(self, v, etype_dict, cross_reducer, apply_node_func=None, inplace=False)\n",
      " |      **DEPRECATED**: The API is removed in v0.5.\n",
      " |  \n",
      " |  multi_recv(self, v, reducer_dict, cross_reducer, apply_node_func=None, inplace=False)\n",
      " |      Receive messages from multiple edge types and perform aggregation.\n",
      " |      \n",
      " |      DEPRECATE: please use multi_send_and_recv, multi_update_all.\n",
      " |  \n",
      " |  multi_send_and_recv(self, etype_dict, cross_reducer, apply_node_func=None, inplace=False)\n",
      " |      **DEPRECATED**: The API is removed in v0.5.\n",
      " |  \n",
      " |  multi_update_all(self, etype_dict, cross_reducer, apply_node_func=None)\n",
      " |      Send messages along all the edges, reduce them by first type-wisely\n",
      " |      then across different types, and then update the node features of all\n",
      " |      the nodes.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      etype_dict : dict\n",
      " |          Arguments for edge-type-wise message passing. The keys are edge types\n",
      " |          while the values are message passing arguments.\n",
      " |      \n",
      " |          The allowed key formats are:\n",
      " |      \n",
      " |          * ``(str, str, str)`` for source node type, edge type and destination node type.\n",
      " |          * or one ``str`` edge type name if the name can uniquely identify a\n",
      " |            triplet format in the graph.\n",
      " |      \n",
      " |          The value must be a tuple ``(message_func, reduce_func, [apply_node_func])``, where\n",
      " |      \n",
      " |          * message_func : dgl.function.BuiltinFunction or callable\n",
      " |              The message function to generate messages along the edges.\n",
      " |              It must be either a :ref:`api-built-in` or a :ref:`apiudf`.\n",
      " |          * reduce_func : dgl.function.BuiltinFunction or callable\n",
      " |              The reduce function to aggregate the messages.\n",
      " |              It must be either a :ref:`api-built-in` or a :ref:`apiudf`.\n",
      " |          * apply_node_func : callable, optional\n",
      " |              An optional apply function to further update the node features\n",
      " |              after the message reduction. It must be a :ref:`apiudf`.\n",
      " |      \n",
      " |      cross_reducer : str or callable function\n",
      " |          Cross type reducer. One of ``\"sum\"``, ``\"min\"``, ``\"max\"``, ``\"mean\"``, ``\"stack\"``\n",
      " |          or a callable function. If a callable function is provided, the input argument must be\n",
      " |          a single list of tensors containing aggregation results from each edge type, and the\n",
      " |          output of function must be a single tensor.\n",
      " |      apply_node_func : callable, optional\n",
      " |          An optional apply function after the messages are reduced both\n",
      " |          type-wisely and across different types.\n",
      " |          It must be a :ref:`apiudf`.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      DGL recommends using DGL's bulit-in function for the message_func\n",
      " |      and the reduce_func in the type-wise message passing arguments,\n",
      " |      because DGL will invoke efficient kernels that avoids copying node features to\n",
      " |      edge features in this case.\n",
      " |      \n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> import dgl\n",
      " |      >>> import dgl.function as fn\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      Instantiate a heterograph.\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({\n",
      " |      ...     ('user', 'follows', 'user'): ([0, 1], [1, 1]),\n",
      " |      ...     ('game', 'attracts', 'user'): ([0], [1])\n",
      " |      ... })\n",
      " |      >>> g.nodes['user'].data['h'] = torch.tensor([[1.], [2.]])\n",
      " |      >>> g.nodes['game'].data['h'] = torch.tensor([[1.]])\n",
      " |      \n",
      " |      Update all.\n",
      " |      \n",
      " |      >>> g.multi_update_all(\n",
      " |      ...     {'follows': (fn.copy_src('h', 'm'), fn.sum('m', 'h')),\n",
      " |      ...      'attracts': (fn.copy_src('h', 'm'), fn.sum('m', 'h'))},\n",
      " |      ... \"sum\")\n",
      " |      >>> g.nodes['user'].data['h']\n",
      " |      tensor([[0.],\n",
      " |              [4.]])\n",
      " |      \n",
      " |      User-defined cross reducer equivalent to \"sum\".\n",
      " |      \n",
      " |      >>> def cross_sum(flist):\n",
      " |      ...     return torch.sum(torch.stack(flist, dim=0), dim=0) if len(flist) > 1 else flist[0]\n",
      " |      \n",
      " |      Use the user-defined cross reducer.\n",
      " |      \n",
      " |      >>> g.multi_update_all(\n",
      " |      ...     {'follows': (fn.copy_src('h', 'm'), fn.sum('m', 'h')),\n",
      " |      ...      'attracts': (fn.copy_src('h', 'm'), fn.sum('m', 'h'))},\n",
      " |      ... cross_sum)\n",
      " |  \n",
      " |  node_attr_schemes(self, ntype=None)\n",
      " |      Return the node feature schemes for the specified type.\n",
      " |      \n",
      " |      The scheme of a feature describes the shape and data type of it.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      ntype : str, optional\n",
      " |          The node type name. Can be omitted if there is only one type of nodes\n",
      " |          in the graph.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      dict[str, Scheme]\n",
      " |          A dictionary mapping a feature name to its associated feature scheme.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      Query for a homogeneous graph.\n",
      " |      \n",
      " |      >>> g = dgl.graph((torch.tensor([0, 1]), torch.tensor([1, 2])))\n",
      " |      >>> g.ndata['h1'] = torch.randn(3, 1)\n",
      " |      >>> g.ndata['h2'] = torch.randn(3, 2)\n",
      " |      >>> g.node_attr_schemes()\n",
      " |      {'h1': Scheme(shape=(1,), dtype=torch.float32),\n",
      " |       'h2': Scheme(shape=(2,), dtype=torch.float32)}\n",
      " |      \n",
      " |      Query for a heterogeneous graph of multiple node types.\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({('user', 'plays', 'game'):\n",
      " |      ...                      (torch.tensor([1, 2]), torch.tensor([3, 4]))})\n",
      " |      >>> g.nodes['user'].data['h1'] = torch.randn(3, 1)\n",
      " |      >>> g.nodes['user'].data['h2'] = torch.randn(3, 2)\n",
      " |      >>> g.node_attr_schemes('user')\n",
      " |      {'h1': Scheme(shape=(1,), dtype=torch.float32),\n",
      " |       'h2': Scheme(shape=(2,), dtype=torch.float32)}\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      edge_attr_schemes\n",
      " |  \n",
      " |  node_type_subgraph(graph, ntypes, output_device=None)\n",
      " |      Alias of :func:`dgl.node_type_subgraph`.\n",
      " |  \n",
      " |  num_dst_nodes(self, ntype=None)\n",
      " |      Return the number of destination nodes in the graph.\n",
      " |      \n",
      " |      If the graph can further divide its node types into two subsets A and B where\n",
      " |      all the edeges are from nodes of types in A to nodes of types in B, we call\n",
      " |      this graph a *uni-bipartite* graph and the nodes in A being the *source*\n",
      " |      nodes and the ones in B being the *destination* nodes. If the graph is not\n",
      " |      uni-bipartite, the source and destination nodes are just the entire set of\n",
      " |      nodes in the graph.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      ntype : str, optional\n",
      " |          The destination node type name. If given, it returns the number of nodes of\n",
      " |          the destination node type. If not given (default), it returns the number of\n",
      " |          nodes summed over all the destination node types.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      int\n",
      " |          The number of nodes\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      num_src_nodes\n",
      " |      is_unibipartite\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      Create a homogeneous graph for query.\n",
      " |      \n",
      " |      >>> g = dgl.graph((torch.tensor([0, 1]), torch.tensor([1, 2])))\n",
      " |      >>> g.num_dst_nodes()\n",
      " |      3\n",
      " |      \n",
      " |      Create a heterogeneous graph with two destination node types -- 'user' and 'game'.\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({\n",
      " |      ...     ('user', 'follows', 'user'): (torch.tensor([0, 1]), torch.tensor([1, 2])),\n",
      " |      ...     ('user', 'plays', 'game'): (torch.tensor([3, 4]), torch.tensor([5, 6]))\n",
      " |      ... })\n",
      " |      \n",
      " |      Query for the number of nodes.\n",
      " |      \n",
      " |      >>> g.num_dst_nodes('user')\n",
      " |      5\n",
      " |      >>> g.num_dst_nodes('game')\n",
      " |      7\n",
      " |      >>> g.num_dst_nodes()\n",
      " |      12\n",
      " |  \n",
      " |  num_edges(self, etype=None)\n",
      " |      Return the number of edges in the graph.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      etype : str or (str, str, str), optional\n",
      " |          The type name of the edges. The allowed type name formats are:\n",
      " |      \n",
      " |          * ``(str, str, str)`` for source node type, edge type and destination node type.\n",
      " |          * or one ``str`` edge type name if the name can uniquely identify a\n",
      " |            triplet format in the graph.\n",
      " |      \n",
      " |          If not provided, return the total number of edges regardless of the types\n",
      " |          in the graph.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      int\n",
      " |          The number of edges.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      Create a graph with three canonical edge types.\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({\n",
      " |      ...     ('user', 'follows', 'user'): (torch.tensor([0, 1]), torch.tensor([1, 2])),\n",
      " |      ...     ('user', 'follows', 'game'): (torch.tensor([0, 1, 2]), torch.tensor([1, 2, 3])),\n",
      " |      ...     ('user', 'plays', 'game'): (torch.tensor([1, 3]), torch.tensor([2, 3]))\n",
      " |      ... })\n",
      " |      \n",
      " |      Query for the number of edges.\n",
      " |      \n",
      " |      >>> g.num_edges('plays')\n",
      " |      2\n",
      " |      >>> g.num_edges()\n",
      " |      7\n",
      " |      \n",
      " |      Use a canonical edge type instead when there is ambiguity for an edge type.\n",
      " |      \n",
      " |      >>> g.num_edges(('user', 'follows', 'user'))\n",
      " |      2\n",
      " |      >>> g.num_edges(('user', 'follows', 'game'))\n",
      " |      3\n",
      " |  \n",
      " |  num_nodes(self, ntype=None)\n",
      " |      Return the number of nodes in the graph.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      ntype : str, optional\n",
      " |          The node type name. If given, it returns the number of nodes of the\n",
      " |          type. If not given (default), it returns the total number of nodes of all types.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      int\n",
      " |          The number of nodes.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      Create a graph with two node types -- 'user' and 'game'.\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({\n",
      " |      ...     ('user', 'follows', 'user'): (torch.tensor([0, 1]), torch.tensor([1, 2])),\n",
      " |      ...     ('user', 'plays', 'game'): (torch.tensor([3, 4]), torch.tensor([5, 6]))\n",
      " |      ... })\n",
      " |      \n",
      " |      Query for the number of nodes.\n",
      " |      \n",
      " |      >>> g.num_nodes('user')\n",
      " |      5\n",
      " |      >>> g.num_nodes('game')\n",
      " |      7\n",
      " |      >>> g.num_nodes()\n",
      " |      12\n",
      " |  \n",
      " |  num_src_nodes(self, ntype=None)\n",
      " |      Return the number of source nodes in the graph.\n",
      " |      \n",
      " |      If the graph can further divide its node types into two subsets A and B where\n",
      " |      all the edeges are from nodes of types in A to nodes of types in B, we call\n",
      " |      this graph a *uni-bipartite* graph and the nodes in A being the *source*\n",
      " |      nodes and the ones in B being the *destination* nodes. If the graph is not\n",
      " |      uni-bipartite, the source and destination nodes are just the entire set of\n",
      " |      nodes in the graph.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      ntype : str, optional\n",
      " |          The source node type name. If given, it returns the number of nodes for\n",
      " |          the source node type. If not given (default), it returns the number of\n",
      " |          nodes summed over all source node types.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      int\n",
      " |          The number of nodes\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      num_dst_nodes\n",
      " |      is_unibipartite\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      Create a homogeneous graph for query.\n",
      " |      \n",
      " |      >>> g = dgl.graph((torch.tensor([0, 1]), torch.tensor([1, 2])))\n",
      " |      >>> g.num_src_nodes()\n",
      " |      3\n",
      " |      \n",
      " |      Create a heterogeneous graph with two source node types -- 'developer' and 'user'.\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({\n",
      " |      ...     ('developer', 'develops', 'game'): (torch.tensor([0, 1]), torch.tensor([1, 2])),\n",
      " |      ...     ('user', 'plays', 'game'): (torch.tensor([3, 4]), torch.tensor([5, 6]))\n",
      " |      ... })\n",
      " |      \n",
      " |      Query for the number of nodes.\n",
      " |      \n",
      " |      >>> g.num_src_nodes('developer')\n",
      " |      2\n",
      " |      >>> g.num_src_nodes('user')\n",
      " |      5\n",
      " |      >>> g.num_src_nodes()\n",
      " |      7\n",
      " |  \n",
      " |  number_of_dst_nodes(self, ntype=None)\n",
      " |      Alias of :func:`num_dst_nodes`\n",
      " |  \n",
      " |  number_of_edges(self, etype=None)\n",
      " |      Alias of :func:`num_edges`\n",
      " |  \n",
      " |  number_of_nodes(self, ntype=None)\n",
      " |      Alias of :meth:`num_nodes`\n",
      " |  \n",
      " |  number_of_src_nodes(self, ntype=None)\n",
      " |      Alias of :meth:`num_src_nodes`\n",
      " |  \n",
      " |  out_degree(self, u, etype=None)\n",
      " |      Return the out-degree of node `u` with edges of type ``etype``.\n",
      " |      \n",
      " |      DEPRECATED: please use DGL.out_degrees\n",
      " |  \n",
      " |  out_degrees(self, u='__ALL__', etype=None)\n",
      " |      Return the out-degree(s) of the given nodes.\n",
      " |      \n",
      " |      It computes the out-degree(s) w.r.t. to the edges of the given edge type.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      u : node IDs\n",
      " |          The node IDs. The allowed formats are:\n",
      " |      \n",
      " |          * ``int``: A single node.\n",
      " |          * Int Tensor: Each element is a node ID. The tensor must have the same device type\n",
      " |            and ID data type as the graph's.\n",
      " |          * iterable[int]: Each element is a node ID.\n",
      " |      \n",
      " |          If not given, return the in-degrees of all the nodes.\n",
      " |      etype : str or (str, str, str), optional\n",
      " |          The type names of the edges. The allowed type name formats are:\n",
      " |      \n",
      " |          * ``(str, str, str)`` for source node type, edge type and destination node type.\n",
      " |          * or one ``str`` edge type name if the name can uniquely identify a\n",
      " |            triplet format in the graph.\n",
      " |      \n",
      " |          Can be omitted if the graph has only one type of edges.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      int or Tensor\n",
      " |          The out-degree(s) of the node(s) in a Tensor. The i-th element is the out-degree\n",
      " |          of the i-th input node. If :attr:`v` is an ``int``, return an ``int`` too.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      Create a homogeneous graph.\n",
      " |      \n",
      " |      >>> g = dgl.graph((torch.tensor([0, 0, 1, 1]), torch.tensor([1, 1, 2, 3])))\n",
      " |      \n",
      " |      Query for all nodes.\n",
      " |      \n",
      " |      >>> g.out_degrees()\n",
      " |      tensor([2, 2, 0, 0])\n",
      " |      \n",
      " |      Query for nodes 1 and 2.\n",
      " |      \n",
      " |      >>> g.out_degrees(torch.tensor([1, 2]))\n",
      " |      tensor([2, 0])\n",
      " |      \n",
      " |      For a graph of multiple edge types, it is required to specify the edge type in query.\n",
      " |      \n",
      " |      >>> hg = dgl.heterograph({\n",
      " |      ...     ('user', 'follows', 'user'): (torch.tensor([0, 1]), torch.tensor([1, 2])),\n",
      " |      ...     ('user', 'plays', 'game'): (torch.tensor([3, 4]), torch.tensor([5, 6]))\n",
      " |      ... })\n",
      " |      >>> hg.out_degrees(torch.tensor([1, 0]), etype='follows')\n",
      " |      tensor([1, 1])\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      in_degrees\n",
      " |  \n",
      " |  out_edges(self, u, form='uv', etype=None)\n",
      " |      Return the outgoing edges of the given nodes.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      u : node ID(s)\n",
      " |          The node IDs. The allowed formats are:\n",
      " |      \n",
      " |          * ``int``: A single node.\n",
      " |          * Int Tensor: Each element is a node ID. The tensor must have the same device type\n",
      " |            and ID data type as the graph's.\n",
      " |          * iterable[int]: Each element is a node ID.\n",
      " |      form : str, optional\n",
      " |          The return form, which can be one of the following:\n",
      " |      \n",
      " |          - ``'eid'``: The returned result is a 1D tensor :math:`EID`, representing\n",
      " |            the IDs of all edges.\n",
      " |          - ``'uv'`` (default): The returned result is a 2-tuple of 1D tensors :math:`(U, V)`,\n",
      " |            representing the source and destination nodes of all edges. For each :math:`i`,\n",
      " |            :math:`(U[i], V[i])` forms an edge.\n",
      " |          - ``'all'``: The returned result is a 3-tuple of 1D tensors :math:`(U, V, EID)`,\n",
      " |            representing the source nodes, destination nodes and IDs of all edges.\n",
      " |            For each :math:`i`, :math:`(U[i], V[i])` forms an edge with ID :math:`EID[i]`.\n",
      " |      etype : str or (str, str, str), optional\n",
      " |          The type names of the edges. The allowed type name formats are:\n",
      " |      \n",
      " |          * ``(str, str, str)`` for source node type, edge type and destination node type.\n",
      " |          * or one ``str`` edge type name if the name can uniquely identify a\n",
      " |            triplet format in the graph.\n",
      " |      \n",
      " |          Can be omitted if the graph has only one type of edges.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Tensor or (Tensor, Tensor) or (Tensor, Tensor, Tensor)\n",
      " |          All outgoing edges of the nodes with the specified type. For a description of the\n",
      " |          returned result, see the description of :attr:`form`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      Create a homogeneous graph.\n",
      " |      \n",
      " |      >>> g = dgl.graph((torch.tensor([0, 0, 1, 1]), torch.tensor([1, 0, 2, 3])))\n",
      " |      \n",
      " |      Query for the nodes 1 and 2.\n",
      " |      \n",
      " |      >>> g.out_edges(torch.tensor([1, 2]))\n",
      " |      (tensor([1, 1]), tensor([2, 3]))\n",
      " |      \n",
      " |      Specify a different value for :attr:`form`.\n",
      " |      \n",
      " |      >>> g.out_edges(torch.tensor([1, 2]), form='all')\n",
      " |      (tensor([1, 1]), tensor([2, 3]), tensor([2, 3]))\n",
      " |      \n",
      " |      For a graph of multiple edge types, it is required to specify the edge type in query.\n",
      " |      \n",
      " |      >>> hg = dgl.heterograph({\n",
      " |      ...     ('user', 'follows', 'user'): (torch.tensor([0, 1]), torch.tensor([1, 2])),\n",
      " |      ...     ('user', 'plays', 'game'): (torch.tensor([3, 4]), torch.tensor([5, 6]))\n",
      " |      ... })\n",
      " |      >>> hg.out_edges(torch.tensor([1, 2]), etype='follows')\n",
      " |      (tensor([1]), tensor([2]))\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      edges\n",
      " |      in_edges\n",
      " |  \n",
      " |  out_subgraph(graph, nodes, *, relabel_nodes=False, store_ids=True, output_device=None)\n",
      " |      Alias of :func:`dgl.out_subgraph`.\n",
      " |  \n",
      " |  pin_memory_(self)\n",
      " |      Pin the graph structure and node/edge data to the page-locked memory for\n",
      " |      GPU zero-copy access.\n",
      " |      \n",
      " |      This is an **inplace** method. The graph structure must be on CPU to be pinned.\n",
      " |      If the graph struture is already pinned, the function directly returns it.\n",
      " |      \n",
      " |      Materialization of new sparse formats for pinned graphs is not allowed.\n",
      " |      To avoid implicit formats materialization during training,\n",
      " |      you should create all the needed formats before pinning.\n",
      " |      But cloning and materialization is fine. See the examples below.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DGLGraph\n",
      " |          The pinned graph.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      >>> g = dgl.graph((torch.tensor([1, 0]), torch.tensor([1, 2])))\n",
      " |      >>> g.pin_memory_()\n",
      " |      \n",
      " |      Materialization of new sparse formats is not allowed for pinned graphs.\n",
      " |      \n",
      " |      >>> g.create_formats_()  # This would raise an error! You should do this before pinning.\n",
      " |      \n",
      " |      Cloning and materializing new formats is allowed. The returned graph is **not** pinned.\n",
      " |      \n",
      " |      >>> g1 = g.formats(['csc'])\n",
      " |      >>> assert not g1.is_pinned()\n",
      " |      \n",
      " |      The pinned graph can be access from both CPU and GPU. The concrete device depends\n",
      " |      on the context of ``query``. For example, ``eid`` in ``find_edges()`` is a query.\n",
      " |      When ``eid`` is on CPU, ``find_edges()`` is executed on CPU, and the returned\n",
      " |      values are CPU tensors\n",
      " |      \n",
      " |      >>> g.unpin_memory_()\n",
      " |      >>> g.create_formats_()\n",
      " |      >>> g.pin_memory_()\n",
      " |      >>> eid = torch.tensor([1])\n",
      " |      >>> g.find_edges(eids)\n",
      " |      (tensor([0]), tensor([2]))\n",
      " |      \n",
      " |      Moving ``eid`` to GPU, ``find_edges()`` will be executed on GPU, and the returned\n",
      " |      values are GPU tensors.\n",
      " |      \n",
      " |      >>> eid = eid.to('cuda:0')\n",
      " |      >>> g.find_edges(eids)\n",
      " |      (tensor([0], device='cuda:0'), tensor([2], device='cuda:0'))\n",
      " |      \n",
      " |      If you don't provide a ``query``, methods will be executed on CPU by default.\n",
      " |      \n",
      " |      >>> g.in_degrees()\n",
      " |      tensor([0, 1, 1])\n",
      " |  \n",
      " |  predecessors(self, v, etype=None)\n",
      " |      Return the predecessor(s) of a particular node with the specified edge type.\n",
      " |      \n",
      " |      Node ``u`` is a predecessor of node ``v`` if there is an edge ``(u, v)`` with type\n",
      " |      ``etype`` in the graph.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      v : int\n",
      " |          The node ID. If the graph has multiple edge types, the ID is for the destination\n",
      " |          type corresponding to the edge type.\n",
      " |      etype : str or (str, str, str), optional\n",
      " |          The type names of the edges. The allowed type name formats are:\n",
      " |      \n",
      " |          * ``(str, str, str)`` for source node type, edge type and destination node type.\n",
      " |          * or one ``str`` edge type name if the name can uniquely identify a\n",
      " |            triplet format in the graph.\n",
      " |      \n",
      " |          Can be omitted if the graph has only one type of edges.\n",
      " |      \n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Tensor\n",
      " |          The predecessors of :attr:`v` with the specified edge type.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      Create a homogeneous graph.\n",
      " |      \n",
      " |      >>> g = dgl.graph((torch.tensor([0, 0, 1, 1]), torch.tensor([1, 1, 2, 3])))\n",
      " |      \n",
      " |      Query for node 1.\n",
      " |      \n",
      " |      >>> g.predecessors(1)\n",
      " |      tensor([0, 0])\n",
      " |      \n",
      " |      For a graph of multiple edge types, it is required to specify the edge type in query.\n",
      " |      \n",
      " |      >>> hg = dgl.heterograph({\n",
      " |      ...     ('user', 'follows', 'user'): (torch.tensor([0, 1]), torch.tensor([1, 2])),\n",
      " |      ...     ('user', 'plays', 'game'): (torch.tensor([3, 4]), torch.tensor([5, 6]))\n",
      " |      ... })\n",
      " |      >>> hg.predecessors(1, etype='follows')\n",
      " |      tensor([0])\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      successors\n",
      " |  \n",
      " |  prop_edges(self, edges_generator, message_func, reduce_func, apply_node_func=None, etype=None)\n",
      " |      Propagate messages using graph traversal by sequentially triggering\n",
      " |      :func:`send_and_recv()` on edges.\n",
      " |      \n",
      " |      The traversal order is specified by the ``edges_generator``. It generates\n",
      " |      edge frontiers. The edge frontiers should be of *valid edges type*.\n",
      " |      See :func:`send` for more details.\n",
      " |      \n",
      " |      Edges in the same frontier will be triggered together, and edges in\n",
      " |      different frontiers will be triggered according to the generating order.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      edges_generator : generator\n",
      " |          The generator of edge frontiers.\n",
      " |      message_func : dgl.function.BuiltinFunction or callable\n",
      " |          The message function to generate messages along the edges.\n",
      " |          It must be either a :ref:`api-built-in` or a :ref:`apiudf`.\n",
      " |      reduce_func : dgl.function.BuiltinFunction or callable\n",
      " |          The reduce function to aggregate the messages.\n",
      " |          It must be either a :ref:`api-built-in` or a :ref:`apiudf`.\n",
      " |      apply_node_func : callable, optional\n",
      " |          An optional apply function to further update the node features\n",
      " |          after the message reduction. It must be a :ref:`apiudf`.\n",
      " |      etype : str or (str, str, str), optional\n",
      " |          The type name of the edges. The allowed type name formats are:\n",
      " |      \n",
      " |          * ``(str, str, str)`` for source node type, edge type and destination node type.\n",
      " |          * or one ``str`` edge type name if the name can uniquely identify a\n",
      " |            triplet format in the graph.\n",
      " |      \n",
      " |          Can be omitted if the graph has only one type of edges.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> import torch\n",
      " |      >>> import dgl\n",
      " |      >>> import dgl.function as fn\n",
      " |      \n",
      " |      Instantiate a heterogrph and perform multiple rounds of message passing.\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({('user', 'follows', 'user'): ([0, 1, 2, 3], [2, 3, 4, 4])})\n",
      " |      >>> g.nodes['user'].data['h'] = torch.tensor([[1.], [2.], [3.], [4.], [5.]])\n",
      " |      >>> g['follows'].prop_edges([[0, 1], [2, 3]], fn.copy_src('h', 'm'),\n",
      " |      ...                         fn.sum('m', 'h'), etype='follows')\n",
      " |      >>> g.nodes['user'].data['h']\n",
      " |      tensor([[1.],\n",
      " |              [2.],\n",
      " |              [1.],\n",
      " |              [2.],\n",
      " |              [3.]])\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      prop_nodes\n",
      " |  \n",
      " |  prop_nodes(self, nodes_generator, message_func, reduce_func, apply_node_func=None, etype=None)\n",
      " |      Propagate messages using graph traversal by sequentially triggering\n",
      " |      :func:`pull()` on nodes.\n",
      " |      \n",
      " |      The traversal order is specified by the ``nodes_generator``. It generates\n",
      " |      node frontiers, which is a list or a tensor of nodes. The nodes in the\n",
      " |      same frontier will be triggered together, while nodes in different frontiers\n",
      " |      will be triggered according to the generating order.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      nodes_generator : iterable[node IDs]\n",
      " |          The generator of node frontiers. Each frontier is a set of node IDs\n",
      " |          stored in Tensor or python iterables.\n",
      " |          It specifies which nodes perform :func:`pull` at each step.\n",
      " |      message_func : dgl.function.BuiltinFunction or callable\n",
      " |          The message function to generate messages along the edges.\n",
      " |          It must be either a :ref:`api-built-in` or a :ref:`apiudf`.\n",
      " |      reduce_func : dgl.function.BuiltinFunction or callable\n",
      " |          The reduce function to aggregate the messages.\n",
      " |          It must be either a :ref:`api-built-in` or a :ref:`apiudf`.\n",
      " |      apply_node_func : callable, optional\n",
      " |          An optional apply function to further update the node features\n",
      " |          after the message reduction. It must be a :ref:`apiudf`.\n",
      " |      etype : str or (str, str, str), optional\n",
      " |          The type name of the edges. The allowed type name formats are:\n",
      " |      \n",
      " |          * ``(str, str, str)`` for source node type, edge type and destination node type.\n",
      " |          * or one ``str`` edge type name if the name can uniquely identify a\n",
      " |            triplet format in the graph.\n",
      " |      \n",
      " |          Can be omitted if the graph has only one type of edges.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> import torch\n",
      " |      >>> import dgl\n",
      " |      >>> import dgl.function as fn\n",
      " |      \n",
      " |      Instantiate a heterogrph and perform multiple rounds of message passing.\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({('user', 'follows', 'user'): ([0, 1, 2, 3], [2, 3, 4, 4])})\n",
      " |      >>> g.nodes['user'].data['h'] = torch.tensor([[1.], [2.], [3.], [4.], [5.]])\n",
      " |      >>> g['follows'].prop_nodes([[2, 3], [4]], fn.copy_src('h', 'm'),\n",
      " |      ...                         fn.sum('m', 'h'), etype='follows')\n",
      " |      tensor([[1.],\n",
      " |              [2.],\n",
      " |              [1.],\n",
      " |              [2.],\n",
      " |              [3.]])\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      prop_edges\n",
      " |  \n",
      " |  pull(self, v, message_func, reduce_func, apply_node_func=None, etype=None, inplace=False)\n",
      " |      Pull messages from the specified node(s)' predecessors along the\n",
      " |      specified edge type, aggregate them to update the node features.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      v : node IDs\n",
      " |          The node IDs. The allowed formats are:\n",
      " |      \n",
      " |          * ``int``: A single node.\n",
      " |          * Int Tensor: Each element is a node ID. The tensor must have the same device type\n",
      " |            and ID data type as the graph's.\n",
      " |          * iterable[int]: Each element is a node ID.\n",
      " |      \n",
      " |      message_func : dgl.function.BuiltinFunction or callable\n",
      " |          The message function to generate messages along the edges.\n",
      " |          It must be either a :ref:`api-built-in` or a :ref:`apiudf`.\n",
      " |      reduce_func : dgl.function.BuiltinFunction or callable\n",
      " |          The reduce function to aggregate the messages.\n",
      " |          It must be either a :ref:`api-built-in` or a :ref:`apiudf`.\n",
      " |      apply_node_func : callable, optional\n",
      " |          An optional apply function to further update the node features\n",
      " |          after the message reduction. It must be a :ref:`apiudf`.\n",
      " |      etype : str or (str, str, str), optional\n",
      " |          The type name of the edges. The allowed type name formats are:\n",
      " |      \n",
      " |          * ``(str, str, str)`` for source node type, edge type and destination node type.\n",
      " |          * or one ``str`` edge type name if the name can uniquely identify a\n",
      " |            triplet format in the graph.\n",
      " |      \n",
      " |          Can be omitted if the graph has only one type of edges.\n",
      " |      \n",
      " |      inplace: bool, optional\n",
      " |          **DEPRECATED**.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      * If some of the given nodes :attr:`v` has no in-edges, DGL does not invoke\n",
      " |        message and reduce functions for these nodes and fill their aggregated messages\n",
      " |        with zero. Users can control the filled values via :meth:`set_n_initializer`.\n",
      " |        DGL still invokes :attr:`apply_node_func` if provided.\n",
      " |      * DGL recommends using DGL's bulit-in function for the :attr:`message_func`\n",
      " |        and the :attr:`reduce_func` arguments,\n",
      " |        because DGL will invoke efficient kernels that avoids copying node features to\n",
      " |        edge features in this case.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import dgl.function as fn\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      **Homogeneous graph**\n",
      " |      \n",
      " |      >>> g = dgl.graph(([0, 1, 2, 3], [1, 2, 3, 4]))\n",
      " |      >>> g.ndata['x'] = torch.ones(5, 2)\n",
      " |      >>> g.pull([0, 3, 4], fn.copy_u('x', 'm'), fn.sum('m', 'h'))\n",
      " |      >>> g.ndata['h']\n",
      " |      tensor([[0., 0.],\n",
      " |              [0., 0.],\n",
      " |              [0., 0.],\n",
      " |              [1., 1.],\n",
      " |              [1., 1.]])\n",
      " |      \n",
      " |      **Heterogeneous graph**\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({\n",
      " |      ...     ('user', 'follows', 'user'): ([0, 1], [1, 2]),\n",
      " |      ...     ('user', 'plays', 'game'): ([0, 2], [0, 1])\n",
      " |      ... })\n",
      " |      >>> g.nodes['user'].data['h'] = torch.tensor([[0.], [1.], [2.]])\n",
      " |      \n",
      " |      Pull.\n",
      " |      \n",
      " |      >>> g['follows'].pull(2, fn.copy_src('h', 'm'), fn.sum('m', 'h'), etype='follows')\n",
      " |      >>> g.nodes['user'].data['h']\n",
      " |      tensor([[0.],\n",
      " |              [1.],\n",
      " |              [1.]])\n",
      " |  \n",
      " |  push(self, u, message_func, reduce_func, apply_node_func=None, etype=None, inplace=False)\n",
      " |      Send message from the specified node(s) to their successors\n",
      " |      along the specified edge type and update their node features.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      v : node IDs\n",
      " |          The node IDs. The allowed formats are:\n",
      " |      \n",
      " |          * ``int``: A single node.\n",
      " |          * Int Tensor: Each element is a node ID. The tensor must have the same device type\n",
      " |            and ID data type as the graph's.\n",
      " |          * iterable[int]: Each element is a node ID.\n",
      " |      \n",
      " |      message_func : dgl.function.BuiltinFunction or callable\n",
      " |          The message function to generate messages along the edges.\n",
      " |          It must be either a :ref:`api-built-in` or a :ref:`apiudf`.\n",
      " |      reduce_func : dgl.function.BuiltinFunction or callable\n",
      " |          The reduce function to aggregate the messages.\n",
      " |          It must be either a :ref:`api-built-in` or a :ref:`apiudf`.\n",
      " |      apply_node_func : callable, optional\n",
      " |          An optional apply function to further update the node features\n",
      " |          after the message reduction. It must be a :ref:`apiudf`.\n",
      " |      etype : str or (str, str, str), optional\n",
      " |          The type name of the edges. The allowed type name formats are:\n",
      " |      \n",
      " |          * ``(str, str, str)`` for source node type, edge type and destination node type.\n",
      " |          * or one ``str`` edge type name if the name can uniquely identify a\n",
      " |            triplet format in the graph.\n",
      " |      \n",
      " |          Can be omitted if the graph has only one type of edges.\n",
      " |      \n",
      " |      inplace: bool, optional\n",
      " |          **DEPRECATED**.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      DGL recommends using DGL's bulit-in function for the :attr:`message_func`\n",
      " |      and the :attr:`reduce_func` arguments,\n",
      " |      because DGL will invoke efficient kernels that avoids copying node features to\n",
      " |      edge features in this case.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import dgl.function as fn\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      **Homogeneous graph**\n",
      " |      \n",
      " |      >>> g = dgl.graph(([0, 1, 2, 3], [1, 2, 3, 4]))\n",
      " |      >>> g.ndata['x'] = torch.ones(5, 2)\n",
      " |      >>> g.push([0, 1], fn.copy_u('x', 'm'), fn.sum('m', 'h'))\n",
      " |      >>> g.ndata['h']\n",
      " |      tensor([[0., 0.],\n",
      " |              [1., 1.],\n",
      " |              [1., 1.],\n",
      " |              [0., 0.],\n",
      " |              [0., 0.]])\n",
      " |      \n",
      " |      **Heterogeneous graph**\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({('user', 'follows', 'user'): ([0, 0], [1, 2])})\n",
      " |      >>> g.nodes['user'].data['h'] = torch.tensor([[0.], [1.], [2.]])\n",
      " |      \n",
      " |      Push.\n",
      " |      \n",
      " |      >>> g['follows'].push(0, fn.copy_src('h', 'm'), fn.sum('m', 'h'), etype='follows')\n",
      " |      >>> g.nodes['user'].data['h']\n",
      " |      tensor([[0.],\n",
      " |              [0.],\n",
      " |              [0.]])\n",
      " |  \n",
      " |  readonly(self, readonly_state=True)\n",
      " |      Deprecated: DGLGraph will always be mutable.\n",
      " |  \n",
      " |  record_stream(self, stream)\n",
      " |      Record the stream that is using this graph.\n",
      " |      This method only supports the PyTorch backend and requires graphs on the GPU.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      stream : torch.cuda.Stream\n",
      " |          The stream that is using this graph.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DGLGraph\n",
      " |          self.\n",
      " |  \n",
      " |  recv(self, v, reduce_func, apply_node_func=None, etype=None, inplace=False)\n",
      " |      Receive and reduce incoming messages and update the features of node(s) :math:`v`.\n",
      " |      \n",
      " |      DEPRECATE: please use send_and_recv, update_all.\n",
      " |  \n",
      " |  register_apply_edge_func(self, func)\n",
      " |      Deprecated: please directly call :func:`apply_edges` with ``func``\n",
      " |      as argument.\n",
      " |  \n",
      " |  register_apply_node_func(self, func)\n",
      " |      Deprecated: please directly call :func:`apply_nodes` with ``func``\n",
      " |      as argument.\n",
      " |  \n",
      " |  register_message_func(self, func)\n",
      " |      Deprecated: please directly call :func:`update_all` with ``func``\n",
      " |      as argument.\n",
      " |  \n",
      " |  register_reduce_func(self, func)\n",
      " |      Deprecated: please directly call :func:`update_all` with ``func``\n",
      " |      as argument.\n",
      " |  \n",
      " |  remove_edges(self, eids, etype=None, store_ids=False)\n",
      " |      Remove multiple edges with the specified edge type\n",
      " |      \n",
      " |      Nodes will not be removed. After removing edges, the rest\n",
      " |      edges will be re-indexed using consecutive integers from 0,\n",
      " |      with their relative order preserved.\n",
      " |      \n",
      " |      The features for the removed edges will be removed accordingly.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      eids : int, tensor, numpy.ndarray, list\n",
      " |          IDs for the edges to remove.\n",
      " |      etype : str or tuple of str, optional\n",
      " |          The type of the edges to remove. Can be omitted if there is\n",
      " |          only one edge type in the graph.\n",
      " |      store_ids : bool, optional\n",
      " |          If True, it will store the raw IDs of the extracted nodes and edges in the ``ndata``\n",
      " |          and ``edata`` of the resulting graph under name ``dgl.NID`` and ``dgl.EID``,\n",
      " |          respectively.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This function preserves the batch information.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      **Homogeneous Graphs or Heterogeneous Graphs with A Single Edge Type**\n",
      " |      \n",
      " |      >>> g = dgl.graph((torch.tensor([0, 0, 2]), torch.tensor([0, 1, 2])))\n",
      " |      >>> g.edata['he'] = torch.arange(3).float().reshape(-1, 1)\n",
      " |      >>> g.remove_edges(torch.tensor([0, 1]))\n",
      " |      >>> g\n",
      " |      Graph(num_nodes=3, num_edges=1,\n",
      " |          ndata_schemes={}\n",
      " |          edata_schemes={'he': Scheme(shape=(1,), dtype=torch.float32)})\n",
      " |      >>> g.edges('all')\n",
      " |      (tensor([2]), tensor([2]), tensor([0]))\n",
      " |      >>> g.edata['he']\n",
      " |      tensor([[2.]])\n",
      " |      \n",
      " |      Removing edges from a batched graph preserves batch information.\n",
      " |      \n",
      " |      >>> g = dgl.graph((torch.tensor([0, 0, 2]), torch.tensor([0, 1, 2])))\n",
      " |      >>> g2 = dgl.graph((torch.tensor([1, 2, 3]), torch.tensor([1, 3, 4])))\n",
      " |      >>> bg = dgl.batch([g, g2])\n",
      " |      >>> bg.batch_num_edges()\n",
      " |      tensor([3, 3])\n",
      " |      >>> bg.remove_edges([1, 4])\n",
      " |      >>> bg.batch_num_edges()\n",
      " |      tensor([2, 2])\n",
      " |      \n",
      " |      **Heterogeneous Graphs with Multiple Edge Types**\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({\n",
      " |      ...     ('user', 'plays', 'game'): (torch.tensor([0, 1, 1, 2]),\n",
      " |      ...                                 torch.tensor([0, 0, 1, 1])),\n",
      " |      ...     ('developer', 'develops', 'game'): (torch.tensor([0, 1]),\n",
      " |      ...                                         torch.tensor([0, 1]))\n",
      " |      ...     })\n",
      " |      >>> g.remove_edges(torch.tensor([0, 1]))\n",
      " |      DGLError: Edge type name must be specified\n",
      " |      if there are more than one edge types.\n",
      " |      >>> g.remove_edges(torch.tensor([0, 1]), 'plays')\n",
      " |      >>> g.edges('all', etype='plays')\n",
      " |      (tensor([0, 1]), tensor([0, 0]), tensor([0, 1]))\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      add_nodes\n",
      " |      add_edges\n",
      " |      remove_nodes\n",
      " |  \n",
      " |  remove_nodes(self, nids, ntype=None, store_ids=False)\n",
      " |      Remove multiple nodes with the specified node type\n",
      " |      \n",
      " |      Edges that connect to the nodes will be removed as well. After removing\n",
      " |      nodes and edges, the rest nodes and edges will be re-indexed using\n",
      " |      consecutive integers from 0, with their relative order preserved.\n",
      " |      \n",
      " |      The features for the removed nodes/edges will be removed accordingly.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      nids : int, tensor, numpy.ndarray, list\n",
      " |          Nodes to remove.\n",
      " |      ntype : str, optional\n",
      " |          The type of the nodes to remove. Can be omitted if there is\n",
      " |          only one node type in the graph.\n",
      " |      store_ids : bool, optional\n",
      " |          If True, it will store the raw IDs of the extracted nodes and edges in the ``ndata``\n",
      " |          and ``edata`` of the resulting graph under name ``dgl.NID`` and ``dgl.EID``,\n",
      " |          respectively.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This function preserves the batch information.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      **Homogeneous Graphs or Heterogeneous Graphs with A Single Node Type**\n",
      " |      \n",
      " |      >>> g = dgl.graph((torch.tensor([0, 0, 2]), torch.tensor([0, 1, 2])))\n",
      " |      >>> g.ndata['hv'] = torch.arange(3).float().reshape(-1, 1)\n",
      " |      >>> g.edata['he'] = torch.arange(3).float().reshape(-1, 1)\n",
      " |      >>> g.remove_nodes(torch.tensor([0, 1]))\n",
      " |      >>> g\n",
      " |      Graph(num_nodes=1, num_edges=1,\n",
      " |          ndata_schemes={'hv': Scheme(shape=(1,), dtype=torch.float32)}\n",
      " |          edata_schemes={'he': Scheme(shape=(1,), dtype=torch.float32)})\n",
      " |      >>> g.ndata['hv']\n",
      " |      tensor([[2.]])\n",
      " |      >>> g.edata['he']\n",
      " |      tensor([[2.]])\n",
      " |      \n",
      " |      Removing nodes from a batched graph preserves batch information.\n",
      " |      \n",
      " |      >>> g = dgl.graph((torch.tensor([0, 0, 2]), torch.tensor([0, 1, 2])))\n",
      " |      >>> g2 = dgl.graph((torch.tensor([1, 2, 3]), torch.tensor([1, 3, 4])))\n",
      " |      >>> bg = dgl.batch([g, g2])\n",
      " |      >>> bg.batch_num_nodes()\n",
      " |      tensor([3, 5])\n",
      " |      >>> bg.remove_nodes([1, 4])\n",
      " |      >>> bg.batch_num_nodes()\n",
      " |      tensor([2, 4])\n",
      " |      >>> bg.batch_num_edges()\n",
      " |      tensor([2, 2])\n",
      " |      \n",
      " |      **Heterogeneous Graphs with Multiple Node Types**\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({\n",
      " |      ...     ('user', 'plays', 'game'): (torch.tensor([0, 1, 1, 2]),\n",
      " |      ...                                 torch.tensor([0, 0, 1, 1])),\n",
      " |      ...     ('developer', 'develops', 'game'): (torch.tensor([0, 1]),\n",
      " |      ...                                         torch.tensor([0, 1]))\n",
      " |      ...     })\n",
      " |      >>> g.remove_nodes(torch.tensor([0, 1]))\n",
      " |      DGLError: Node type name must be specified\n",
      " |      if there are more than one node types.\n",
      " |      >>> g.remove_nodes(torch.tensor([0, 1]), ntype='game')\n",
      " |      >>> g.num_nodes('user')\n",
      " |      3\n",
      " |      >>> g.num_nodes('game')\n",
      " |      0\n",
      " |      >>> g.num_edges('plays')\n",
      " |      0\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      add_nodes\n",
      " |      add_edges\n",
      " |      remove_edges\n",
      " |  \n",
      " |  remove_self_loop(g, etype=None)\n",
      " |      Alias of :func:`dgl.remove_self_loop`.\n",
      " |  \n",
      " |  reorder_graph(g, node_permute_algo=None, edge_permute_algo='src', store_ids=True, permute_config=None)\n",
      " |      Alias of :func:`dgl.reorder_graph`.\n",
      " |  \n",
      " |  reverse(g, copy_ndata=True, copy_edata=False, *, share_ndata=None, share_edata=None)\n",
      " |      Alias of :func:`dgl.reverse`.\n",
      " |  \n",
      " |  sample_etype_neighbors(g, nodes, etype_field, fanout, edge_dir='in', prob=None, replace=False, copy_ndata=True, copy_edata=True, etype_sorted=False, _dist_training=False, output_device=None)\n",
      " |      Alias of :func:`dgl.sample_etype_neighbors`.\n",
      " |  \n",
      " |  sample_neighbors(g, nodes, fanout, edge_dir='in', prob=None, replace=False, copy_ndata=True, copy_edata=True, _dist_training=False, exclude_edges=None, output_device=None)\n",
      " |      Alias of :func:`dgl.sample_neighbors`.\n",
      " |  \n",
      " |  sample_neighbors_biased(g, nodes, fanout, bias, edge_dir='in', tag_offset_name='_TAG_OFFSET', replace=False, copy_ndata=True, copy_edata=True, output_device=None)\n",
      " |      Alias of :func:`dgl.sample_neighbors_biased`.\n",
      " |  \n",
      " |  select_topk(g, k, weight, nodes=None, edge_dir='in', ascending=False, copy_ndata=True, copy_edata=True, output_device=None)\n",
      " |      Alias of :func:`dgl.select_topk`.\n",
      " |  \n",
      " |  send(self, edges, message_func, etype=None)\n",
      " |      Send messages along the given edges with the same edge type.\n",
      " |      \n",
      " |      DEPRECATE: please use send_and_recv, update_all.\n",
      " |  \n",
      " |  send_and_recv(self, edges, message_func, reduce_func, apply_node_func=None, etype=None, inplace=False)\n",
      " |      Send messages along the specified edges and reduce them on\n",
      " |      the destination nodes to update their features.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      edges : edges\n",
      " |          The edges to send and receive messages on. The allowed input formats are:\n",
      " |      \n",
      " |          * ``int``: A single edge ID.\n",
      " |          * Int Tensor: Each element is an edge ID.  The tensor must have the same device type\n",
      " |            and ID data type as the graph's.\n",
      " |          * iterable[int]: Each element is an edge ID.\n",
      " |          * (Tensor, Tensor): The node-tensors format where the i-th elements\n",
      " |            of the two tensors specify an edge.\n",
      " |          * (iterable[int], iterable[int]): Similar to the node-tensors format but\n",
      " |            stores edge endpoints in python iterables.\n",
      " |      \n",
      " |      message_func : dgl.function.BuiltinFunction or callable\n",
      " |          The message function to generate messages along the edges.\n",
      " |          It must be either a :ref:`api-built-in` or a :ref:`apiudf`.\n",
      " |      reduce_func : dgl.function.BuiltinFunction or callable\n",
      " |          The reduce function to aggregate the messages.\n",
      " |          It must be either a :ref:`api-built-in` or a :ref:`apiudf`.\n",
      " |      apply_node_func : callable, optional\n",
      " |          An optional apply function to further update the node features\n",
      " |          after the message reduction. It must be a :ref:`apiudf`.\n",
      " |      etype : str or (str, str, str), optional\n",
      " |          The type name of the edges. The allowed type name formats are:\n",
      " |      \n",
      " |          * ``(str, str, str)`` for source node type, edge type and destination node type.\n",
      " |          * or one ``str`` edge type name if the name can uniquely identify a\n",
      " |            triplet format in the graph.\n",
      " |      \n",
      " |          Can be omitted if the graph has only one type of edges.\n",
      " |      \n",
      " |      inplace: bool, optional\n",
      " |          **DEPRECATED**.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      DGL recommends using DGL's bulit-in function for the :attr:`message_func`\n",
      " |      and the :attr:`reduce_func` arguments,\n",
      " |      because DGL will invoke efficient kernels that avoids copying node features to\n",
      " |      edge features in this case.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import dgl.function as fn\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      **Homogeneous graph**\n",
      " |      \n",
      " |      >>> g = dgl.graph(([0, 1, 2, 3], [1, 2, 3, 4]))\n",
      " |      >>> g.ndata['x'] = torch.ones(5, 2)\n",
      " |      >>> # Specify edges using (Tensor, Tensor).\n",
      " |      >>> g.send_and_recv(([1, 2], [2, 3]), fn.copy_u('x', 'm'), fn.sum('m', 'h'))\n",
      " |      >>> g.ndata['h']\n",
      " |      tensor([[0., 0.],\n",
      " |              [0., 0.],\n",
      " |              [1., 1.],\n",
      " |              [1., 1.],\n",
      " |              [0., 0.]])\n",
      " |      >>> # Specify edges using IDs.\n",
      " |      >>> g.send_and_recv([0, 2, 3], fn.copy_u('x', 'm'), fn.sum('m', 'h'))\n",
      " |      >>> g.ndata['h']\n",
      " |      tensor([[0., 0.],\n",
      " |              [1., 1.],\n",
      " |              [0., 0.],\n",
      " |              [1., 1.],\n",
      " |              [1., 1.]])\n",
      " |      \n",
      " |      **Heterogeneous graph**\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({\n",
      " |      ...     ('user', 'follows', 'user'): ([0, 1], [1, 2]),\n",
      " |      ...     ('user', 'plays', 'game'): ([0, 1, 1, 2], [0, 0, 1, 1])\n",
      " |      ... })\n",
      " |      >>> g.nodes['user'].data['h'] = torch.tensor([[0.], [1.], [2.]])\n",
      " |      >>> g.send_and_recv(g['follows'].edges(), fn.copy_src('h', 'm'),\n",
      " |      ...                 fn.sum('m', 'h'), etype='follows')\n",
      " |      >>> g.nodes['user'].data['h']\n",
      " |      tensor([[0.],\n",
      " |              [0.],\n",
      " |              [1.]])\n",
      " |      \n",
      " |      **``send_and_recv`` using user-defined functions**\n",
      " |      \n",
      " |      >>> import torch as th\n",
      " |      >>> g = dgl.graph(([0, 1], [1, 2]))\n",
      " |      >>> g.ndata['x'] = th.tensor([[1.], [2.], [3.]])\n",
      " |      \n",
      " |      >>> # Define the function for sending node features as messages.\n",
      " |      >>> def send_source(edges):\n",
      " |      ...     return {'m': edges.src['x']}\n",
      " |      >>> # Sum the messages received and use this to replace the original node feature.\n",
      " |      >>> def simple_reduce(nodes):\n",
      " |      ...     return {'x': nodes.mailbox['m'].sum(1)}\n",
      " |      \n",
      " |      Send and receive messages.\n",
      " |      \n",
      " |      >>> g.send_and_recv(g.edges())\n",
      " |      >>> g.ndata['x']\n",
      " |      tensor([[1.],\n",
      " |              [1.],\n",
      " |              [2.]])\n",
      " |      \n",
      " |      Note that the feature of node 0 remains the same as it has no incoming edges.\n",
      " |  \n",
      " |  set_batch_num_edges(self, val)\n",
      " |      Manually set the number of edges for each graph in the batch with the specified edge\n",
      " |      type.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      val : Tensor or Mapping[str, Tensor]\n",
      " |          The dictionary storing number of edges for each graph in the batch for all edge types.\n",
      " |          If the graph has only one edge type, ``val`` can also be a single array indicating the\n",
      " |          number of edges per graph in the batch.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This API is always used together with ``set_batch_num_nodes`` to specify batching\n",
      " |      information of a graph, it also do not check the correspondance between the graph structure\n",
      " |      and batching information and user must guarantee there will be no cross-graph edges in the\n",
      " |      batch.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      Create a homogeneous graph.\n",
      " |      \n",
      " |      >>> g = dgl.graph(([0, 1, 2, 3, 4, 5], [1, 2, 0, 4, 5, 3]))\n",
      " |      \n",
      " |      Manually set batch information\n",
      " |      \n",
      " |      >>> g.set_batch_num_nodes(torch.tensor([3, 3]))\n",
      " |      >>> g.set_batch_num_edges(torch.tensor([3, 3]))\n",
      " |      \n",
      " |      Unbatch the graph.\n",
      " |      \n",
      " |      >>> dgl.unbatch(g)\n",
      " |      [Graph(num_nodes=3, num_edges=3,\n",
      " |            ndata_schemes={}\n",
      " |            edata_schemes={}), Graph(num_nodes=3, num_edges=3,\n",
      " |            ndata_schemes={}\n",
      " |            edata_schemes={})]\n",
      " |      \n",
      " |      Create a heterogeneous graph.\n",
      " |      \n",
      " |      >>> hg = dgl.heterograph({\n",
      " |      ...      ('user', 'plays', 'game') : ([0, 1, 2, 3, 4, 5], [0, 1, 1, 3, 3, 2]),\n",
      " |      ...      ('developer', 'develops', 'game') : ([0, 1, 2, 3], [1, 0, 3, 2])})\n",
      " |      \n",
      " |      Manually set batch information.\n",
      " |      \n",
      " |      >>> hg.set_batch_num_nodes({\n",
      " |      ...     'user': torch.tensor([3, 3]),\n",
      " |      ...     'game': torch.tensor([2, 2]),\n",
      " |      ...     'developer': torch.tensor([2, 2])})\n",
      " |      >>> hg.set_batch_num_edges(\n",
      " |      ...     {('user', 'plays', 'game'): torch.tensor([3, 3]),\n",
      " |      ...     ('developer', 'develops', 'game'): torch.tensor([2, 2])})\n",
      " |      \n",
      " |      Unbatch the graph.\n",
      " |      \n",
      " |      >>> g1, g2 = dgl.unbatch(hg)\n",
      " |      >>> g1\n",
      " |      Graph(num_nodes={'developer': 2, 'game': 2, 'user': 3},\n",
      " |            num_edges={('developer', 'develops', 'game'): 2, ('user', 'plays', 'game'): 3},\n",
      " |            metagraph=[('developer', 'game', 'develops'), ('user', 'game', 'plays')])\n",
      " |      >>> g2\n",
      " |      Graph(num_nodes={'developer': 2, 'game': 2, 'user': 3},\n",
      " |            num_edges={('developer', 'develops', 'game'): 2, ('user', 'plays', 'game'): 3},\n",
      " |            metagraph=[('developer', 'game', 'develops'), ('user', 'game', 'plays')])\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      set_batch_num_nodes\n",
      " |      batch\n",
      " |      unbatch\n",
      " |  \n",
      " |  set_batch_num_nodes(self, val)\n",
      " |      Manually set the number of nodes for each graph in the batch with the specified node\n",
      " |      type.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      val : Tensor or Mapping[str, Tensor]\n",
      " |          The dictionary storing number of nodes for each graph in the batch for all node types.\n",
      " |          If the graph has only one node type, ``val`` can also be a single array indicating the\n",
      " |          number of nodes per graph in the batch.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This API is always used together with ``set_batch_num_edges`` to specify batching\n",
      " |      information of a graph, it also do not check the correspondance between the graph structure\n",
      " |      and batching information and user must guarantee there will be no cross-graph edges in the\n",
      " |      batch.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      Create a homogeneous graph.\n",
      " |      \n",
      " |      >>> g = dgl.graph(([0, 1, 2, 3, 4, 5], [1, 2, 0, 4, 5, 3]))\n",
      " |      \n",
      " |      Manually set batch information\n",
      " |      \n",
      " |      >>> g.set_batch_num_nodes(torch.tensor([3, 3]))\n",
      " |      >>> g.set_batch_num_edges(torch.tensor([3, 3]))\n",
      " |      \n",
      " |      Unbatch the graph.\n",
      " |      \n",
      " |      >>> dgl.unbatch(g)\n",
      " |      [Graph(num_nodes=3, num_edges=3,\n",
      " |            ndata_schemes={}\n",
      " |            edata_schemes={}), Graph(num_nodes=3, num_edges=3,\n",
      " |            ndata_schemes={}\n",
      " |            edata_schemes={})]\n",
      " |      \n",
      " |      Create a heterogeneous graph.\n",
      " |      \n",
      " |      >>> hg = dgl.heterograph({\n",
      " |      ...      ('user', 'plays', 'game') : ([0, 1, 2, 3, 4, 5], [0, 1, 1, 3, 3, 2]),\n",
      " |      ...      ('developer', 'develops', 'game') : ([0, 1, 2, 3], [1, 0, 3, 2])})\n",
      " |      \n",
      " |      Manually set batch information.\n",
      " |      \n",
      " |      >>> hg.set_batch_num_nodes({\n",
      " |      ...     'user': torch.tensor([3, 3]),\n",
      " |      ...     'game': torch.tensor([2, 2]),\n",
      " |      ...     'developer': torch.tensor([2, 2])})\n",
      " |      >>> hg.set_batch_num_edges({\n",
      " |      ...     ('user', 'plays', 'game'): torch.tensor([3, 3]),\n",
      " |      ...     ('developer', 'develops', 'game'): torch.tensor([2, 2])})\n",
      " |      \n",
      " |      Unbatch the graph.\n",
      " |      \n",
      " |      >>> g1, g2 = dgl.unbatch(hg)\n",
      " |      >>> g1\n",
      " |      Graph(num_nodes={'developer': 2, 'game': 2, 'user': 3},\n",
      " |            num_edges={('developer', 'develops', 'game'): 2, ('user', 'plays', 'game'): 3},\n",
      " |            metagraph=[('developer', 'game', 'develops'), ('user', 'game', 'plays')])\n",
      " |      >>> g2\n",
      " |      Graph(num_nodes={'developer': 2, 'game': 2, 'user': 3},\n",
      " |            num_edges={('developer', 'develops', 'game'): 2, ('user', 'plays', 'game'): 3},\n",
      " |            metagraph=[('developer', 'game', 'develops'), ('user', 'game', 'plays')])\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      set_batch_num_edges\n",
      " |      batch\n",
      " |      unbatch\n",
      " |  \n",
      " |  set_e_initializer(self, initializer, field=None, etype=None)\n",
      " |      Set the initializer for edge features.\n",
      " |      \n",
      " |      When only part of the edges have a feature (e.g. new edges are added,\n",
      " |      features are set for a subset of edges), the initializer initializes\n",
      " |      features for the rest edges.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      initializer : callable\n",
      " |          A function of signature ``func(shape, dtype, ctx, id_range) -> Tensor``.\n",
      " |          The tensor will be the initialized features. The arguments are:\n",
      " |      \n",
      " |          - ``shape``: The shape of the tensor to return, which is a tuple of int.\n",
      " |            The first dimension is the number of edges for feature initialization.\n",
      " |          - ``dtype``: The data type of the tensor to return, which is a\n",
      " |            framework-specific data type object.\n",
      " |          - ``ctx``: The device of the tensor to return, which is a framework-specific\n",
      " |            device object.\n",
      " |          - ``id_range``: The start and end ID of the edges for feature initialization,\n",
      " |            which is a slice.\n",
      " |      field : str, optional\n",
      " |          The name of the feature that the initializer applies. If not given, the\n",
      " |          initializer applies to all features.\n",
      " |      etype : str or (str, str, str), optional\n",
      " |          The type names of the edges. The allowed type name formats are:\n",
      " |      \n",
      " |          * ``(str, str, str)`` for source node type, edge type and destination node type.\n",
      " |          * or one ``str`` edge type name if the name can uniquely identify a\n",
      " |            triplet format in the graph.\n",
      " |      \n",
      " |          Can be omitted if the graph has only one type of edges.\n",
      " |      \n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Without setting an edge feature initializer, zero tensors are generated\n",
      " |      for edges without a feature.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      Define a function for initializer.\n",
      " |      \n",
      " |      >>> def init_feats(shape, dtype, device, id_range):\n",
      " |      ...     return torch.ones(shape, dtype=dtype, device=device)\n",
      " |      \n",
      " |      An example for a homogeneous graph.\n",
      " |      \n",
      " |      >>> g = dgl.graph((torch.tensor([0]), torch.tensor([1])))\n",
      " |      >>> g.edata['h1'] = torch.zeros(1, 2)\n",
      " |      >>> g.edata['h2'] = torch.ones(1, 1)\n",
      " |      >>> # Apply the initializer to feature 'h2' only.\n",
      " |      >>> g.set_e_initializer(init_feats, field='h2')\n",
      " |      >>> g.add_edges(torch.tensor([1]), torch.tensor([1]))\n",
      " |      >>> print(g.edata['h1'])\n",
      " |      tensor([[0., 0.],\n",
      " |              [0., 0.]])\n",
      " |      >>> print(g.edata['h2'])\n",
      " |      tensor([[1.], [1.]])\n",
      " |      \n",
      " |      An example for a heterogeneous graph of multiple edge types.\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({\n",
      " |      ...     ('user', 'plays', 'game'): (torch.tensor([0, 1]),\n",
      " |      ...                                 torch.tensor([0, 0])),\n",
      " |      ...     ('developer', 'develops', 'game'): (torch.tensor([0, 1]),\n",
      " |      ...                                         torch.tensor([0, 1]))\n",
      " |      ...     })\n",
      " |      >>> g.edges['plays'].data['h'] = torch.zeros(2, 2)\n",
      " |      >>> g.edges['develops'].data['w'] = torch.ones(2, 2)\n",
      " |      >>> g.set_e_initializer(init_feats, etype='plays')\n",
      " |      >>> # Initializer not set for 'develops', use zero tensors by default\n",
      " |      >>> g.add_edges(torch.tensor([1]), torch.tensor([1]), etype='develops')\n",
      " |      >>> g.edges['develops'].data['w']\n",
      " |      tensor([[1., 1.],\n",
      " |              [1., 1.],\n",
      " |              [0., 0.]])\n",
      " |      >>> # Initializer set for 'plays'\n",
      " |      >>> g.add_edges(torch.tensor([1]), torch.tensor([1]), etype='plays')\n",
      " |      >>> g.edges['plays'].data['h']\n",
      " |      tensor([[0., 0.],\n",
      " |              [0., 0.],\n",
      " |              [1., 1.]])\n",
      " |  \n",
      " |  set_n_initializer(self, initializer, field=None, ntype=None)\n",
      " |      Set the initializer for node features.\n",
      " |      \n",
      " |      When only part of the nodes have a feature (e.g. new nodes are added,\n",
      " |      features are set for a subset of nodes), the initializer initializes\n",
      " |      features for the rest nodes.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      initializer : callable\n",
      " |          A function of signature ``func(shape, dtype, ctx, id_range) -> Tensor``.\n",
      " |          The tensor will be the initialized features. The arguments are:\n",
      " |      \n",
      " |          - ``shape``: The shape of the tensor to return, which is a tuple of int.\n",
      " |            The first dimension is the number of nodes for feature initialization.\n",
      " |          - ``dtype``: The data type of the tensor to return, which is a\n",
      " |            framework-specific data type object.\n",
      " |          - ``ctx``: The device of the tensor to return, which is a framework-specific\n",
      " |            device object.\n",
      " |          - ``id_range``: The start and end ID of the nodes for feature initialization,\n",
      " |            which is a slice.\n",
      " |      field : str, optional\n",
      " |          The name of the feature that the initializer applies. If not given, the\n",
      " |          initializer applies to all features.\n",
      " |      ntype : str, optional\n",
      " |          The type name of the nodes. Can be omitted if the graph has only one type of nodes.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Without setting a node feature initializer, zero tensors are generated\n",
      " |      for nodes without a feature.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      Define a function for initializer.\n",
      " |      \n",
      " |      >>> def init_feats(shape, dtype, device, id_range):\n",
      " |      ...     return torch.ones(shape, dtype=dtype, device=device)\n",
      " |      \n",
      " |      An example for a homogeneous graph.\n",
      " |      \n",
      " |      >>> g = dgl.graph((torch.tensor([0]), torch.tensor([1])))\n",
      " |      >>> g.ndata['h1'] = torch.zeros(2, 2)\n",
      " |      >>> g.ndata['h2'] = torch.ones(2, 1)\n",
      " |      >>> # Apply the initializer to feature 'h2' only.\n",
      " |      >>> g.set_n_initializer(init_feats, field='h2')\n",
      " |      >>> g.add_nodes(1)\n",
      " |      >>> print(g.ndata['h1'])\n",
      " |      tensor([[0., 0.],\n",
      " |              [0., 0.],\n",
      " |              [0., 0.]])\n",
      " |      >>> print(g.ndata['h2'])\n",
      " |      tensor([[1.], [1.], [1.]])\n",
      " |      \n",
      " |      An example for a heterogeneous graph of multiple node types.\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({\n",
      " |      ...     ('user', 'plays', 'game'): (torch.tensor([0, 1, 1, 2]),\n",
      " |      ...                                 torch.tensor([0, 0, 1, 1])),\n",
      " |      ...     ('developer', 'develops', 'game'): (torch.tensor([0, 1]),\n",
      " |      ...                                         torch.tensor([0, 1]))\n",
      " |      ...     })\n",
      " |      >>> g.nodes['user'].data['h'] = torch.zeros(3, 2)\n",
      " |      >>> g.nodes['game'].data['w'] = torch.ones(2, 2)\n",
      " |      >>> g.set_n_initializer(init_feats, ntype='game')\n",
      " |      >>> g.add_nodes(1, ntype='user')\n",
      " |      >>> # Initializer not set for 'user', use zero tensors by default\n",
      " |      >>> g.nodes['user'].data['h']\n",
      " |      tensor([[0., 0.],\n",
      " |              [0., 0.],\n",
      " |              [0., 0.],\n",
      " |              [0., 0.]])\n",
      " |      >>> # Initializer set for 'game'\n",
      " |      >>> g.add_nodes(1, ntype='game')\n",
      " |      >>> g.nodes['game'].data['w']\n",
      " |      tensor([[1., 1.],\n",
      " |              [1., 1.],\n",
      " |              [1., 1.]])\n",
      " |  \n",
      " |  shared_memory(self, name, formats=('coo', 'csr', 'csc'))\n",
      " |      Return a copy of this graph in shared memory, without node data or edge data.\n",
      " |      \n",
      " |      It moves the graph index to shared memory and returns a DGLHeterograph object which\n",
      " |      has the same graph structure, node types and edge types but does not contain node data\n",
      " |      or edge data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      name : str\n",
      " |          The name of the shared memory.\n",
      " |      formats : str or a list of str (optional)\n",
      " |          Desired formats to be materialized.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      HeteroGraph\n",
      " |          The graph in shared memory\n",
      " |  \n",
      " |  subgraph = node_subgraph(graph, nodes, *, relabel_nodes=True, store_ids=True, output_device=None)\n",
      " |      Alias of :func:`dgl.node_subgraph`.\n",
      " |  \n",
      " |  successors(self, v, etype=None)\n",
      " |      Return the successor(s) of a particular node with the specified edge type.\n",
      " |      \n",
      " |      Node ``u`` is a successor of node ``v`` if there is an edge ``(v, u)`` with type\n",
      " |      ``etype`` in the graph.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      v : int\n",
      " |          The node ID. If the graph has multiple edge types, the ID is for the source\n",
      " |          type corresponding to the edge type.\n",
      " |      etype : str or (str, str, str), optional\n",
      " |          The type names of the edges. The allowed type name formats are:\n",
      " |      \n",
      " |          * ``(str, str, str)`` for source node type, edge type and destination node type.\n",
      " |          * or one ``str`` edge type name if the name can uniquely identify a\n",
      " |            triplet format in the graph.\n",
      " |      \n",
      " |          Can be omitted if the graph has only one type of edges.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Tensor\n",
      " |          The successors of :attr:`v` with the specified edge type.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      Create a homogeneous graph.\n",
      " |      \n",
      " |      >>> g = dgl.graph((torch.tensor([0, 0, 1, 1]), torch.tensor([1, 1, 2, 3])))\n",
      " |      \n",
      " |      Query for node 1.\n",
      " |      \n",
      " |      >>> g.successors(1)\n",
      " |      tensor([2, 3])\n",
      " |      \n",
      " |      For a graph of multiple edge types, it is required to specify the edge type in query.\n",
      " |      \n",
      " |      >>> hg = dgl.heterograph({\n",
      " |      ...     ('user', 'follows', 'user'): (torch.tensor([0, 1]), torch.tensor([1, 2])),\n",
      " |      ...     ('user', 'plays', 'game'): (torch.tensor([3, 4]), torch.tensor([5, 6]))\n",
      " |      ... })\n",
      " |      >>> hg.successors(1, etype='follows')\n",
      " |      tensor([2])\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      predecessors\n",
      " |  \n",
      " |  to(self, device, **kwargs)\n",
      " |      Move ndata, edata and graph structure to the targeted device (cpu/gpu).\n",
      " |      \n",
      " |      If the graph is already on the specified device, the function directly returns it.\n",
      " |      Otherwise, it returns a cloned graph on the specified device.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      device : Framework-specific device context object\n",
      " |          The context to move data to (e.g., ``torch.device``).\n",
      " |      kwargs : Key-word arguments.\n",
      " |          Key-word arguments fed to the framework copy function.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DGLGraph\n",
      " |          The graph on the specified device.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      >>> g = dgl.graph((torch.tensor([1, 0]), torch.tensor([1, 2])))\n",
      " |      >>> g.ndata['h'] = torch.ones(3, 1)\n",
      " |      >>> g.edata['h'] = torch.zeros(2, 2)\n",
      " |      >>> g1 = g.to(torch.device('cuda:0'))\n",
      " |      >>> print(g1.device)\n",
      " |      device(type='cuda', index=0)\n",
      " |      >>> print(g1.ndata['h'].device)\n",
      " |      device(type='cuda', index=0)\n",
      " |      >>> print(g1.nodes().device)\n",
      " |      device(type='cuda', index=0)\n",
      " |      \n",
      " |      The original graph is still on CPU.\n",
      " |      \n",
      " |      >>> print(g.device)\n",
      " |      device(type='cpu')\n",
      " |      >>> print(g.ndata['h'].device)\n",
      " |      device(type='cpu')\n",
      " |      >>> print(g.nodes().device)\n",
      " |      device(type='cpu')\n",
      " |      \n",
      " |      The case of heterogeneous graphs is the same.\n",
      " |  \n",
      " |  to_canonical_etype(self, etype)\n",
      " |      Convert an edge type to the corresponding canonical edge type in the graph.\n",
      " |      \n",
      " |      A canonical edge type is a string triplet ``(str, str, str)``\n",
      " |      for source node type, edge type and destination node type.\n",
      " |      \n",
      " |      The function expects the given edge type name can uniquely identify a canonical edge\n",
      " |      type. DGL will raise error if this is not the case.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      etype : str or (str, str, str)\n",
      " |          If :attr:`etype` is an edge type (str), it returns the corresponding canonical edge\n",
      " |          type in the graph. If :attr:`etype` is already a canonical edge type,\n",
      " |          it directly returns the input unchanged.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      (str, str, str)\n",
      " |          The canonical edge type corresponding to the edge type.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      Create a heterograph.\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({\n",
      " |      ...     ('user', 'follows', 'user'): ([0, 1], [1, 2]),\n",
      " |      ...     ('user', 'plays', 'game'): ([0, 1, 1, 2], [0, 0, 1, 1]),\n",
      " |      ...     ('developer', 'follows', 'game'): ([0, 1], [0, 1])\n",
      " |      ... })\n",
      " |      \n",
      " |      Map an edge type to its corresponding canonical edge type.\n",
      " |      \n",
      " |      >>> g.to_canonical_etype('plays')\n",
      " |      ('user', 'plays', 'game')\n",
      " |      >>> g.to_canonical_etype(('user', 'plays', 'game'))\n",
      " |      ('user', 'plays', 'game')\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      canonical_etypes\n",
      " |  \n",
      " |  to_cugraph(g)\n",
      " |      Convert a DGL graph to a :class:`cugraph.Graph` and return.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      g : DGLGraph\n",
      " |          A homogeneous graph.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      cugraph.Graph\n",
      " |          The converted cugraph graph.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The function only supports GPU graph input.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import cugraph\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      >>> g = dgl.graph((torch.tensor([1, 2]), torch.tensor([1, 3]))).to('cuda')\n",
      " |      >>> cugraph_g = g.to_cugraph()\n",
      " |      >>> cugraph_g.edges()\n",
      " |          src  dst\n",
      " |      0    2    3\n",
      " |      1    1    1\n",
      " |  \n",
      " |  to_networkx(g, node_attrs=None, edge_attrs=None)\n",
      " |      Convert a homogeneous graph to a NetworkX graph and return.\n",
      " |      \n",
      " |      The resulting NetworkX graph also contains the node/edge features of the input graph.\n",
      " |      Additionally, DGL saves the edge IDs as the ``'id'`` edge attribute in the\n",
      " |      returned NetworkX graph.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      g : DGLGraph\n",
      " |          A homogeneous graph.\n",
      " |      node_attrs : iterable of str, optional\n",
      " |          The node attributes to copy from ``g.ndata``. (Default: None)\n",
      " |      edge_attrs : iterable of str, optional\n",
      " |          The edge attributes to copy from ``g.edata``. (Default: None)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      networkx.DiGraph\n",
      " |          The converted NetworkX graph.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The function only supports CPU graph input.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      >>> g = dgl.graph((torch.tensor([1, 2]), torch.tensor([1, 3])))\n",
      " |      >>> g.ndata['h'] = torch.zeros(4, 1)\n",
      " |      >>> g.edata['h1'] = torch.ones(2, 1)\n",
      " |      >>> g.edata['h2'] = torch.zeros(2, 2)\n",
      " |      >>> nx_g = dgl.to_networkx(g, node_attrs=['h'], edge_attrs=['h1', 'h2'])\n",
      " |      >>> nx_g.nodes(data=True)\n",
      " |      NodeDataView({0: {'h': tensor([0.])},\n",
      " |                    1: {'h': tensor([0.])},\n",
      " |                    2: {'h': tensor([0.])},\n",
      " |                    3: {'h': tensor([0.])}})\n",
      " |      >>> nx_g.edges(data=True)\n",
      " |      OutMultiEdgeDataView([(1, 1, {'id': 0, 'h1': tensor([1.]), 'h2': tensor([0., 0.])}),\n",
      " |                            (2, 3, {'id': 1, 'h1': tensor([1.]), 'h2': tensor([0., 0.])})])\n",
      " |  \n",
      " |  to_simple(g, return_counts='count', writeback_mapping=False, copy_ndata=True, copy_edata=False, aggregator='arbitrary')\n",
      " |      Alias of :func:`dgl.to_simple`.\n",
      " |  \n",
      " |  unpin_memory_(self)\n",
      " |      Unpin the graph structure and node/edge data from the page-locked memory.\n",
      " |      \n",
      " |      This is an **inplace** method. If the graph struture is not pinned,\n",
      " |      e.g., on CPU or GPU, the function directly returns it.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DGLGraph\n",
      " |          The unpinned graph.\n",
      " |  \n",
      " |  update_all(self, message_func, reduce_func, apply_node_func=None, etype=None)\n",
      " |      Send messages along all the edges of the specified type\n",
      " |      and update all the nodes of the corresponding destination type.\n",
      " |      \n",
      " |      For heterogeneous graphs with number of relation types > 1, send messages\n",
      " |      along all the edges, reduce them by type-wisely and across different types\n",
      " |      at the same time. Then, update the node features of all the nodes.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      message_func : dgl.function.BuiltinFunction or callable\n",
      " |          The message function to generate messages along the edges.\n",
      " |          It must be either a :ref:`api-built-in` or a :ref:`apiudf`.\n",
      " |      reduce_func : dgl.function.BuiltinFunction or callable\n",
      " |          The reduce function to aggregate the messages.\n",
      " |          It must be either a :ref:`api-built-in` or a :ref:`apiudf`.\n",
      " |      apply_node_func : callable, optional\n",
      " |          An optional apply function to further update the node features\n",
      " |          after the message reduction. It must be a :ref:`apiudf`.\n",
      " |      etype : str or (str, str, str), optional\n",
      " |          The type name of the edges. The allowed type name formats are:\n",
      " |      \n",
      " |          * ``(str, str, str)`` for source node type, edge type and destination node type.\n",
      " |          * or one ``str`` edge type name if the name can uniquely identify a\n",
      " |            triplet format in the graph.\n",
      " |      \n",
      " |          Can be omitted if the graph has only one type of edges.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      * If some of the nodes in the graph has no in-edges, DGL does not invoke\n",
      " |        message and reduce functions for these nodes and fill their aggregated messages\n",
      " |        with zero. Users can control the filled values via :meth:`set_n_initializer`.\n",
      " |        DGL still invokes :attr:`apply_node_func` if provided.\n",
      " |      * DGL recommends using DGL's bulit-in function for the :attr:`message_func`\n",
      " |        and the :attr:`reduce_func` arguments,\n",
      " |        because DGL will invoke efficient kernels that avoids copying node features to\n",
      " |        edge features in this case.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> import dgl\n",
      " |      >>> import dgl.function as fn\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      **Homogeneous graph**\n",
      " |      \n",
      " |      >>> g = dgl.graph(([0, 1, 2, 3], [1, 2, 3, 4]))\n",
      " |      >>> g.ndata['x'] = torch.ones(5, 2)\n",
      " |      >>> g.update_all(fn.copy_u('x', 'm'), fn.sum('m', 'h'))\n",
      " |      >>> g.ndata['h']\n",
      " |      tensor([[0., 0.],\n",
      " |              [1., 1.],\n",
      " |              [1., 1.],\n",
      " |              [1., 1.],\n",
      " |              [1., 1.]])\n",
      " |      \n",
      " |      **Heterogeneous graph**\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({('user', 'follows', 'user'): ([0, 1, 2], [1, 2, 2])})\n",
      " |      \n",
      " |      Update all.\n",
      " |      \n",
      " |      >>> g.nodes['user'].data['h'] = torch.tensor([[0.], [1.], [2.]])\n",
      " |      >>> g['follows'].update_all(fn.copy_src('h', 'm'), fn.sum('m', 'h'), etype='follows')\n",
      " |      >>> g.nodes['user'].data['h']\n",
      " |      tensor([[0.],\n",
      " |              [0.],\n",
      " |              [3.]])\n",
      " |      \n",
      " |      **Heterogenenous graph (number relation types > 1)**\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({\n",
      " |      ...     ('user', 'follows', 'user'): ([0, 1], [1, 1]),\n",
      " |      ...     ('game', 'attracts', 'user'): ([0], [1])\n",
      " |      ... })\n",
      " |      \n",
      " |      Update all.\n",
      " |      \n",
      " |      >>> g.nodes['user'].data['h'] = torch.tensor([[1.], [2.]])\n",
      " |      >>> g.nodes['game'].data['h'] = torch.tensor([[1.]])\n",
      " |      >>> g.update_all(fn.copy_src('h', 'm'), fn.sum('m', 'h'))\n",
      " |      >>> g.nodes['user'].data['h']\n",
      " |      tensor([[0.],\n",
      " |              [4.]])\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |  \n",
      " |  batch_size\n",
      " |      Return the number of graphs in the batched graph.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      int\n",
      " |          The Number of graphs in the batch. If the graph is not a batched one,\n",
      " |          it will return 1.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      Query for homogeneous graphs.\n",
      " |      \n",
      " |      >>> g1 = dgl.graph((torch.tensor([0, 1, 2]), torch.tensor([1, 2, 3])))\n",
      " |      >>> g1.batch_size\n",
      " |      1\n",
      " |      >>> g2 = dgl.graph((torch.tensor([0, 0, 0, 1]), torch.tensor([0, 1, 2, 0])))\n",
      " |      >>> bg = dgl.batch([g1, g2])\n",
      " |      >>> bg.batch_size\n",
      " |      2\n",
      " |      \n",
      " |      Query for heterogeneous graphs.\n",
      " |      \n",
      " |      >>> hg1 = dgl.heterograph({\n",
      " |      ...       ('user', 'plays', 'game') : (torch.tensor([0, 1]), torch.tensor([0, 0]))})\n",
      " |      >>> hg1.batch_size\n",
      " |      1\n",
      " |      >>> hg2 = dgl.heterograph({\n",
      " |      ...       ('user', 'plays', 'game') : (torch.tensor([0, 0]), torch.tensor([1, 0]))})\n",
      " |      >>> bg = dgl.batch([hg1, hg2])\n",
      " |      >>> bg.batch_size\n",
      " |      2\n",
      " |  \n",
      " |  canonical_etypes\n",
      " |      Return all the canonical edge types in the graph.\n",
      " |      \n",
      " |      A canonical edge type is a string triplet ``(str, str, str)``\n",
      " |      for source node type, edge type and destination node type.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      list[(str, str, str)]\n",
      " |          All the canonical edge type triplets in a list.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      DGL internally assigns an integer ID for each edge type. The returned\n",
      " |      edge type names are sorted according to their IDs.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      etypes\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({\n",
      " |      ...     ('user', 'follows', 'user'): (torch.tensor([0, 1]), torch.tensor([1, 2])),\n",
      " |      ...     ('user', 'follows', 'game'): (torch.tensor([0, 1, 2]), torch.tensor([1, 2, 3])),\n",
      " |      ...     ('user', 'plays', 'game'): (torch.tensor([1, 3]), torch.tensor([2, 3]))\n",
      " |      ... })\n",
      " |      >>> g.canonical_etypes\n",
      " |      [('user', 'follows', 'user'),\n",
      " |       ('user', 'follows', 'game'),\n",
      " |       ('user', 'plays', 'game')]\n",
      " |  \n",
      " |  device\n",
      " |      Get the device of the graph.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      device context\n",
      " |          The device of the graph, which should be a framework-specific device object\n",
      " |          (e.g., ``torch.device``).\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      Create a homogeneous graph for demonstration.\n",
      " |      \n",
      " |      >>> g = dgl.graph((torch.tensor([0, 1]), torch.tensor([1, 2])))\n",
      " |      >>> print(g.device)\n",
      " |      device(type='cpu')\n",
      " |      \n",
      " |      The case of heterogeneous graphs is the same.\n",
      " |  \n",
      " |  dstdata\n",
      " |      Return a node data view for setting/getting destination node features.\n",
      " |      \n",
      " |      Let ``g`` be a DGLGraph. If ``g`` is a graph of a single destination node type,\n",
      " |      ``g.dstdata[feat]`` returns the destination node feature associated with the name\n",
      " |      ``feat``. One can also set a destination node feature associated with the name\n",
      " |      ``feat`` by setting ``g.dstdata[feat]`` to a tensor.\n",
      " |      \n",
      " |      If ``g`` is a graph of multiple destination node types, ``g.dstdata[feat]`` returns a\n",
      " |      dict[str, Tensor] mapping destination node types to the node features associated with\n",
      " |      the name ``feat`` for the corresponding type. One can also set a node feature\n",
      " |      associated with the name ``feat`` for some destination node type(s) by setting\n",
      " |      ``g.dstdata[feat]`` to a dictionary as described.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For setting features, the device of the features must be the same as the device\n",
      " |      of the graph.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      Set and get feature 'h' for a graph of a single destination node type.\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({\n",
      " |      ...     ('user', 'plays', 'game'): (torch.tensor([0, 1]), torch.tensor([1, 2]))})\n",
      " |      >>> g.dstdata['h'] = torch.ones(3, 1)\n",
      " |      >>> g.dstdata['h']\n",
      " |      tensor([[1.],\n",
      " |              [1.],\n",
      " |              [1.]])\n",
      " |      \n",
      " |      Set and get feature 'h' for a graph of multiple destination node types.\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({\n",
      " |      ...     ('user', 'plays', 'game'): (torch.tensor([1, 2]), torch.tensor([1, 2])),\n",
      " |      ...     ('user', 'watches', 'movie'): (torch.tensor([2, 2]), torch.tensor([1, 1]))\n",
      " |      ... })\n",
      " |      >>> g.dstdata['h'] = {'game': torch.zeros(3, 1), 'movie': torch.ones(2, 1)}\n",
      " |      >>> g.dstdata['h']\n",
      " |      {'game': tensor([[0.], [0.], [0.]]),\n",
      " |       'movie': tensor([[1.], [1.]])}\n",
      " |      >>> g.dstdata['h'] = {'game': torch.ones(3, 1)}\n",
      " |      >>> g.dstdata['h']\n",
      " |      {'game': tensor([[1.], [1.], [1.]]),\n",
      " |       'movie': tensor([[1.], [1.]])}\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      nodes\n",
      " |      ndata\n",
      " |      dstnodes\n",
      " |  \n",
      " |  dstnodes\n",
      " |      Return a node view for destination nodes\n",
      " |      \n",
      " |      If the graph is a uni-bipartite graph (see :func:`is_unibipartite` for reference),\n",
      " |      this is :func:`nodes` restricted to destination node types. Otherwise, it is an alias\n",
      " |      for :func:`nodes`.\n",
      " |      \n",
      " |      One can use it for:\n",
      " |      \n",
      " |      1. Getting the node IDs for a single node type.\n",
      " |      2. Setting/getting features for all nodes of a single node type.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      Create a uni-bipartite graph.\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({\n",
      " |      ...     ('user', 'plays', 'game'): (torch.tensor([0]), torch.tensor([1])),\n",
      " |      ...     ('developer', 'develops', 'game'): (torch.tensor([1]), torch.tensor([2]))\n",
      " |      ... })\n",
      " |      \n",
      " |      Get the node IDs for destination node types.\n",
      " |      \n",
      " |      >>> g.dstnodes('game')\n",
      " |      tensor([0, 1, 2])\n",
      " |      \n",
      " |      Set/get features for destination node types.\n",
      " |      \n",
      " |      >>> g.dstnodes['game'].data['h'] = torch.ones(3, 1)\n",
      " |      >>> g.dstnodes['game'].data['h']\n",
      " |      tensor([[1.],\n",
      " |              [1.],\n",
      " |              [1.]])\n",
      " |      \n",
      " |      Create a graph that is not uni-bipartite.\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({\n",
      " |      ...     ('user', 'follows', 'user'): (torch.tensor([0]), torch.tensor([1])),\n",
      " |      ...     ('developer', 'develops', 'game'): (torch.tensor([1]), torch.tensor([2]))\n",
      " |      ... })\n",
      " |      \n",
      " |      :func:`dgl.DGLGraph.dstnodes` falls back to :func:`dgl.DGLGraph.nodes` and one can\n",
      " |      get the node IDs for both source and destination node types.\n",
      " |      \n",
      " |      >>> g.dstnodes('developer')\n",
      " |      tensor([0, 1])\n",
      " |      \n",
      " |      One can also set/get features for source node types in this case.\n",
      " |      \n",
      " |      >>> g.dstnodes['developer'].data['h'] = torch.ones(2, 1)\n",
      " |      >>> g.dstnodes['developer'].data['h']\n",
      " |      tensor([[1.],\n",
      " |              [1.]])\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      dstdata\n",
      " |  \n",
      " |  dsttypes\n",
      " |      Return all the destination node type names in this graph.\n",
      " |      \n",
      " |      If the graph can further divide its node types into two subsets A and B where\n",
      " |      all the edeges are from nodes of types in A to nodes of types in B, we call\n",
      " |      this graph a *uni-bipartite* graph and the nodes in A being the *source*\n",
      " |      nodes and the ones in B being the *destination* nodes. If the graph is not\n",
      " |      uni-bipartite, the source and destination nodes are just the entire set of\n",
      " |      nodes in the graph.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      list[str]\n",
      " |          All the destination node type names in a list.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      srctypes\n",
      " |      is_unibipartite\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      Query for a uni-bipartite graph.\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({\n",
      " |      ...     ('user', 'plays', 'game'): (torch.tensor([0]), torch.tensor([1])),\n",
      " |      ...     ('developer', 'develops', 'game'): (torch.tensor([1]), torch.tensor([2]))\n",
      " |      ... })\n",
      " |      >>> g.dsttypes\n",
      " |      ['game']\n",
      " |      \n",
      " |      Query for a graph that is not uni-bipartite.\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({\n",
      " |      ...     ('user', 'follows', 'user'): (torch.tensor([0]), torch.tensor([1])),\n",
      " |      ...     ('developer', 'develops', 'game'): (torch.tensor([1]), torch.tensor([2]))\n",
      " |      ... })\n",
      " |      >>> g.dsttypes\n",
      " |      ['developer', 'game', 'user']\n",
      " |  \n",
      " |  edata\n",
      " |      Return an edge data view for setting/getting edge features.\n",
      " |      \n",
      " |      Let ``g`` be a DGLGraph. If ``g`` is a graph of a single edge type, ``g.edata[feat]``\n",
      " |      returns the edge feature associated with the name ``feat``. One can also set an\n",
      " |      edge feature associated with the name ``feat`` by setting ``g.edata[feat]`` to a tensor.\n",
      " |      \n",
      " |      If ``g`` is a graph of multiple edge types, ``g.edata[feat]`` returns a\n",
      " |      dict[str, Tensor] mapping canonical edge types to the edge features associated with\n",
      " |      the name ``feat`` for the corresponding type. One can also set an edge feature\n",
      " |      associated with the name ``feat`` for some edge type(s) by setting\n",
      " |      ``g.edata[feat]`` to a dictionary as described.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For setting features, the device of the features must be the same as the device\n",
      " |      of the graph.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      Set and get feature 'h' for a graph of a single edge type.\n",
      " |      \n",
      " |      >>> g = dgl.graph((torch.tensor([0, 1]), torch.tensor([1, 2])))\n",
      " |      >>> g.edata['h'] = torch.ones(2, 1)\n",
      " |      >>> g.edata['h']\n",
      " |      tensor([[1.],\n",
      " |              [1.]])\n",
      " |      \n",
      " |      Set and get feature 'h' for a graph of multiple edge types.\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({\n",
      " |      ...     ('user', 'follows', 'user'): (torch.tensor([1, 2]), torch.tensor([3, 4])),\n",
      " |      ...     ('user', 'plays', 'user'): (torch.tensor([2, 2]), torch.tensor([1, 1])),\n",
      " |      ...     ('player', 'plays', 'game'): (torch.tensor([2, 2]), torch.tensor([1, 1]))\n",
      " |      ... })\n",
      " |      >>> g.edata['h'] = {('user', 'follows', 'user'): torch.zeros(2, 1),\n",
      " |      ...                 ('user', 'plays', 'user'): torch.ones(2, 1)}\n",
      " |      >>> g.edata['h']\n",
      " |      {('user', 'follows', 'user'): tensor([[0.], [0.]]),\n",
      " |       ('user', 'plays', 'user'): tensor([[1.], [1.]])}\n",
      " |      >>> g.edata['h'] = {('user', 'follows', 'user'): torch.ones(2, 1)}\n",
      " |      >>> g.edata['h']\n",
      " |      {('user', 'follows', 'user'): tensor([[1.], [1.]]),\n",
      " |       ('user', 'plays', 'user'): tensor([[1.], [1.]])}\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      edges\n",
      " |  \n",
      " |  edges\n",
      " |      Return an edge view\n",
      " |      \n",
      " |      One can use it for:\n",
      " |      \n",
      " |      1. Getting the edges for a single edge type. In this case, it can take the\n",
      " |         following optional arguments:\n",
      " |      \n",
      " |          - form : str, optional\n",
      " |                The return form, which can be one of the following:\n",
      " |      \n",
      " |                - ``'uv'`` (default): The returned result is a 2-tuple of 1D tensors\n",
      " |                  :math:`(U, V)`, representing the source and destination nodes of all edges.\n",
      " |                  For each :math:`i`, :math:`(U[i], V[i])` forms an edge.\n",
      " |                - ``'eid'``: The returned result is a 1D tensor :math:`EID`, representing\n",
      " |                  the IDs of all edges.\n",
      " |                - ``'all'``: The returned result is a 3-tuple of 1D tensors :math:`(U, V, EID)`,\n",
      " |                  representing the source nodes, destination nodes and IDs of all edges.\n",
      " |                  For each :math:`i`, :math:`(U[i], V[i])` forms an edge with ID :math:`EID[i]`.\n",
      " |          - order : str, optional\n",
      " |                The order of the returned edges, which can be one of the following:\n",
      " |      \n",
      " |                - ``'eid'`` (default): The edges are sorted by their IDs.\n",
      " |                - ``'srcdst'``: The edges are sorted first by their source node IDs and then\n",
      " |                  by their destination node IDs to break ties.\n",
      " |          - etype : str or tuple of str, optional\n",
      " |                The edge type for query, which can be an edge type (str) or a canonical edge\n",
      " |                type (3-tuple of str). When an edge type appears in multiple canonical edge\n",
      " |                types, one must use a canonical edge type. If the graph has multiple edge\n",
      " |                types, one must specify the argument. Otherwise, it can be omitted.\n",
      " |      2. Setting/getting features for all edges of a single edge type. To set/get a feature\n",
      " |         ``feat`` for edges of type ``etype`` in a graph ``g``, one can use\n",
      " |         ``g.edges[etype].data[feat]``.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      **Get the Edges for a Single Edge Type**\n",
      " |      \n",
      " |      Create a graph with a single edge type.\n",
      " |      \n",
      " |      >>> g = dgl.graph((torch.tensor([1, 0, 0]), torch.tensor([1, 1, 0])))\n",
      " |      >>> g.edges()\n",
      " |      (tensor([1, 0, 0]), tensor([1, 1, 0]))\n",
      " |      \n",
      " |      Specify a different value for :attr:`form` and :attr:`order`.\n",
      " |      \n",
      " |      >>> g.edges(form='all', order='srcdst')\n",
      " |      (tensor([0, 0, 1]), tensor([0, 1, 1]), tensor([2, 1, 0]))\n",
      " |      \n",
      " |      For a graph of multiple edge types, it is required to specify the edge type in query.\n",
      " |      \n",
      " |      >>> hg = dgl.heterograph({\n",
      " |      ...     ('user', 'follows', 'user'): (torch.tensor([0, 1]), torch.tensor([1, 2])),\n",
      " |      ...     ('user', 'plays', 'game'): (torch.tensor([3, 4]), torch.tensor([5, 6]))\n",
      " |      ... })\n",
      " |      >>> hg.edges(etype='plays')\n",
      " |      (tensor([3, 4]), tensor([5, 6]))\n",
      " |      \n",
      " |      **Set/get Features for All Edges of a Single Edge Type**\n",
      " |      \n",
      " |      Create a heterogeneous graph of two edge types.\n",
      " |      \n",
      " |      >>> hg = dgl.heterograph({\n",
      " |      ...     ('user', 'follows', 'user'): (torch.tensor([0, 1]), torch.tensor([1, 2])),\n",
      " |      ...     ('user', 'plays', 'game'): (torch.tensor([3, 4]), torch.tensor([5, 6]))\n",
      " |      ... })\n",
      " |      \n",
      " |      Set and get a feature 'h' for all edges of a single type in the heterogeneous graph.\n",
      " |      \n",
      " |      >>> hg.edges['follows'].data['h'] = torch.ones(2, 1)\n",
      " |      >>> hg.edges['follows'].data['h']\n",
      " |      tensor([[1.], [1.]])\n",
      " |      \n",
      " |      To set edge features for a graph with a single edge type, use :func:`DGLGraph.edata`.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      edata\n",
      " |  \n",
      " |  etypes\n",
      " |      Return all the edge type names in the graph.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      list[str]\n",
      " |          All the edge type names in a list.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      DGL internally assigns an integer ID for each edge type. The returned\n",
      " |      edge type names are sorted according to their IDs.\n",
      " |      \n",
      " |      The complete format to specify an relation is a string triplet ``(str, str, str)``\n",
      " |      for source node type, edge type and destination node type. DGL calls this\n",
      " |      format *canonical edge type*. An edge type can appear in multiple canonical edge types.\n",
      " |      For example, ``'interacts'`` can appear in two canonical edge types\n",
      " |      ``('drug', 'interacts', 'drug')`` and ``('protein', 'interacts', 'protein')``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      canonical_etypes\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({\n",
      " |      ...     ('user', 'follows', 'user'): (torch.tensor([0, 1]), torch.tensor([1, 2])),\n",
      " |      ...     ('user', 'follows', 'game'): (torch.tensor([0, 1, 2]), torch.tensor([1, 2, 3])),\n",
      " |      ...     ('user', 'plays', 'game'): (torch.tensor([1, 3]), torch.tensor([2, 3]))\n",
      " |      ... })\n",
      " |      >>> g.etypes\n",
      " |      ['follows', 'follows', 'plays']\n",
      " |  \n",
      " |  idtype\n",
      " |      The data type for storing the structure-related graph information\n",
      " |      such as node and edge IDs.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Framework-specific device object\n",
      " |          For example, this can be ``torch.int32`` or ``torch.int64`` for PyTorch.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      >>> src_ids = torch.tensor([0, 0, 1])\n",
      " |      >>> dst_ids = torch.tensor([1, 2, 2])\n",
      " |      >>> g = dgl.graph((src_ids, dst_ids))\n",
      " |      >>> g.idtype\n",
      " |      torch.int64\n",
      " |      >>> g = dgl.graph((src_ids, dst_ids), idtype=torch.int32)\n",
      " |      >>> g.idtype\n",
      " |      torch.int32\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      long\n",
      " |      int\n",
      " |  \n",
      " |  is_homogeneous\n",
      " |      Return whether the graph is a homogeneous graph.\n",
      " |      \n",
      " |      A homogeneous graph only has one node type and one edge type.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      bool\n",
      " |          True if the graph is a homogeneous graph.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      Create a homogeneous graph for check.\n",
      " |      \n",
      " |      >>> g = dgl.graph((torch.tensor([0, 0, 1, 1]), torch.tensor([1, 0, 2, 3])))\n",
      " |      >>> g.is_homogeneous\n",
      " |      True\n",
      " |      \n",
      " |      Create a heterogeneous graph for check.\n",
      " |      \n",
      " |      If the graph has multiple edge types, one need to specify the edge type.\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({\n",
      " |      ...     ('user', 'follows', 'game'): (torch.tensor([0, 1, 2]), torch.tensor([1, 2, 3]))})\n",
      " |      >>> g.is_homogeneous\n",
      " |      False\n",
      " |  \n",
      " |  is_multigraph\n",
      " |      Return whether the graph is a multigraph with parallel edges.\n",
      " |      \n",
      " |      A multigraph has more than one edges between the same pair of nodes, called\n",
      " |      *parallel edges*.  For heterogeneous graphs, parallel edge further requires\n",
      " |      the canonical edge type to be the same (see :meth:`canonical_etypes` for the\n",
      " |      definition).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      bool\n",
      " |          True if the graph is a multigraph.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Checking whether the graph is a multigraph could be expensive for a large one.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      Check for homogeneous graphs.\n",
      " |      \n",
      " |      >>> g = dgl.graph((torch.tensor([0, 1]), torch.tensor([1, 3])))\n",
      " |      >>> g.is_multigraph\n",
      " |      False\n",
      " |      >>> g = dgl.graph((torch.tensor([0, 1, 1]), torch.tensor([1, 3, 3])))\n",
      " |      >>> g.is_multigraph\n",
      " |      True\n",
      " |      \n",
      " |      Check for heterogeneous graphs.\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({\n",
      " |      ...     ('user', 'follows', 'user'): (torch.tensor([0, 1]), torch.tensor([1, 2])),\n",
      " |      ...     ('user', 'follows', 'game'): (torch.tensor([0, 1, 2]), torch.tensor([1, 2, 3]))\n",
      " |      ... })\n",
      " |      >>> g.is_multigraph\n",
      " |      False\n",
      " |      >>> g = dgl.heterograph({\n",
      " |      ...     ('user', 'follows', 'user'): (torch.tensor([0, 1, 1]), torch.tensor([1, 2, 2])),\n",
      " |      ...     ('user', 'follows', 'game'): (torch.tensor([0, 1, 2]), torch.tensor([1, 2, 3]))\n",
      " |      ... })\n",
      " |      >>> g.is_multigraph\n",
      " |      True\n",
      " |  \n",
      " |  is_readonly\n",
      " |      **DEPRECATED**: DGLGraph will always be mutable.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      bool\n",
      " |          True if the graph is readonly, False otherwise.\n",
      " |  \n",
      " |  is_unibipartite\n",
      " |      Return whether the graph is a uni-bipartite graph.\n",
      " |      \n",
      " |      A uni-bipartite heterograph can further divide its node types into two sets:\n",
      " |      SRC and DST. All edges are from nodes in SRC to nodes in DST. The following APIs\n",
      " |      can be used to get the type, data, and nodes that belong to SRC and DST sets:\n",
      " |      \n",
      " |      * :func:`srctype` and :func:`dsttype`\n",
      " |      * :func:`srcdata` and :func:`dstdata`\n",
      " |      * :func:`srcnodes` and :func:`dstnodes`\n",
      " |      \n",
      " |      Note that we allow two node types to have the same name as long as one\n",
      " |      belongs to SRC while the other belongs to DST. To distinguish them, prepend\n",
      " |      the name with ``\"SRC/\"`` or ``\"DST/\"`` when specifying a node type.\n",
      " |  \n",
      " |  ndata\n",
      " |      Return a node data view for setting/getting node features\n",
      " |      \n",
      " |      Let ``g`` be a DGLGraph. If ``g`` is a graph of a single node type, ``g.ndata[feat]``\n",
      " |      returns the node feature associated with the name ``feat``. One can also set a node\n",
      " |      feature associated with the name ``feat`` by setting ``g.ndata[feat]`` to a tensor.\n",
      " |      \n",
      " |      If ``g`` is a graph of multiple node types, ``g.ndata[feat]`` returns a\n",
      " |      dict[str, Tensor] mapping node types to the node features associated with the name\n",
      " |      ``feat`` for the corresponding type. One can also set a node feature associated\n",
      " |      with the name ``feat`` for some node type(s) by setting ``g.ndata[feat]`` to a\n",
      " |      dictionary as described.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For setting features, the device of the features must be the same as the device\n",
      " |      of the graph.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      Set and get feature 'h' for a graph of a single node type.\n",
      " |      \n",
      " |      >>> g = dgl.graph((torch.tensor([0, 1]), torch.tensor([1, 2])))\n",
      " |      >>> g.ndata['h'] = torch.ones(3, 1)\n",
      " |      >>> g.ndata['h']\n",
      " |      tensor([[1.],\n",
      " |              [1.],\n",
      " |              [1.]])\n",
      " |      \n",
      " |      Set and get feature 'h' for a graph of multiple node types.\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({\n",
      " |      ...     ('user', 'follows', 'user'): (torch.tensor([1, 2]), torch.tensor([3, 4])),\n",
      " |      ...     ('player', 'plays', 'game'): (torch.tensor([2, 2]), torch.tensor([1, 1]))\n",
      " |      ... })\n",
      " |      >>> g.ndata['h'] = {'game': torch.zeros(2, 1), 'player': torch.ones(3, 1)}\n",
      " |      >>> g.ndata['h']\n",
      " |      {'game': tensor([[0.], [0.]]),\n",
      " |       'player': tensor([[1.], [1.], [1.]])}\n",
      " |      >>> g.ndata['h'] = {'game': torch.ones(2, 1)}\n",
      " |      >>> g.ndata['h']\n",
      " |      {'game': tensor([[1.], [1.]]),\n",
      " |       'player': tensor([[1.], [1.], [1.]])}\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      nodes\n",
      " |  \n",
      " |  nodes\n",
      " |      Return a node view\n",
      " |      \n",
      " |      One can use it for:\n",
      " |      \n",
      " |      1. Getting the node IDs for a single node type.\n",
      " |      2. Setting/getting features for all nodes of a single node type.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      Create a homogeneous graph and a heterogeneous graph of two node types.\n",
      " |      \n",
      " |      >>> g = dgl.graph((torch.tensor([0, 1]), torch.tensor([1, 2])))\n",
      " |      >>> hg = dgl.heterograph({\n",
      " |      ...     ('user', 'follows', 'user'): (torch.tensor([0, 1]), torch.tensor([1, 2])),\n",
      " |      ...     ('user', 'plays', 'game'): (torch.tensor([3, 4]), torch.tensor([5, 6]))\n",
      " |      ... })\n",
      " |      \n",
      " |      Get the node IDs of the homogeneous graph.\n",
      " |      \n",
      " |      >>> g.nodes()\n",
      " |      tensor([0, 1, 2])\n",
      " |      \n",
      " |      Get the node IDs of the heterogeneous graph. With multiple node types introduced,\n",
      " |      one needs to specify the node type for query.\n",
      " |      \n",
      " |      >>> hg.nodes('user')\n",
      " |      tensor([0, 1, 2, 3, 4])\n",
      " |      \n",
      " |      Set and get a feature 'h' for all nodes of a single type in the heterogeneous graph.\n",
      " |      \n",
      " |      >>> hg.nodes['user'].data['h'] = torch.ones(5, 1)\n",
      " |      >>> hg.nodes['user'].data['h']\n",
      " |      tensor([[1.], [1.], [1.], [1.], [1.]])\n",
      " |      \n",
      " |      To set node features for a graph with a single node type, use :func:`DGLGraph.ndata`.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      ndata\n",
      " |  \n",
      " |  ntypes\n",
      " |      Return all the node type names in the graph.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      list[str]\n",
      " |          All the node type names in a list.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      DGL internally assigns an integer ID for each node type. The returned\n",
      " |      node type names are sorted according to their IDs.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({\n",
      " |      ...     ('user', 'follows', 'user'): (torch.tensor([0, 1]), torch.tensor([1, 2])),\n",
      " |      ...     ('user', 'follows', 'game'): (torch.tensor([0, 1, 2]), torch.tensor([1, 2, 3])),\n",
      " |      ...     ('user', 'plays', 'game'): (torch.tensor([1, 3]), torch.tensor([2, 3]))\n",
      " |      ... })\n",
      " |      >>> g.ntypes\n",
      " |      ['game', 'user']\n",
      " |  \n",
      " |  srcdata\n",
      " |      Return a node data view for setting/getting source node features.\n",
      " |      \n",
      " |      Let ``g`` be a DGLGraph. If ``g`` is a graph of a single source node type,\n",
      " |      ``g.srcdata[feat]`` returns the source node feature associated with the name ``feat``.\n",
      " |      One can also set a source node feature associated with the name ``feat`` by\n",
      " |      setting ``g.srcdata[feat]`` to a tensor.\n",
      " |      \n",
      " |      If ``g`` is a graph of multiple source node types, ``g.srcdata[feat]`` returns a\n",
      " |      dict[str, Tensor] mapping source node types to the node features associated with\n",
      " |      the name ``feat`` for the corresponding type. One can also set a node feature\n",
      " |      associated with the name ``feat`` for some source node type(s) by setting\n",
      " |      ``g.srcdata[feat]`` to a dictionary as described.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For setting features, the device of the features must be the same as the device\n",
      " |      of the graph.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      Set and get feature 'h' for a graph of a single source node type.\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({\n",
      " |      ...     ('user', 'plays', 'game'): (torch.tensor([0, 1]), torch.tensor([1, 2]))})\n",
      " |      >>> g.srcdata['h'] = torch.ones(2, 1)\n",
      " |      >>> g.srcdata['h']\n",
      " |      tensor([[1.],\n",
      " |              [1.]])\n",
      " |      \n",
      " |      Set and get feature 'h' for a graph of multiple source node types.\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({\n",
      " |      ...     ('user', 'plays', 'game'): (torch.tensor([1, 2]), torch.tensor([3, 4])),\n",
      " |      ...     ('player', 'plays', 'game'): (torch.tensor([2, 2]), torch.tensor([1, 1]))\n",
      " |      ... })\n",
      " |      >>> g.srcdata['h'] = {'user': torch.zeros(3, 1), 'player': torch.ones(3, 1)}\n",
      " |      >>> g.srcdata['h']\n",
      " |      {'player': tensor([[1.], [1.], [1.]]),\n",
      " |       'user': tensor([[0.], [0.], [0.]])}\n",
      " |      >>> g.srcdata['h'] = {'user': torch.ones(3, 1)}\n",
      " |      >>> g.srcdata['h']\n",
      " |      {'player': tensor([[1.], [1.], [1.]]),\n",
      " |       'user': tensor([[1.], [1.], [1.]])}\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      nodes\n",
      " |      ndata\n",
      " |      srcnodes\n",
      " |  \n",
      " |  srcnodes\n",
      " |      Return a node view for source nodes\n",
      " |      \n",
      " |      If the graph is a uni-bipartite graph (see :func:`is_unibipartite` for reference),\n",
      " |      this is :func:`nodes` restricted to source node types. Otherwise, it is an alias\n",
      " |      for :func:`nodes`.\n",
      " |      \n",
      " |      One can use it for:\n",
      " |      \n",
      " |      1. Getting the node IDs for a single node type.\n",
      " |      2. Setting/getting features for all nodes of a single node type.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      Create a uni-bipartite graph.\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({\n",
      " |      ...     ('user', 'plays', 'game'): (torch.tensor([0]), torch.tensor([1])),\n",
      " |      ...     ('developer', 'develops', 'game'): (torch.tensor([1]), torch.tensor([2]))\n",
      " |      ... })\n",
      " |      \n",
      " |      Get the node IDs for source node types.\n",
      " |      \n",
      " |      >>> g.srcnodes('user')\n",
      " |      tensor([0])\n",
      " |      >>> g.srcnodes('developer')\n",
      " |      tensor([0, 1])\n",
      " |      \n",
      " |      Set/get features for source node types.\n",
      " |      \n",
      " |      >>> g.srcnodes['user'].data['h'] = torch.ones(1, 1)\n",
      " |      >>> g.srcnodes['user'].data['h']\n",
      " |      tensor([[1.]])\n",
      " |      \n",
      " |      Create a graph that is not uni-bipartite.\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({\n",
      " |      ...     ('user', 'follows', 'user'): (torch.tensor([0]), torch.tensor([1])),\n",
      " |      ...     ('developer', 'develops', 'game'): (torch.tensor([1]), torch.tensor([2]))\n",
      " |      ... })\n",
      " |      \n",
      " |      :func:`dgl.DGLGraph.srcnodes` falls back to :func:`dgl.DGLGraph.nodes` and one can\n",
      " |      get the node IDs for both source and destination node types.\n",
      " |      \n",
      " |      >>> g.srcnodes('game')\n",
      " |      tensor([0, 1, 2])\n",
      " |      \n",
      " |      One can also set/get features for destination node types in this case.\n",
      " |      \n",
      " |      >>> g.srcnodes['game'].data['h'] = torch.ones(3, 1)\n",
      " |      >>> g.srcnodes['game'].data['h']\n",
      " |      tensor([[1.],\n",
      " |              [1.],\n",
      " |              [1.]])\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      srcdata\n",
      " |  \n",
      " |  srctypes\n",
      " |      Return all the source node type names in this graph.\n",
      " |      \n",
      " |      If the graph can further divide its node types into two subsets A and B where\n",
      " |      all the edeges are from nodes of types in A to nodes of types in B, we call\n",
      " |      this graph a *uni-bipartite* graph and the nodes in A being the *source*\n",
      " |      nodes and the ones in B being the *destination* nodes. If the graph is not\n",
      " |      uni-bipartite, the source and destination nodes are just the entire set of\n",
      " |      nodes in the graph.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      list[str]\n",
      " |          All the source node type names in a list.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      dsttypes\n",
      " |      is_unibipartite\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      Query for a uni-bipartite graph.\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({\n",
      " |      ...     ('user', 'plays', 'game'): (torch.tensor([0]), torch.tensor([1])),\n",
      " |      ...     ('developer', 'develops', 'game'): (torch.tensor([1]), torch.tensor([2]))\n",
      " |      ... })\n",
      " |      >>> g.srctypes\n",
      " |      ['developer', 'user']\n",
      " |      \n",
      " |      Query for a graph that is not uni-bipartite.\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({\n",
      " |      ...     ('user', 'follows', 'user'): (torch.tensor([0]), torch.tensor([1])),\n",
      " |      ...     ('developer', 'develops', 'game'): (torch.tensor([1]), torch.tensor([2]))\n",
      " |      ... })\n",
      " |      >>> g.srctypes\n",
      " |      ['developer', 'game', 'user']\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  is_block = False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(batch_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "3d898176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes=369, num_edges=43212,\n",
       "      ndata_schemes={'h': Scheme(shape=(300,), dtype=torch.float32)}\n",
       "      edata_schemes={'w': Scheme(shape=(1,), dtype=torch.float32)})"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "6cf35223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Graph(num_nodes=167, num_edges=17238,\n",
       "       ndata_schemes={'h': Scheme(shape=(300,), dtype=torch.float32)}\n",
       "       edata_schemes={'w': Scheme(shape=(1,), dtype=torch.float32)}),\n",
       " Graph(num_nodes=202, num_edges=25974,\n",
       "       ndata_schemes={'h': Scheme(shape=(300,), dtype=torch.float32)}\n",
       "       edata_schemes={'w': Scheme(shape=(1,), dtype=torch.float32)})]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "6cdbbec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on DGLHeteroGraph in module dgl.heterograph object:\n",
      "\n",
      "class DGLHeteroGraph(builtins.object)\n",
      " |  DGLHeteroGraph(gidx=[], ntypes=['_N'], etypes=['_E'], node_frames=None, edge_frames=None, **deprecate_kwargs)\n",
      " |  \n",
      " |  Class for storing graph structure and node/edge feature data.\n",
      " |  \n",
      " |  There are a few ways to create a DGLGraph:\n",
      " |  \n",
      " |  * To create a homogeneous graph from Tensor data, use :func:`dgl.graph`.\n",
      " |  * To create a heterogeneous graph from Tensor data, use :func:`dgl.heterograph`.\n",
      " |  * To create a graph from other data sources, use ``dgl.*`` create ops. See\n",
      " |    :ref:`api-graph-create-ops`.\n",
      " |  \n",
      " |  Read the user guide chapter :ref:`guide-graph` for an in-depth explanation about its\n",
      " |  usage.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __contains__(self, vid)\n",
      " |      **DEPRECATED**: please directly call :func:`has_nodes`.\n",
      " |  \n",
      " |  __copy__(self)\n",
      " |      Shallow copy implementation.\n",
      " |  \n",
      " |  __getitem__(self, key)\n",
      " |      Return the relation slice of this graph.\n",
      " |      \n",
      " |      You can get a relation slice with ``self[srctype, etype, dsttype]``, where\n",
      " |      ``srctype``, ``etype``, and ``dsttype`` can be either a string or a full\n",
      " |      slice (``:``) representing wildcard (i.e. any source/edge/destination type).\n",
      " |      \n",
      " |      A relation slice is a homogeneous (with one node type and one edge type) or\n",
      " |      bipartite (with two node types and one edge type) graph, transformed from\n",
      " |      the original heterogeneous graph.\n",
      " |      \n",
      " |      If there is only one canonical edge type found, then the returned relation\n",
      " |      slice would be a subgraph induced from the original graph.  That is, it is\n",
      " |      equivalent to ``self.edge_type_subgraph(etype)``.  The node and edge features\n",
      " |      of the returned graph would be shared with thew original graph.\n",
      " |      \n",
      " |      If there are multiple canonical edge types found, then the source/edge/destination\n",
      " |      node types would be a *concatenation* of original node/edge types.  The\n",
      " |      new source/destination node type would have the concatenation determined by\n",
      " |      :func:`dgl.combine_names() <dgl.combine_names>` called on original source/destination\n",
      " |      types as its name.  The source/destination node would be formed by concatenating the\n",
      " |      common features of the original source/destination types.  Therefore they are not\n",
      " |      shared with the original graph.  Edge type is similar.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      key : str or tuple\n",
      " |          Either a string representing the edge type name, or a tuple in the form of\n",
      " |          ``(srctype, etype, dsttype)`` where ``srctype``, ``etype``, ``dsttype`` can be either\n",
      " |          strings representing type names or a full slice object (`:`).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DGLGraph\n",
      " |          The relation slice.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This function returns a new graph.  Changing the content of this graph does not reflect\n",
      " |      onto the original graph.\n",
      " |      \n",
      " |      If the graph combines multiple node types or edge types together, it will have the\n",
      " |      mapping of node/edge types and IDs from the new graph to the original graph.\n",
      " |      The mappings have the name ``dgl.NTYPE``, ``dgl.NID``, ``dgl.ETYPE`` and ``dgl.EID``,\n",
      " |      similar to the function :func:`dgl.to_homogenenous`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> g = dgl.heterograph({\n",
      " |      ...     ('A1', 'AB1', 'B'): ([0, 1, 2], [1, 2, 3]),\n",
      " |      ...     ('A1', 'AB2', 'B'): ([1, 2, 3], [3, 4, 5]),\n",
      " |      ...     ('A2', 'AB2', 'B'): ([1, 3, 5], [2, 4, 6])})\n",
      " |      >>> new_g = g['A1', :, 'B']         # combines all edge types between A1 and B\n",
      " |      >>> new_g\n",
      " |      Graph(num_nodes={'A1': 4, 'B': 7},\n",
      " |            num_edges={('A1', 'AB1+AB2', 'B'): 6},\n",
      " |            metagraph=[('A1', 'B', 'AB1+AB2')])\n",
      " |      >>> new_g.edges()\n",
      " |      (tensor([0, 1, 2, 1, 2, 3]), tensor([1, 2, 3, 3, 4, 5]))\n",
      " |      >>> new_g2 = g[:, 'AB2', 'B']        # combines all node types that are source of AB2\n",
      " |      >>> new_g2\n",
      " |      Graph(num_nodes={'A1+A2': 10, 'B': 7},\n",
      " |            num_edges={('A1+A2', 'AB2+AB2', 'B'): 6},\n",
      " |            metagraph=[('A1+A2', 'B', 'AB2+AB2')])\n",
      " |      >>> new_g2.edges()\n",
      " |      (tensor([1, 2, 3, 5, 7, 9]), tensor([3, 4, 5, 2, 4, 6]))\n",
      " |      \n",
      " |      If a combination of multiple node types and edge types occur, one can find\n",
      " |      the mapping to the original node type and IDs like the following:\n",
      " |      \n",
      " |      >>> new_g1.edges['AB1+AB2'].data[dgl.EID]\n",
      " |      tensor([0, 1, 2, 0, 1, 2])\n",
      " |      >>> new_g1.edges['AB1+AB2'].data[dgl.ETYPE]\n",
      " |      tensor([0, 0, 0, 1, 1, 1])\n",
      " |      >>> new_g2.nodes['A1+A2'].data[dgl.NID]\n",
      " |      tensor([0, 1, 2, 3, 0, 1, 2, 3, 4, 5])\n",
      " |      >>> new_g2.nodes['A1+A2'].data[dgl.NTYPE]\n",
      " |      tensor([0, 0, 0, 0, 1, 1, 1, 1, 1, 1])\n",
      " |  \n",
      " |  __init__(self, gidx=[], ntypes=['_N'], etypes=['_E'], node_frames=None, edge_frames=None, **deprecate_kwargs)\n",
      " |      Internal constructor for creating a DGLGraph.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      gidx : HeteroGraphIndex\n",
      " |          Graph index object.\n",
      " |      ntypes : list of str, pair of list of str\n",
      " |          Node type list. ``ntypes[i]`` stores the name of node type i.\n",
      " |          If a pair is given, the graph created is a uni-directional bipartite graph,\n",
      " |          and its SRC node types and DST node types are given as in the pair.\n",
      " |      etypes : list of str\n",
      " |          Edge type list. ``etypes[i]`` stores the name of edge type i.\n",
      " |      node_frames : list[Frame], optional\n",
      " |          Node feature storage. If None, empty frame is created.\n",
      " |          Otherwise, ``node_frames[i]`` stores the node features\n",
      " |          of node type i. (default: None)\n",
      " |      edge_frames : list[Frame], optional\n",
      " |          Edge feature storage. If None, empty frame is created.\n",
      " |          Otherwise, ``edge_frames[i]`` stores the edge features\n",
      " |          of edge type i. (default: None)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  add_edge(self, u, v, data=None, etype=None)\n",
      " |      Add one edge to the graph.\n",
      " |      \n",
      " |      DEPRECATED: please use ``add_edges``.\n",
      " |  \n",
      " |  add_edges(self, u, v, data=None, etype=None)\n",
      " |      Add multiple new edges for the specified edge type\n",
      " |      \n",
      " |      The i-th new edge will be from ``u[i]`` to ``v[i]``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      u : int, tensor, numpy.ndarray, list\n",
      " |          Source node IDs, ``u[i]`` gives the source node for the i-th new edge.\n",
      " |      v : int, tensor, numpy.ndarray, list\n",
      " |          Destination node IDs, ``v[i]`` gives the destination node for the i-th new edge.\n",
      " |      data : dict, optional\n",
      " |          Feature data of the added edges. The i-th row of the feature data\n",
      " |          corresponds to the i-th new edge.\n",
      " |      etype : str or tuple of str, optional\n",
      " |          The type of the new edges. Can be omitted if there is\n",
      " |          only one edge type in the graph.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      \n",
      " |      * Inplace update is applied to the current graph.\n",
      " |      * If end nodes of adding edges does not exists, add_nodes is invoked\n",
      " |        to add new nodes. The node features of the new nodes will be created\n",
      " |        by initializers defined with :func:`set_n_initializer` (default\n",
      " |        initializer fills zeros). In certain cases, it is recommanded to\n",
      " |        add_nodes first and then add_edges.\n",
      " |      * If the key of ``data`` does not contain some existing feature fields,\n",
      " |        those features for the new edges will be created by initializers\n",
      " |        defined with :func:`set_n_initializer` (default initializer fills zeros).\n",
      " |      * If the key of ``data`` contains new feature fields, those features for\n",
      " |        the old edges will be created by initializers defined with\n",
      " |        :func:`set_n_initializer` (default initializer fills zeros).\n",
      " |      * This function discards the batch information. Please use\n",
      " |        :func:`dgl.DGLGraph.set_batch_num_nodes`\n",
      " |        and :func:`dgl.DGLGraph.set_batch_num_edges` on the transformed graph\n",
      " |        to maintain the information.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      **Homogeneous Graphs or Heterogeneous Graphs with A Single Edge Type**\n",
      " |      \n",
      " |      >>> g = dgl.graph((torch.tensor([0, 1]), torch.tensor([1, 2])))\n",
      " |      >>> g.num_edges()\n",
      " |      2\n",
      " |      >>> g.add_edges(torch.tensor([1, 3]), torch.tensor([0, 1]))\n",
      " |      >>> g.num_edges()\n",
      " |      4\n",
      " |      \n",
      " |      Since ``u`` or ``v`` contains a non-existing node ID, the nodes are\n",
      " |      added implicitly.\n",
      " |      >>> g.num_nodes()\n",
      " |      4\n",
      " |      \n",
      " |      If the graph has some edge features and new edges are added without\n",
      " |      features, their features will be created by initializers defined\n",
      " |      with :func:`set_n_initializer`.\n",
      " |      \n",
      " |      >>> g.edata['h'] = torch.ones(4, 1)\n",
      " |      >>> g.add_edges(torch.tensor([1]), torch.tensor([1]))\n",
      " |      >>> g.edata['h']\n",
      " |      tensor([[1.], [1.], [1.], [1.], [0.]])\n",
      " |      \n",
      " |      We can also assign features for the new edges in adding new edges.\n",
      " |      \n",
      " |      >>> g.add_edges(torch.tensor([0, 0]), torch.tensor([2, 2]),\n",
      " |      ...             {'h': torch.tensor([[1.], [2.]]), 'w': torch.ones(2, 1)})\n",
      " |      >>> g.edata['h']\n",
      " |      tensor([[1.], [1.], [1.], [1.], [0.], [1.], [2.]])\n",
      " |      \n",
      " |      Since ``data`` contains new feature fields, the features for old edges\n",
      " |      will be created by initializers defined with :func:`set_n_initializer`.\n",
      " |      \n",
      " |      >>> g.edata['w']\n",
      " |      tensor([[0.], [0.], [0.], [0.], [0.], [1.], [1.]])\n",
      " |      \n",
      " |      **Heterogeneous Graphs with Multiple Edge Types**\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({\n",
      " |      ...     ('user', 'plays', 'game'): (torch.tensor([0, 1, 1, 2]),\n",
      " |      ...                                 torch.tensor([0, 0, 1, 1])),\n",
      " |      ...     ('developer', 'develops', 'game'): (torch.tensor([0, 1]),\n",
      " |      ...                                         torch.tensor([0, 1]))\n",
      " |      ...     })\n",
      " |      >>> g.add_edges(torch.tensor([3]), torch.tensor([3]))\n",
      " |      DGLError: Edge type name must be specified\n",
      " |      if there are more than one edge types.\n",
      " |      >>> g.number_of_edges('plays')\n",
      " |      4\n",
      " |      >>> g.add_edges(torch.tensor([3]), torch.tensor([3]), etype='plays')\n",
      " |      >>> g.number_of_edges('plays')\n",
      " |      5\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      add_nodes\n",
      " |      remove_nodes\n",
      " |      remove_edges\n",
      " |  \n",
      " |  add_nodes(self, num, data=None, ntype=None)\n",
      " |      Add new nodes of the same node type\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      num : int\n",
      " |          Number of nodes to add.\n",
      " |      data : dict, optional\n",
      " |          Feature data of the added nodes.\n",
      " |      ntype : str, optional\n",
      " |          The type of the new nodes. Can be omitted if there is\n",
      " |          only one node type in the graph.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      \n",
      " |      * Inplace update is applied to the current graph.\n",
      " |      * If the key of ``data`` does not contain some existing feature fields,\n",
      " |        those features for the new nodes will be created by initializers\n",
      " |        defined with :func:`set_n_initializer` (default initializer fills zeros).\n",
      " |      * If the key of ``data`` contains new feature fields, those features for\n",
      " |        the old nodes will be created by initializers defined with\n",
      " |        :func:`set_n_initializer` (default initializer fills zeros).\n",
      " |      * This function discards the batch information. Please use\n",
      " |        :func:`dgl.DGLGraph.set_batch_num_nodes`\n",
      " |        and :func:`dgl.DGLGraph.set_batch_num_edges` on the transformed graph\n",
      " |        to maintain the information.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      **Homogeneous Graphs or Heterogeneous Graphs with A Single Node Type**\n",
      " |      \n",
      " |      >>> g = dgl.graph((torch.tensor([0, 1]), torch.tensor([1, 2])))\n",
      " |      >>> g.num_nodes()\n",
      " |      3\n",
      " |      >>> g.add_nodes(2)\n",
      " |      >>> g.num_nodes()\n",
      " |      5\n",
      " |      \n",
      " |      If the graph has some node features and new nodes are added without\n",
      " |      features, their features will be created by initializers defined\n",
      " |      with :func:`set_n_initializer`.\n",
      " |      \n",
      " |      >>> g.ndata['h'] = torch.ones(5, 1)\n",
      " |      >>> g.add_nodes(1)\n",
      " |      >>> g.ndata['h']\n",
      " |      tensor([[1.], [1.], [1.], [1.], [1.], [0.]])\n",
      " |      \n",
      " |      We can also assign features for the new nodes in adding new nodes.\n",
      " |      \n",
      " |      >>> g.add_nodes(1, {'h': torch.ones(1, 1), 'w': torch.ones(1, 1)})\n",
      " |      >>> g.ndata['h']\n",
      " |      tensor([[1.], [1.], [1.], [1.], [1.], [0.], [1.]])\n",
      " |      \n",
      " |      Since ``data`` contains new feature fields, the features for old nodes\n",
      " |      will be created by initializers defined with :func:`set_n_initializer`.\n",
      " |      \n",
      " |      >>> g.ndata['w']\n",
      " |      tensor([[0.], [0.], [0.], [0.], [0.], [0.], [1.]])\n",
      " |      \n",
      " |      \n",
      " |      **Heterogeneous Graphs with Multiple Node Types**\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({\n",
      " |      ...     ('user', 'plays', 'game'): (torch.tensor([0, 1, 1, 2]),\n",
      " |      ...                                 torch.tensor([0, 0, 1, 1])),\n",
      " |      ...     ('developer', 'develops', 'game'): (torch.tensor([0, 1]),\n",
      " |      ...                                         torch.tensor([0, 1]))\n",
      " |      ...     })\n",
      " |      >>> g.add_nodes(2)\n",
      " |      DGLError: Node type name must be specified\n",
      " |      if there are more than one node types.\n",
      " |      >>> g.num_nodes('user')\n",
      " |      3\n",
      " |      >>> g.add_nodes(2, ntype='user')\n",
      " |      >>> g.num_nodes('user')\n",
      " |      5\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      remove_nodes\n",
      " |      add_edges\n",
      " |      remove_edges\n",
      " |  \n",
      " |  add_self_loop(g, edge_feat_names=None, fill_data=1.0, etype=None)\n",
      " |      Alias of :func:`dgl.add_self_loop`.\n",
      " |  \n",
      " |  adj(self, transpose=False, ctx=device(type='cpu'), scipy_fmt=None, etype=None)\n",
      " |      Return the adjacency matrix of edges of the given edge type.\n",
      " |      \n",
      " |      By default, a row of returned adjacency matrix represents the\n",
      " |      source of an edge and the column represents the destination.\n",
      " |      \n",
      " |      When transpose is True, a row represents the destination and a column\n",
      " |      represents the source.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      transpose : bool, optional\n",
      " |          A flag to transpose the returned adjacency matrix. (Default: False)\n",
      " |      ctx : context, optional\n",
      " |          The context of returned adjacency matrix. (Default: cpu)\n",
      " |      scipy_fmt : str, optional\n",
      " |          If specified, return a scipy sparse matrix in the given format.\n",
      " |          Otherwise, return a backend dependent sparse tensor. (Default: None)\n",
      " |      etype : str or (str, str, str), optional\n",
      " |          The type names of the edges. The allowed type name formats are:\n",
      " |      \n",
      " |          * ``(str, str, str)`` for source node type, edge type and destination node type.\n",
      " |          * or one ``str`` edge type name if the name can uniquely identify a\n",
      " |            triplet format in the graph.\n",
      " |      \n",
      " |          Can be omitted if the graph has only one type of edges.\n",
      " |      \n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      SparseTensor or scipy.sparse.spmatrix\n",
      " |          Adjacency matrix.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      Instantiate a heterogeneous graph.\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({\n",
      " |      ...     ('user', 'follows', 'user'): ([0, 1], [0, 1]),\n",
      " |      ...     ('developer', 'develops', 'game'): ([0, 1], [0, 2])\n",
      " |      ... })\n",
      " |      \n",
      " |      Get a backend dependent sparse tensor. Here we use PyTorch for example.\n",
      " |      \n",
      " |      >>> g.adj(etype='develops')\n",
      " |      tensor(indices=tensor([[0, 1],\n",
      " |                             [0, 2]]),\n",
      " |             values=tensor([1., 1.]),\n",
      " |             size=(2, 3), nnz=2, layout=torch.sparse_coo)\n",
      " |      \n",
      " |      Get a scipy coo sparse matrix.\n",
      " |      \n",
      " |      >>> g.adj(scipy_fmt='coo', etype='develops')\n",
      " |      <2x3 sparse matrix of type '<class 'numpy.int64'>'\n",
      " |         with 2 stored elements in COOrdinate format>\n",
      " |  \n",
      " |  adj_sparse(self, fmt, etype=None)\n",
      " |      Return the adjacency matrix of edges of the given edge type as tensors of\n",
      " |      a sparse matrix representation.\n",
      " |      \n",
      " |      By default, a row of returned adjacency matrix represents the\n",
      " |      source of an edge and the column represents the destination.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      fmt : str\n",
      " |          Either ``coo``, ``csr`` or ``csc``.\n",
      " |      etype : str or (str, str, str), optional\n",
      " |          The type names of the edges. The allowed type name formats are:\n",
      " |      \n",
      " |          * ``(str, str, str)`` for source node type, edge type and destination node type.\n",
      " |          * or one ``str`` edge type name if the name can uniquely identify a\n",
      " |            triplet format in the graph.\n",
      " |      \n",
      " |          Can be omitted if the graph has only one type of edges.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      tuple[Tensor]\n",
      " |          If :attr:`fmt` is ``coo``, returns a pair of source and destination node ID\n",
      " |          tensors.\n",
      " |      \n",
      " |          If :attr:`fmt` is ``csr`` or ``csc``, return the CSR or CSC representation\n",
      " |          of the adjacency matrix as a triplet of tensors\n",
      " |          ``(indptr, indices, edge_ids)``.  Namely ``edge_ids`` could be an empty\n",
      " |          tensor with 0 elements, in which case the edge IDs are consecutive\n",
      " |          integers starting from 0.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> g = dgl.graph(([0, 1, 2], [1, 2, 3]))\n",
      " |      >>> g.adj_sparse('coo')\n",
      " |      (tensor([0, 1, 2]), tensor([1, 2, 3]))\n",
      " |      >>> g.adj_sparse('csr')\n",
      " |      (tensor([0, 1, 2, 3, 3]), tensor([1, 2, 3]), tensor([0, 1, 2]))\n",
      " |  \n",
      " |  adjacency_matrix(self, transpose=False, ctx=device(type='cpu'), scipy_fmt=None, etype=None)\n",
      " |      Alias of :meth:`adj`\n",
      " |  \n",
      " |  adjacency_matrix_scipy(self, transpose=False, fmt='csr', return_edge_ids=None)\n",
      " |      DEPRECATED: please use ``dgl.adjacency_matrix(transpose, scipy_fmt=fmt)``.\n",
      " |  \n",
      " |  all_edges(self, form='uv', order='eid', etype=None)\n",
      " |      Return all edges with the specified edge type.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      form : str, optional\n",
      " |          The return form, which can be one of the following:\n",
      " |      \n",
      " |          - ``'eid'``: The returned result is a 1D tensor :math:`EID`, representing\n",
      " |            the IDs of all edges.\n",
      " |          - ``'uv'`` (default): The returned result is a 2-tuple of 1D tensors :math:`(U, V)`,\n",
      " |            representing the source and destination nodes of all edges. For each :math:`i`,\n",
      " |            :math:`(U[i], V[i])` forms an edge.\n",
      " |          - ``'all'``: The returned result is a 3-tuple of 1D tensors :math:`(U, V, EID)`,\n",
      " |            representing the source nodes, destination nodes and IDs of all edges.\n",
      " |            For each :math:`i`, :math:`(U[i], V[i])` forms an edge with ID :math:`EID[i]`.\n",
      " |      order : str, optional\n",
      " |          The order of the returned edges, which can be one of the following:\n",
      " |      \n",
      " |          - ``'srcdst'``: The edges are sorted first by their source node IDs and then\n",
      " |            by their destination node IDs to break ties.\n",
      " |          - ``'eid'`` (default): The edges are sorted by their IDs.\n",
      " |      etype : str or tuple of str, optional\n",
      " |          The edge type for query, which can be an edge type (str) or a canonical edge type\n",
      " |          (3-tuple of str). When an edge type appears in multiple canonical edge types, one\n",
      " |          must use a canonical edge type. If the graph has multiple edge types, one must\n",
      " |          specify the argument. Otherwise, it can be omitted.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Tensor or (Tensor, Tensor) or (Tensor, Tensor, Tensor)\n",
      " |          All edges of the specified edge type. For a description of the returned result,\n",
      " |          see the description of :attr:`form`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      Create a homogeneous graph.\n",
      " |      \n",
      " |      >>> g = dgl.graph((torch.tensor([0, 0, 1, 1]), torch.tensor([1, 0, 2, 3])))\n",
      " |      \n",
      " |      Query for edges.\n",
      " |      \n",
      " |      >>> g.all_edges()\n",
      " |      (tensor([0, 0, 1, 1]), tensor([1, 0, 2, 3]))\n",
      " |      \n",
      " |      Specify a different value for :attr:`form` and :attr:`order`.\n",
      " |      \n",
      " |      >>> g.all_edges(form='all', order='srcdst')\n",
      " |      (tensor([0, 0, 1, 1]), tensor([0, 1, 2, 3]), tensor([1, 0, 2, 3]))\n",
      " |      \n",
      " |      For a graph of multiple edge types, it is required to specify the edge type in query.\n",
      " |      \n",
      " |      >>> hg = dgl.heterograph({\n",
      " |      ...     ('user', 'follows', 'user'): (torch.tensor([0, 1]), torch.tensor([1, 2])),\n",
      " |      ...     ('user', 'plays', 'game'): (torch.tensor([3, 4]), torch.tensor([5, 6]))\n",
      " |      ... })\n",
      " |      >>> hg.all_edges(etype='plays')\n",
      " |      (tensor([3, 4]), tensor([5, 6]))\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      edges\n",
      " |      in_edges\n",
      " |      out_edges\n",
      " |  \n",
      " |  apply_edges(self, func, edges='__ALL__', etype=None, inplace=False)\n",
      " |      Update the features of the specified edges by the provided function.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : dgl.function.BuiltinFunction or callable\n",
      " |          The function to generate new edge features. It must be either\n",
      " |          a :ref:`api-built-in` or a :ref:`apiudf`.\n",
      " |      edges : edges\n",
      " |          The edges to update features on. The allowed input formats are:\n",
      " |      \n",
      " |          * ``int``: A single edge ID.\n",
      " |          * Int Tensor: Each element is an edge ID.  The tensor must have the same device type\n",
      " |            and ID data type as the graph's.\n",
      " |          * iterable[int]: Each element is an edge ID.\n",
      " |          * (Tensor, Tensor): The node-tensors format where the i-th elements\n",
      " |            of the two tensors specify an edge.\n",
      " |          * (iterable[int], iterable[int]): Similar to the node-tensors format but\n",
      " |            stores edge endpoints in python iterables.\n",
      " |      \n",
      " |          Default value specifies all the edges in the graph.\n",
      " |      \n",
      " |      etype : str or (str, str, str), optional\n",
      " |          The type name of the edges. The allowed type name formats are:\n",
      " |      \n",
      " |          * ``(str, str, str)`` for source node type, edge type and destination node type.\n",
      " |          * or one ``str`` edge type name if the name can uniquely identify a\n",
      " |            triplet format in the graph.\n",
      " |      \n",
      " |          Can be omitted if the graph has only one type of edges.\n",
      " |      \n",
      " |      inplace: bool, optional\n",
      " |          **DEPRECATED**.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      DGL recommends using DGL's bulit-in function for the :attr:`func` argument,\n",
      " |      because DGL will invoke efficient kernels that avoids copying node features to\n",
      " |      edge features in this case.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      **Homogeneous graph**\n",
      " |      \n",
      " |      >>> g = dgl.graph(([0, 1, 2, 3], [1, 2, 3, 4]))\n",
      " |      >>> g.ndata['h'] = torch.ones(5, 2)\n",
      " |      >>> g.apply_edges(lambda edges: {'x' : edges.src['h'] + edges.dst['h']})\n",
      " |      >>> g.edata['x']\n",
      " |      tensor([[2., 2.],\n",
      " |              [2., 2.],\n",
      " |              [2., 2.],\n",
      " |              [2., 2.]])\n",
      " |      \n",
      " |      Use built-in function\n",
      " |      \n",
      " |      >>> import dgl.function as fn\n",
      " |      >>> g.apply_edges(fn.u_add_v('h', 'h', 'x'))\n",
      " |      >>> g.edata['x']\n",
      " |      tensor([[2., 2.],\n",
      " |              [2., 2.],\n",
      " |              [2., 2.],\n",
      " |              [2., 2.]])\n",
      " |      \n",
      " |      **Heterogeneous graph**\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({('user', 'plays', 'game'): ([0, 1, 1, 2], [0, 0, 2, 1])})\n",
      " |      >>> g.edges[('user', 'plays', 'game')].data['h'] = torch.ones(4, 5)\n",
      " |      >>> g.apply_edges(lambda edges: {'h': edges.data['h'] * 2})\n",
      " |      >>> g.edges[('user', 'plays', 'game')].data['h']\n",
      " |      tensor([[2., 2., 2., 2., 2.],\n",
      " |              [2., 2., 2., 2., 2.],\n",
      " |              [2., 2., 2., 2., 2.],\n",
      " |              [2., 2., 2., 2., 2.]])\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      apply_nodes\n",
      " |  \n",
      " |  apply_nodes(self, func, v='__ALL__', ntype=None, inplace=False)\n",
      " |      Update the features of the specified nodes by the provided function.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : callable\n",
      " |          The function to update node features. It must be\n",
      " |          a :ref:`apiudf`.\n",
      " |      v : node IDs\n",
      " |          The node IDs. The allowed formats are:\n",
      " |      \n",
      " |          * ``int``: A single node.\n",
      " |          * Int Tensor: Each element is a node ID. The tensor must have the same device type\n",
      " |            and ID data type as the graph's.\n",
      " |          * iterable[int]: Each element is a node ID.\n",
      " |      \n",
      " |          If not given (default), use all the nodes in the graph.\n",
      " |      ntype : str, optional\n",
      " |          The node type name. Can be omitted if there is\n",
      " |          only one type of nodes in the graph.\n",
      " |      inplace : bool, optional\n",
      " |          **DEPRECATED**.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      **Homogeneous graph**\n",
      " |      \n",
      " |      >>> g = dgl.graph(([0, 1, 2, 3], [1, 2, 3, 4]))\n",
      " |      >>> g.ndata['h'] = torch.ones(5, 2)\n",
      " |      >>> g.apply_nodes(lambda nodes: {'x' : nodes.data['h'] * 2})\n",
      " |      >>> g.ndata['x']\n",
      " |      tensor([[2., 2.],\n",
      " |              [2., 2.],\n",
      " |              [2., 2.],\n",
      " |              [2., 2.],\n",
      " |              [2., 2.]])\n",
      " |      \n",
      " |      **Heterogeneous graph**\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({('user', 'follows', 'user'): ([0, 1], [1, 2])})\n",
      " |      >>> g.nodes['user'].data['h'] = torch.ones(3, 5)\n",
      " |      >>> g.apply_nodes(lambda nodes: {'h': nodes.data['h'] * 2}, ntype='user')\n",
      " |      >>> g.nodes['user'].data['h']\n",
      " |      tensor([[2., 2., 2., 2., 2.],\n",
      " |              [2., 2., 2., 2., 2.],\n",
      " |              [2., 2., 2., 2., 2.]])\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      apply_edges\n",
      " |  \n",
      " |  astype(self, idtype)\n",
      " |      Cast this graph to use another ID type.\n",
      " |      \n",
      " |      Features are copied (shallow copy) to the new graph.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      idtype : Data type object.\n",
      " |          New ID type. Can only be int32 or int64.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DGLHeteroGraph\n",
      " |          Graph in the new ID type.\n",
      " |  \n",
      " |  batch_num_edges(self, etype=None)\n",
      " |      Return the number of edges for each graph in the batch with the specified edge type.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      etype : str or tuple of str, optional\n",
      " |          The edge type for query, which can be an edge type (str) or a canonical edge type\n",
      " |          (3-tuple of str). When an edge type appears in multiple canonical edge types, one\n",
      " |          must use a canonical edge type. If the graph has multiple edge types, one must\n",
      " |          specify the argument. Otherwise, it can be omitted.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Tensor\n",
      " |          The number of edges with the specified type for each graph in the batch. The i-th\n",
      " |          element of it is the number of edges with the specified type for the i-th graph.\n",
      " |          If the graph is not a batched one, it will return a list of length 1 that holds\n",
      " |          the number of edges in the graph.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      Query for homogeneous graphs.\n",
      " |      \n",
      " |      >>> g1 = dgl.graph((torch.tensor([0, 1, 2]), torch.tensor([1, 2, 3])))\n",
      " |      >>> g1.batch_num_edges()\n",
      " |      tensor([3])\n",
      " |      >>> g2 = dgl.graph((torch.tensor([0, 0, 0, 1]), torch.tensor([0, 1, 2, 0])))\n",
      " |      >>> bg = dgl.batch([g1, g2])\n",
      " |      >>> bg.batch_num_edges()\n",
      " |      tensor([3, 4])\n",
      " |      \n",
      " |      Query for heterogeneous graphs.\n",
      " |      \n",
      " |      >>> hg1 = dgl.heterograph({\n",
      " |      ...       ('user', 'plays', 'game') : (torch.tensor([0, 1]), torch.tensor([0, 0]))})\n",
      " |      >>> hg2 = dgl.heterograph({\n",
      " |      ...       ('user', 'plays', 'game') : (torch.tensor([0, 0]), torch.tensor([1, 0]))})\n",
      " |      >>> bg = dgl.batch([hg1, hg2])\n",
      " |      >>> bg.batch_num_edges('plays')\n",
      " |      tensor([2, 2])\n",
      " |  \n",
      " |  batch_num_nodes(self, ntype=None)\n",
      " |      Return the number of nodes for each graph in the batch with the specified node type.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      ntype : str, optional\n",
      " |          The node type for query. If the graph has multiple node types, one must\n",
      " |          specify the argument. Otherwise, it can be omitted. If the graph is not a batched\n",
      " |          one, it will return a list of length 1 that holds the number of nodes in the graph.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Tensor\n",
      " |          The number of nodes with the specified type for each graph in the batch. The i-th\n",
      " |          element of it is the number of nodes with the specified type for the i-th graph.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      Query for homogeneous graphs.\n",
      " |      \n",
      " |      >>> g1 = dgl.graph((torch.tensor([0, 1, 2]), torch.tensor([1, 2, 3])))\n",
      " |      >>> g1.batch_num_nodes()\n",
      " |      tensor([4])\n",
      " |      >>> g2 = dgl.graph((torch.tensor([0, 0, 0, 1]), torch.tensor([0, 1, 2, 0])))\n",
      " |      >>> bg = dgl.batch([g1, g2])\n",
      " |      >>> bg.batch_num_nodes()\n",
      " |      tensor([4, 3])\n",
      " |      \n",
      " |      Query for heterogeneous graphs.\n",
      " |      \n",
      " |      >>> hg1 = dgl.heterograph({\n",
      " |      ...       ('user', 'plays', 'game') : (torch.tensor([0, 1]), torch.tensor([0, 0]))})\n",
      " |      >>> hg2 = dgl.heterograph({\n",
      " |      ...       ('user', 'plays', 'game') : (torch.tensor([0, 0]), torch.tensor([1, 0]))})\n",
      " |      >>> bg = dgl.batch([hg1, hg2])\n",
      " |      >>> bg.batch_num_nodes('user')\n",
      " |      tensor([2, 1])\n",
      " |  \n",
      " |  clone(self)\n",
      " |      Return a heterograph object that is a clone of current graph.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DGLHeteroGraph\n",
      " |          The graph object that is a clone of current graph.\n",
      " |  \n",
      " |  cpu(self)\n",
      " |      Return a new copy of this graph on CPU.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DGLHeteroGraph\n",
      " |          Graph on CPU.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      to\n",
      " |  \n",
      " |  create_formats_(self)\n",
      " |      Create all sparse matrices allowed for the graph.\n",
      " |      \n",
      " |      By default, we create sparse matrices for a graph only when necessary.\n",
      " |      In some cases we may want to create them immediately (e.g. in a\n",
      " |      multi-process data loader), which can be achieved via this API.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      **Homographs or Heterographs with A Single Edge Type**\n",
      " |      \n",
      " |      >>> g = dgl.graph(([0, 0, 1], [2, 3, 2]))\n",
      " |      >>> g.format()\n",
      " |      {'created': ['coo'], 'not created': ['csr', 'csc']}\n",
      " |      >>> g.create_formats_()\n",
      " |      >>> g.format()\n",
      " |      {'created': ['coo', 'csr', 'csc'], 'not created': []}\n",
      " |      \n",
      " |      **Heterographs with Multiple Edge Types**\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({\n",
      " |      ...     ('user', 'plays', 'game'): (torch.tensor([0, 1, 1, 2]),\n",
      " |      ...                                 torch.tensor([0, 0, 1, 1])),\n",
      " |      ...     ('developer', 'develops', 'game'): (torch.tensor([0, 1]),\n",
      " |      ...                                         torch.tensor([0, 1]))\n",
      " |      ...     })\n",
      " |      >>> g.format()\n",
      " |      {'created': ['coo'], 'not created': ['csr', 'csc']}\n",
      " |      >>> g.create_formats_()\n",
      " |      >>> g.format()\n",
      " |      {'created': ['coo', 'csr', 'csc'], 'not created': []}\n",
      " |  \n",
      " |  edge_attr_schemes(self, etype=None)\n",
      " |      Return the edge feature schemes for the specified type.\n",
      " |      \n",
      " |      The scheme of a feature describes the shape and data type of it.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      etype : str or (str, str, str), optional\n",
      " |          The type names of the edges. The allowed type name formats are:\n",
      " |      \n",
      " |          * ``(str, str, str)`` for source node type, edge type and destination node type.\n",
      " |          * or one ``str`` edge type name if the name can uniquely identify a\n",
      " |            triplet format in the graph.\n",
      " |      \n",
      " |          Can be omitted if the graph has only one type of edges.\n",
      " |      \n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      dict[str, Scheme]\n",
      " |          A dictionary mapping a feature name to its associated feature scheme.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      Query for a homogeneous graph.\n",
      " |      \n",
      " |      >>> g = dgl.graph((torch.tensor([0, 1]), torch.tensor([1, 2])))\n",
      " |      >>> g.edata['h1'] = torch.randn(2, 1)\n",
      " |      >>> g.edata['h2'] = torch.randn(2, 2)\n",
      " |      >>> g.edge_attr_schemes()\n",
      " |      {'h1': Scheme(shape=(1,), dtype=torch.float32),\n",
      " |       'h2': Scheme(shape=(2,), dtype=torch.float32)}\n",
      " |      \n",
      " |      Query for a heterogeneous graph of multiple edge types.\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({('user', 'plays', 'game'):\n",
      " |      ...                      (torch.tensor([1, 2]), torch.tensor([3, 4])),\n",
      " |      ...                      ('user', 'follows', 'user'):\n",
      " |      ...                      (torch.tensor([3, 4]), torch.tensor([5, 6]))})\n",
      " |      >>> g.edges['plays'].data['h1'] = torch.randn(2, 1)\n",
      " |      >>> g.edges['plays'].data['h2'] = torch.randn(2, 2)\n",
      " |      >>> g.edge_attr_schemes('plays')\n",
      " |      {'h1': Scheme(shape=(1,), dtype=torch.float32),\n",
      " |       'h2': Scheme(shape=(2,), dtype=torch.float32)}\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      node_attr_schemes\n",
      " |  \n",
      " |  edge_id(self, u, v, force_multi=None, return_uv=False, etype=None)\n",
      " |      Return the edge ID, or an array of edge IDs, between source node\n",
      " |      `u` and destination node `v`, with the specified edge type\n",
      " |      \n",
      " |      **DEPRECATED**: See edge_ids\n",
      " |  \n",
      " |  edge_ids(self, u, v, force_multi=None, return_uv=False, etype=None)\n",
      " |      Return the edge ID(s) given the two endpoints of the edge(s).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      u : node IDs\n",
      " |          The source node IDs of the edges. The allowed formats are:\n",
      " |      \n",
      " |          * ``int``: A single node.\n",
      " |          * Int Tensor: Each element is a node ID. The tensor must have the same device type\n",
      " |            and ID data type as the graph's.\n",
      " |          * iterable[int]: Each element is a node ID.\n",
      " |      \n",
      " |      v : node IDs\n",
      " |          The destination node IDs of the edges. The allowed formats are:\n",
      " |      \n",
      " |          * ``int``: A single node.\n",
      " |          * Int Tensor: Each element is a node ID. The tensor must have the same device type\n",
      " |            and ID data type as the graph's.\n",
      " |          * iterable[int]: Each element is a node ID.\n",
      " |      force_multi : bool, optional\n",
      " |          **DEPRECATED**, use :attr:`return_uv` instead. Whether to allow the graph to be a\n",
      " |          multigraph, i.e. there can be multiple edges from one node to another.\n",
      " |      return_uv : bool, optional\n",
      " |          Whether to return the source and destination node IDs along with the edges. If\n",
      " |          False (default), it assumes that the graph is a simple graph and there is only\n",
      " |          one edge from one node to another. If True, there can be multiple edges found\n",
      " |          from one node to another.\n",
      " |      etype : str or (str, str, str), optional\n",
      " |          The type names of the edges. The allowed type name formats are:\n",
      " |      \n",
      " |          * ``(str, str, str)`` for source node type, edge type and destination node type.\n",
      " |          * or one ``str`` edge type name if the name can uniquely identify a\n",
      " |            triplet format in the graph.\n",
      " |      \n",
      " |          Can be omitted if the graph has only one type of edges.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Tensor, or (Tensor, Tensor, Tensor)\n",
      " |      \n",
      " |          * If ``return_uv=False``, it returns the edge IDs in a tensor, where the i-th\n",
      " |            element is the ID of the edge ``(u[i], v[i])``.\n",
      " |          * If ``return_uv=True``, it returns a tuple of three 1D tensors ``(eu, ev, e)``.\n",
      " |            ``e[i]`` is the ID of an edge from ``eu[i]`` to ``ev[i]``. It returns all edges\n",
      " |            (including parallel edges) from ``eu[i]`` to ``ev[i]`` in this case.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If the graph is a simple graph, ``return_uv=False``, and there are no edges\n",
      " |      between some pairs of node(s), it will raise an error.\n",
      " |      \n",
      " |      If the graph is a multigraph, ``return_uv=False``, and there are multiple edges\n",
      " |      between some pairs of node(s), it returns an arbitrary one from them.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      Create a homogeneous graph.\n",
      " |      \n",
      " |      >>> g = dgl.graph((torch.tensor([0, 0, 1, 1, 1]), torch.tensor([1, 0, 2, 3, 2])))\n",
      " |      \n",
      " |      Query for the edges.\n",
      " |      \n",
      " |      >>> g.edge_ids(0, 0)\n",
      " |      1\n",
      " |      >>> g.edge_ids(torch.tensor([1, 0]), torch.tensor([3, 1]))\n",
      " |      tensor([3, 0])\n",
      " |      \n",
      " |      Get all edges for pairs of nodes.\n",
      " |      \n",
      " |      >>> g.edge_ids(torch.tensor([1, 0]), torch.tensor([3, 1]), return_uv=True)\n",
      " |      (tensor([1, 0]), tensor([3, 1]), tensor([3, 0]))\n",
      " |      \n",
      " |      If the graph has multiple edge types, one need to specify the edge type.\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({\n",
      " |      ...     ('user', 'follows', 'user'): (torch.tensor([0, 1]), torch.tensor([1, 2])),\n",
      " |      ...     ('user', 'follows', 'game'): (torch.tensor([0, 1, 2]), torch.tensor([1, 2, 3])),\n",
      " |      ...     ('user', 'plays', 'game'): (torch.tensor([1, 3]), torch.tensor([2, 3]))\n",
      " |      ... })\n",
      " |      >>> g.edge_ids(torch.tensor([1]), torch.tensor([2]), etype='plays')\n",
      " |      tensor([0])\n",
      " |      \n",
      " |      Use a canonical edge type instead when there is ambiguity for an edge type.\n",
      " |      \n",
      " |      >>> g.edge_ids(torch.tensor([0, 1]), torch.tensor([1, 2]),\n",
      " |      ...            etype=('user', 'follows', 'user'))\n",
      " |      tensor([0, 1])\n",
      " |      >>> g.edge_ids(torch.tensor([1, 2]), torch.tensor([2, 3]),\n",
      " |      ...            etype=('user', 'follows', 'game'))\n",
      " |      tensor([1, 2])\n",
      " |  \n",
      " |  edge_subgraph(graph, edges, *, relabel_nodes=True, store_ids=True, output_device=None, **deprecated_kwargs)\n",
      " |      Alias of :func:`dgl.edge_subgraph`.\n",
      " |  \n",
      " |  edge_type_subgraph(graph, etypes, output_device=None)\n",
      " |      Alias of :func:`dgl.edge_type_subgraph`.\n",
      " |  \n",
      " |  filter_edges(self, predicate, edges='__ALL__', etype=None)\n",
      " |      Return the IDs of the edges with the given edge type that satisfy\n",
      " |      the given predicate.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      predicate : callable\n",
      " |          A function of signature ``func(edges) -> Tensor``.\n",
      " |          ``edges`` are :class:`dgl.EdgeBatch` objects.\n",
      " |          Its output tensor should be a 1D boolean tensor with\n",
      " |          each element indicating whether the corresponding edge in\n",
      " |          the batch satisfies the predicate.\n",
      " |      edges : edges\n",
      " |          The edges to send and receive messages on. The allowed input formats are:\n",
      " |      \n",
      " |          * ``int``: A single edge ID.\n",
      " |          * Int Tensor: Each element is an edge ID.  The tensor must have the same device type\n",
      " |            and ID data type as the graph's.\n",
      " |          * iterable[int]: Each element is an edge ID.\n",
      " |          * (Tensor, Tensor): The node-tensors format where the i-th elements\n",
      " |            of the two tensors specify an edge.\n",
      " |          * (iterable[int], iterable[int]): Similar to the node-tensors format but\n",
      " |            stores edge endpoints in python iterables.\n",
      " |      \n",
      " |          By default, it considers all the edges.\n",
      " |      etype : str or (str, str, str), optional\n",
      " |          The type name of the edges. The allowed type name formats are:\n",
      " |      \n",
      " |          * ``(str, str, str)`` for source node type, edge type and destination node type.\n",
      " |          * or one ``str`` edge type name if the name can uniquely identify a\n",
      " |            triplet format in the graph.\n",
      " |      \n",
      " |          Can be omitted if the graph has only one type of edges.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Tensor\n",
      " |          A 1D tensor that contains the ID(s) of the edge(s) that satisfy the predicate.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      Define a predicate function.\n",
      " |      \n",
      " |      >>> def edges_with_feature_one(edges):\n",
      " |      ...     # Whether an edge has feature 1\n",
      " |      ...     return (edges.data['h'] == 1.).squeeze(1)\n",
      " |      \n",
      " |      Filter edges for a homogeneous graph.\n",
      " |      \n",
      " |      >>> g = dgl.graph((torch.tensor([0, 1, 2]), torch.tensor([1, 2, 3])))\n",
      " |      >>> g.edata['h'] = torch.tensor([[0.], [1.], [1.]])\n",
      " |      >>> print(g.filter_edges(edges_with_feature_one))\n",
      " |      tensor([1, 2])\n",
      " |      \n",
      " |      Filter on edges with IDs 0 and 1\n",
      " |      \n",
      " |      >>> print(g.filter_edges(edges_with_feature_one, edges=torch.tensor([0, 1])))\n",
      " |      tensor([1])\n",
      " |      \n",
      " |      Filter edges for a heterogeneous graph.\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({\n",
      " |      ...     ('user', 'plays', 'game'): (torch.tensor([0, 1, 1, 2]),\n",
      " |      ...                                 torch.tensor([0, 0, 1, 1])),\n",
      " |      ...     ('user', 'follows', 'user'): (torch.tensor([0, 1]), torch.tensor([1, 2]))})\n",
      " |      >>> g.edges['plays'].data['h'] = torch.tensor([[0.], [1.], [1.], [0.]])\n",
      " |      >>> # Filter for 'plays' nodes\n",
      " |      >>> print(g.filter_edges(edges_with_feature_one, etype='plays'))\n",
      " |      tensor([1, 2])\n",
      " |  \n",
      " |  filter_nodes(self, predicate, nodes='__ALL__', ntype=None)\n",
      " |      Return the IDs of the nodes with the given node type that satisfy\n",
      " |      the given predicate.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      predicate : callable\n",
      " |          A function of signature ``func(nodes) -> Tensor``.\n",
      " |          ``nodes`` are :class:`dgl.NodeBatch` objects.\n",
      " |          Its output tensor should be a 1D boolean tensor with\n",
      " |          each element indicating whether the corresponding node in\n",
      " |          the batch satisfies the predicate.\n",
      " |      nodes : node ID(s), optional\n",
      " |          The node(s) for query. The allowed formats are:\n",
      " |      \n",
      " |          - Tensor: A 1D tensor that contains the node(s) for query, whose data type\n",
      " |            and device should be the same as the :py:attr:`idtype` and device of the graph.\n",
      " |          - iterable[int] : Similar to the tensor, but stores node IDs in a sequence\n",
      " |            (e.g. list, tuple, numpy.ndarray).\n",
      " |      \n",
      " |          By default, it considers all nodes.\n",
      " |      ntype : str, optional\n",
      " |          The node type for query. If the graph has multiple node types, one must\n",
      " |          specify the argument. Otherwise, it can be omitted.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Tensor\n",
      " |          A 1D tensor that contains the ID(s) of the node(s) that satisfy the predicate.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      Define a predicate function.\n",
      " |      \n",
      " |      >>> def nodes_with_feature_one(nodes):\n",
      " |      ...     # Whether a node has feature 1\n",
      " |      ...     return (nodes.data['h'] == 1.).squeeze(1)\n",
      " |      \n",
      " |      Filter nodes for a homogeneous graph.\n",
      " |      \n",
      " |      >>> g = dgl.graph((torch.tensor([0, 1, 2]), torch.tensor([1, 2, 3])))\n",
      " |      >>> g.ndata['h'] = torch.tensor([[0.], [1.], [1.], [0.]])\n",
      " |      >>> print(g.filter_nodes(nodes_with_feature_one))\n",
      " |      tensor([1, 2])\n",
      " |      \n",
      " |      Filter on nodes with IDs 0 and 1\n",
      " |      \n",
      " |      >>> print(g.filter_nodes(nodes_with_feature_one, nodes=torch.tensor([0, 1])))\n",
      " |      tensor([1])\n",
      " |      \n",
      " |      Filter nodes for a heterogeneous graph.\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({\n",
      " |      ...     ('user', 'plays', 'game'): (torch.tensor([0, 1, 1, 2]),\n",
      " |      ...                                 torch.tensor([0, 0, 1, 1]))})\n",
      " |      >>> g.nodes['user'].data['h'] = torch.tensor([[0.], [1.], [1.]])\n",
      " |      >>> g.nodes['game'].data['h'] = torch.tensor([[0.], [1.]])\n",
      " |      >>> # Filter for 'user' nodes\n",
      " |      >>> print(g.filter_nodes(nodes_with_feature_one, ntype='user'))\n",
      " |      tensor([1, 2])\n",
      " |  \n",
      " |  find_edges(self, eid, etype=None)\n",
      " |      Return the source and destination node ID(s) given the edge ID(s).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      eid : edge ID(s)\n",
      " |          The edge IDs. The allowed formats are:\n",
      " |      \n",
      " |          * ``int``: A single ID.\n",
      " |          * Int Tensor: Each element is an ID. The tensor must have the same device type\n",
      " |            and ID data type as the graph's.\n",
      " |          * iterable[int]: Each element is an ID.\n",
      " |      \n",
      " |      etype : str or (str, str, str), optional\n",
      " |          The type names of the edges. The allowed type name formats are:\n",
      " |      \n",
      " |          * ``(str, str, str)`` for source node type, edge type and destination node type.\n",
      " |          * or one ``str`` edge type name if the name can uniquely identify a\n",
      " |            triplet format in the graph.\n",
      " |      \n",
      " |          Can be omitted if the graph has only one type of edges.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Tensor\n",
      " |          The source node IDs of the edges. The i-th element is the source node ID of\n",
      " |          the i-th edge.\n",
      " |      Tensor\n",
      " |          The destination node IDs of the edges. The i-th element is the destination node\n",
      " |          ID of the i-th edge.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      Create a homogeneous graph.\n",
      " |      \n",
      " |      >>> g = dgl.graph((torch.tensor([0, 0, 1, 1]), torch.tensor([1, 0, 2, 3])))\n",
      " |      \n",
      " |      Find edges of IDs 0 and 2.\n",
      " |      \n",
      " |      >>> g.find_edges(torch.tensor([0, 2]))\n",
      " |      (tensor([0, 1]), tensor([1, 2]))\n",
      " |      \n",
      " |      For a graph of multiple edge types, it is required to specify the edge type in query.\n",
      " |      \n",
      " |      >>> hg = dgl.heterograph({\n",
      " |      ...     ('user', 'follows', 'user'): (torch.tensor([0, 1]), torch.tensor([1, 2])),\n",
      " |      ...     ('user', 'plays', 'game'): (torch.tensor([3, 4]), torch.tensor([5, 6]))\n",
      " |      ... })\n",
      " |      >>> hg.find_edges(torch.tensor([1, 0]), 'plays')\n",
      " |      (tensor([4, 3]), tensor([6, 5]))\n",
      " |  \n",
      " |  formats(self, formats=None)\n",
      " |      Get a cloned graph with the specified sparse format(s) or query\n",
      " |      for the usage status of sparse formats\n",
      " |      \n",
      " |      The API copies both the graph structure and the features.\n",
      " |      \n",
      " |      If the input graph has multiple edge types, they will have the same\n",
      " |      sparse format.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      formats : str or list of str or None\n",
      " |      \n",
      " |          * If formats is None, return the usage status of sparse formats\n",
      " |          * Otherwise, it can be ``'coo'``/``'csr'``/``'csc'`` or a sublist of\n",
      " |            them, specifying the sparse formats to use.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      dict or DGLGraph\n",
      " |      \n",
      " |          * If formats is None, the result will be a dict recording the usage\n",
      " |            status of sparse formats.\n",
      " |          * Otherwise, a DGLGraph will be returned, which is a clone of the\n",
      " |            original graph with the specified sparse format(s) ``formats``.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      **Homographs or Heterographs with A Single Edge Type**\n",
      " |      \n",
      " |      >>> g = dgl.graph(([0, 0, 1], [2, 3, 2]))\n",
      " |      >>> g.ndata['h'] = torch.ones(4, 1)\n",
      " |      >>> # Check status of format usage\n",
      " |      >>> g.formats()\n",
      " |      {'created': ['coo'], 'not created': ['csr', 'csc']}\n",
      " |      >>> # Get a clone of the graph with 'csr' format\n",
      " |      >>> csr_g = g.formats('csr')\n",
      " |      >>> # Only allowed formats will be displayed in the status query\n",
      " |      >>> csr_g.formats()\n",
      " |      {'created': ['csr'], 'not created': []}\n",
      " |      >>> # Features are copied as well\n",
      " |      >>> csr_g.ndata['h']\n",
      " |      tensor([[1.],\n",
      " |              [1.],\n",
      " |              [1.],\n",
      " |              [1.]])\n",
      " |      \n",
      " |      **Heterographs with Multiple Edge Types**\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({\n",
      " |      ...     ('user', 'plays', 'game'): (torch.tensor([0, 1, 1, 2]),\n",
      " |      ...                                 torch.tensor([0, 0, 1, 1])),\n",
      " |      ...     ('developer', 'develops', 'game'): (torch.tensor([0, 1]),\n",
      " |      ...                                         torch.tensor([0, 1]))\n",
      " |      ...     })\n",
      " |      >>> g.formats()\n",
      " |      {'created': ['coo'], 'not created': ['csr', 'csc']}\n",
      " |      >>> # Get a clone of the graph with 'csr' format\n",
      " |      >>> csr_g = g.formats('csr')\n",
      " |      >>> # Only allowed formats will be displayed in the status query\n",
      " |      >>> csr_g.formats()\n",
      " |      {'created': ['csr'], 'not created': []}\n",
      " |  \n",
      " |  from_networkx(self, nx_graph, node_attrs=None, edge_attrs=None)\n",
      " |      DEPRECATED: please use\n",
      " |      \n",
      " |          ``dgl.from_networkx(nx_graph, node_attrs, edge_attrs)``\n",
      " |      \n",
      " |      which will return a new graph created from the networkx graph.\n",
      " |  \n",
      " |  from_scipy_sparse_matrix(self, spmat, multigraph=None)\n",
      " |      DEPRECATED: please use\n",
      " |      \n",
      " |          ``dgl.from_scipy(spmat)``\n",
      " |      \n",
      " |      which will return a new graph created from the scipy matrix.\n",
      " |  \n",
      " |  get_edge_storage(self, key, etype=None)\n",
      " |      Get storage object of edge feature of type :attr:`etype` and name :attr:`key`.\n",
      " |  \n",
      " |  get_etype_id(self, etype)\n",
      " |      Return the id of the given edge type.\n",
      " |      \n",
      " |      etype can also be None. If so, there should be only one edge type in the\n",
      " |      graph.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      etype : str or tuple of str\n",
      " |          Edge type\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      int\n",
      " |  \n",
      " |  get_node_storage(self, key, ntype=None)\n",
      " |      Get storage object of node feature of type :attr:`ntype` and name :attr:`key`.\n",
      " |  \n",
      " |  get_ntype_id(self, ntype)\n",
      " |      Return the ID of the given node type.\n",
      " |      \n",
      " |      ntype can also be None. If so, there should be only one node type in the\n",
      " |      graph.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      ntype : str\n",
      " |          Node type\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      int\n",
      " |  \n",
      " |  get_ntype_id_from_dst(self, ntype)\n",
      " |      Internal function to return the ID of the given DST node type.\n",
      " |      \n",
      " |      ntype can also be None. If so, there should be only one node type in the\n",
      " |      DST category. Callable even when the self graph is not uni-bipartite.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      ntype : str\n",
      " |          Node type\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      int\n",
      " |  \n",
      " |  get_ntype_id_from_src(self, ntype)\n",
      " |      Internal function to return the ID of the given SRC node type.\n",
      " |      \n",
      " |      ntype can also be None. If so, there should be only one node type in the\n",
      " |      SRC category. Callable even when the self graph is not uni-bipartite.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      ntype : str\n",
      " |          Node type\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      int\n",
      " |  \n",
      " |  global_uniform_negative_sampling(g, num_samples, exclude_self_loops=True, replace=False, etype=None, redundancy=None)\n",
      " |      Alias of :func:`dgl.global_uniform_negative_sampling`.\n",
      " |  \n",
      " |  group_apply_edges(self, group_by, func, edges='__ALL__', etype=None, inplace=False)\n",
      " |      **DEPRECATED**: The API is removed in 0.5.\n",
      " |  \n",
      " |  has_edge_between(self, u, v, etype=None)\n",
      " |      Whether the graph has edges of type ``etype``.\n",
      " |      \n",
      " |      **DEPRECATED**: please use :func:`~DGLGraph.has_edge_between`.\n",
      " |  \n",
      " |  has_edges_between(self, u, v, etype=None)\n",
      " |      Return whether the graph contains the given edges.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      u : node IDs\n",
      " |          The source node IDs of the edges. The allowed formats are:\n",
      " |      \n",
      " |          * ``int``: A single node.\n",
      " |          * Int Tensor: Each element is a node ID. The tensor must have the same device type\n",
      " |            and ID data type as the graph's.\n",
      " |          * iterable[int]: Each element is a node ID.\n",
      " |      \n",
      " |      v : node IDs\n",
      " |          The destination node IDs of the edges. The allowed formats are:\n",
      " |      \n",
      " |          * ``int``: A single node.\n",
      " |          * Int Tensor: Each element is a node ID. The tensor must have the same device type\n",
      " |            and ID data type as the graph's.\n",
      " |          * iterable[int]: Each element is a node ID.\n",
      " |      \n",
      " |      etype : str or (str, str, str), optional\n",
      " |          The type names of the edges. The allowed type name formats are:\n",
      " |      \n",
      " |          * ``(str, str, str)`` for source node type, edge type and destination node type.\n",
      " |          * or one ``str`` edge type name if the name can uniquely identify a\n",
      " |            triplet format in the graph.\n",
      " |      \n",
      " |          Can be omitted if the graph has only one type of edges.\n",
      " |      \n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      bool or bool Tensor\n",
      " |          A tensor of bool flags where each element is True if the node is in the graph.\n",
      " |          If the input is a single node, return one bool value.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      Create a homogeneous graph.\n",
      " |      \n",
      " |      >>> g = dgl.graph((torch.tensor([0, 0, 1, 1]), torch.tensor([1, 0, 2, 3])))\n",
      " |      \n",
      " |      Query for the edges.\n",
      " |      \n",
      " |      >>> g.has_edges_between(1, 2)\n",
      " |      True\n",
      " |      >>> g.has_edges_between(torch.tensor([1, 2]), torch.tensor([2, 3]))\n",
      " |      tensor([ True, False])\n",
      " |      \n",
      " |      If the graph has multiple edge types, one need to specify the edge type.\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({\n",
      " |      ...     ('user', 'follows', 'user'): (torch.tensor([0, 1]), torch.tensor([1, 2])),\n",
      " |      ...     ('user', 'follows', 'game'): (torch.tensor([0, 1, 2]), torch.tensor([1, 2, 3])),\n",
      " |      ...     ('user', 'plays', 'game'): (torch.tensor([1, 3]), torch.tensor([2, 3]))\n",
      " |      ... })\n",
      " |      >>> g.has_edges_between(torch.tensor([1, 2]), torch.tensor([2, 3]), 'plays')\n",
      " |      tensor([ True, False])\n",
      " |      \n",
      " |      Use a canonical edge type instead when there is ambiguity for an edge type.\n",
      " |      \n",
      " |      >>> g.has_edges_between(torch.tensor([1, 2]), torch.tensor([2, 3]),\n",
      " |      ...                     ('user', 'follows', 'user'))\n",
      " |      tensor([ True, False])\n",
      " |      >>> g.has_edges_between(torch.tensor([1, 2]), torch.tensor([2, 3]),\n",
      " |      ...                     ('user', 'follows', 'game'))\n",
      " |      tensor([True, True])\n",
      " |  \n",
      " |  has_node(self, vid, ntype=None)\n",
      " |      Whether the graph has a particular node of a given type.\n",
      " |      \n",
      " |      **DEPRECATED**: see :func:`~DGLGraph.has_nodes`\n",
      " |  \n",
      " |  has_nodes(self, vid, ntype=None)\n",
      " |      Return whether the graph contains the given nodes.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      vid : node ID(s)\n",
      " |          The nodes IDs. The allowed nodes ID formats are:\n",
      " |      \n",
      " |          * ``int``: The ID of a single node.\n",
      " |          * Int Tensor: Each element is a node ID. The tensor must have the same device type\n",
      " |            and ID data type as the graph's.\n",
      " |          * iterable[int]: Each element is a node ID.\n",
      " |      \n",
      " |      ntype : str, optional\n",
      " |          The node type name. Can be omitted if there is\n",
      " |          only one type of nodes in the graph.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      bool or bool Tensor\n",
      " |          A tensor of bool flags where each element is True if the node is in the graph.\n",
      " |          If the input is a single node, return one bool value.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      Create a graph with two node types -- 'user' and 'game'.\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({\n",
      " |      ...     ('user', 'follows', 'user'): (torch.tensor([0, 1]), torch.tensor([1, 2])),\n",
      " |      ...     ('user', 'plays', 'game'): (torch.tensor([3, 4]), torch.tensor([0, 1]))\n",
      " |      ... })\n",
      " |      \n",
      " |      Query for the nodes.\n",
      " |      \n",
      " |      >>> g.has_nodes(0, 'user')\n",
      " |      True\n",
      " |      >>> g.has_nodes(3, 'game')\n",
      " |      False\n",
      " |      >>> g.has_nodes(torch.tensor([3, 0, 1]), 'game')\n",
      " |      tensor([False,  True,  True])\n",
      " |  \n",
      " |  in_degree(self, v, etype=None)\n",
      " |      Return the in-degree of node ``v`` with edges of type ``etype``.\n",
      " |      \n",
      " |      **DEPRECATED**: Please use in_degrees\n",
      " |  \n",
      " |  in_degrees(self, v='__ALL__', etype=None)\n",
      " |      Return the in-degree(s) of the given nodes.\n",
      " |      \n",
      " |      It computes the in-degree(s) w.r.t. to the edges of the given edge type.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      v : node IDs\n",
      " |          The node IDs. The allowed formats are:\n",
      " |      \n",
      " |          * ``int``: A single node.\n",
      " |          * Int Tensor: Each element is a node ID. The tensor must have the same device type\n",
      " |            and ID data type as the graph's.\n",
      " |          * iterable[int]: Each element is a node ID.\n",
      " |      \n",
      " |          If not given, return the in-degrees of all the nodes.\n",
      " |      etype : str or (str, str, str), optional\n",
      " |          The type name of the edges. The allowed type name formats are:\n",
      " |      \n",
      " |          * ``(str, str, str)`` for source node type, edge type and destination node type.\n",
      " |          * or one ``str`` edge type name if the name can uniquely identify a\n",
      " |            triplet format in the graph.\n",
      " |      \n",
      " |          Can be omitted if the graph has only one type of edges.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      int or Tensor\n",
      " |          The in-degree(s) of the node(s) in a Tensor. The i-th element is the in-degree\n",
      " |          of the i-th input node. If :attr:`v` is an ``int``, return an ``int`` too.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      Create a homogeneous graph.\n",
      " |      \n",
      " |      >>> g = dgl.graph((torch.tensor([0, 0, 1, 1]), torch.tensor([1, 1, 2, 3])))\n",
      " |      \n",
      " |      Query for all nodes.\n",
      " |      \n",
      " |      >>> g.in_degrees()\n",
      " |      tensor([0, 2, 1, 1])\n",
      " |      \n",
      " |      Query for nodes 1 and 2.\n",
      " |      \n",
      " |      >>> g.in_degrees(torch.tensor([1, 2]))\n",
      " |      tensor([2, 1])\n",
      " |      \n",
      " |      For a graph of multiple edge types, it is required to specify the edge type in query.\n",
      " |      \n",
      " |      >>> hg = dgl.heterograph({\n",
      " |      ...     ('user', 'follows', 'user'): (torch.tensor([0, 1]), torch.tensor([1, 2])),\n",
      " |      ...     ('user', 'plays', 'game'): (torch.tensor([3, 4]), torch.tensor([5, 6]))\n",
      " |      ... })\n",
      " |      >>> hg.in_degrees(torch.tensor([1, 0]), etype='follows')\n",
      " |      tensor([1, 0])\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      out_degrees\n",
      " |  \n",
      " |  in_edges(self, v, form='uv', etype=None)\n",
      " |      Return the incoming edges of the given nodes.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      v : node ID(s)\n",
      " |          The node IDs. The allowed formats are:\n",
      " |      \n",
      " |          * ``int``: A single node.\n",
      " |          * Int Tensor: Each element is a node ID. The tensor must have the same device type\n",
      " |            and ID data type as the graph's.\n",
      " |          * iterable[int]: Each element is a node ID.\n",
      " |      form : str, optional\n",
      " |          The result format, which can be one of the following:\n",
      " |      \n",
      " |          - ``'eid'``: The returned result is a 1D tensor :math:`EID`, representing\n",
      " |            the IDs of all edges.\n",
      " |          - ``'uv'`` (default): The returned result is a 2-tuple of 1D tensors :math:`(U, V)`,\n",
      " |            representing the source and destination nodes of all edges. For each :math:`i`,\n",
      " |            :math:`(U[i], V[i])` forms an edge.\n",
      " |          - ``'all'``: The returned result is a 3-tuple of 1D tensors :math:`(U, V, EID)`,\n",
      " |            representing the source nodes, destination nodes and IDs of all edges.\n",
      " |            For each :math:`i`, :math:`(U[i], V[i])` forms an edge with ID :math:`EID[i]`.\n",
      " |      etype : str or (str, str, str), optional\n",
      " |          The type names of the edges. The allowed type name formats are:\n",
      " |      \n",
      " |          * ``(str, str, str)`` for source node type, edge type and destination node type.\n",
      " |          * or one ``str`` edge type name if the name can uniquely identify a\n",
      " |            triplet format in the graph.\n",
      " |      \n",
      " |          Can be omitted if the graph has only one type of edges.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Tensor or (Tensor, Tensor) or (Tensor, Tensor, Tensor)\n",
      " |          All incoming edges of the nodes with the specified type. For a description of the\n",
      " |          returned result, see the description of :attr:`form`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      Create a homogeneous graph.\n",
      " |      \n",
      " |      >>> g = dgl.graph((torch.tensor([0, 0, 1, 1]), torch.tensor([1, 0, 2, 3])))\n",
      " |      \n",
      " |      Query for the nodes 1 and 0.\n",
      " |      \n",
      " |      >>> g.in_edges(torch.tensor([1, 0]))\n",
      " |      (tensor([0, 0]), tensor([1, 0]))\n",
      " |      \n",
      " |      Specify a different value for :attr:`form`.\n",
      " |      \n",
      " |      >>> g.in_edges(torch.tensor([1, 0]), form='all')\n",
      " |      (tensor([0, 0]), tensor([1, 0]), tensor([0, 1]))\n",
      " |      \n",
      " |      For a graph of multiple edge types, it is required to specify the edge type in query.\n",
      " |      \n",
      " |      >>> hg = dgl.heterograph({\n",
      " |      ...     ('user', 'follows', 'user'): (torch.tensor([0, 1]), torch.tensor([1, 2])),\n",
      " |      ...     ('user', 'plays', 'game'): (torch.tensor([3, 4]), torch.tensor([5, 6]))\n",
      " |      ... })\n",
      " |      >>> hg.in_edges(torch.tensor([1, 0]), etype='follows')\n",
      " |      (tensor([0]), tensor([1]))\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      edges\n",
      " |      out_edges\n",
      " |  \n",
      " |  in_subgraph(graph, nodes, *, relabel_nodes=False, store_ids=True, output_device=None)\n",
      " |      Alias of :func:`dgl.in_subgraph`.\n",
      " |  \n",
      " |  inc(self, typestr, ctx=device(type='cpu'), etype=None)\n",
      " |      Return the incidence matrix representation of edges with the given\n",
      " |      edge type.\n",
      " |      \n",
      " |      An incidence matrix is an n-by-m sparse matrix, where n is\n",
      " |      the number of nodes and m is the number of edges. Each nnz\n",
      " |      value indicating whether the edge is incident to the node\n",
      " |      or not.\n",
      " |      \n",
      " |      There are three types of incidence matrices :math:`I`:\n",
      " |      \n",
      " |      * ``in``:\n",
      " |      \n",
      " |          - :math:`I[v, e] = 1` if :math:`e` is the in-edge of :math:`v`\n",
      " |            (or :math:`v` is the dst node of :math:`e`);\n",
      " |          - :math:`I[v, e] = 0` otherwise.\n",
      " |      \n",
      " |      * ``out``:\n",
      " |      \n",
      " |          - :math:`I[v, e] = 1` if :math:`e` is the out-edge of :math:`v`\n",
      " |            (or :math:`v` is the src node of :math:`e`);\n",
      " |          - :math:`I[v, e] = 0` otherwise.\n",
      " |      \n",
      " |      * ``both`` (only if source and destination node type are the same):\n",
      " |      \n",
      " |          - :math:`I[v, e] = 1` if :math:`e` is the in-edge of :math:`v`;\n",
      " |          - :math:`I[v, e] = -1` if :math:`e` is the out-edge of :math:`v`;\n",
      " |          - :math:`I[v, e] = 0` otherwise (including self-loop).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      typestr : str\n",
      " |          Can be either ``in``, ``out`` or ``both``\n",
      " |      ctx : context, optional\n",
      " |          The context of returned incidence matrix. (Default: cpu)\n",
      " |      etype : str or (str, str, str), optional\n",
      " |          The type names of the edges. The allowed type name formats are:\n",
      " |      \n",
      " |          * ``(str, str, str)`` for source node type, edge type and destination node type.\n",
      " |          * or one ``str`` edge type name if the name can uniquely identify a\n",
      " |            triplet format in the graph.\n",
      " |      \n",
      " |          Can be omitted if the graph has only one type of edges.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Framework SparseTensor\n",
      " |          The incidence matrix.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      \n",
      " |      >>> g = dgl.graph(([0, 1], [0, 2]))\n",
      " |      >>> g.inc('in')\n",
      " |      tensor(indices=tensor([[0, 2],\n",
      " |                             [0, 1]]),\n",
      " |             values=tensor([1., 1.]),\n",
      " |             size=(3, 2), nnz=2, layout=torch.sparse_coo)\n",
      " |      >>> g.inc('out')\n",
      " |      tensor(indices=tensor([[0, 1],\n",
      " |                             [0, 1]]),\n",
      " |             values=tensor([1., 1.]),\n",
      " |             size=(3, 2), nnz=2, layout=torch.sparse_coo)\n",
      " |      >>> g.inc('both')\n",
      " |      tensor(indices=tensor([[1, 2],\n",
      " |                             [1, 1]]),\n",
      " |             values=tensor([-1.,  1.]),\n",
      " |             size=(3, 2), nnz=2, layout=torch.sparse_coo)\n",
      " |  \n",
      " |  incidence_matrix = inc(self, typestr, ctx=device(type='cpu'), etype=None)\n",
      " |  \n",
      " |  int(self)\n",
      " |      Cast the graph to one with idtype int32\n",
      " |      \n",
      " |      If the graph already has idtype int32, the function directly returns it. Otherwise,\n",
      " |      it returns a cloned graph of idtype int32 with features copied (shallow copy).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DGLGraph\n",
      " |          The graph of idtype int32.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      Create a graph of idtype int64.\n",
      " |      \n",
      " |      >>> # (0, 1), (0, 2), (1, 2)\n",
      " |      >>> g = dgl.graph((torch.tensor([0, 0, 1]), torch.tensor([1, 2, 2])))\n",
      " |      >>> g.ndata['feat'] = torch.ones(3, 1)\n",
      " |      >>> g.idtype\n",
      " |      torch.int64\n",
      " |      \n",
      " |      Cast the graph to one of idtype int32.\n",
      " |      \n",
      " |      >>> # A cloned graph with an idtype of int32\n",
      " |      >>> g_int = g.int()\n",
      " |      >>> g_int.idtype\n",
      " |      torch.int32\n",
      " |      >>> # The idtype of the original graph does not change.\n",
      " |      >>> g.idtype\n",
      " |      torch.int64\n",
      " |      >>> g_int.edges()\n",
      " |      (tensor([0, 0, 1], dtype=torch.int32), tensor([1, 2, 2], dtype=torch.int32))\n",
      " |      >>> g_int.ndata\n",
      " |      {'feat': tensor([[1.],\n",
      " |                       [1.],\n",
      " |                       [1.]])}\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      long\n",
      " |      idtype\n",
      " |  \n",
      " |  is_pinned(self)\n",
      " |      Check if the graph structure is pinned to the page-locked memory.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      bool\n",
      " |          True if the graph structure is pinned.\n",
      " |  \n",
      " |  khop_in_subgraph(graph, nodes, k, *, relabel_nodes=True, store_ids=True, output_device=None)\n",
      " |      Alias of :func:`dgl.khop_in_subgraph`.\n",
      " |  \n",
      " |  khop_out_subgraph(graph, nodes, k, *, relabel_nodes=True, store_ids=True, output_device=None)\n",
      " |      Alias of :func:`dgl.khop_out_subgraph`.\n",
      " |  \n",
      " |  line_graph(g, backtracking=True, shared=False)\n",
      " |      Alias of :func:`dgl.line_graph`.\n",
      " |  \n",
      " |  local_scope(self)\n",
      " |      Enter a local scope context for the graph.\n",
      " |      \n",
      " |      By entering a local scope, any out-place mutation to the feature data will\n",
      " |      not reflect to the original graph, thus making it easier to use in a function scope\n",
      " |      (e.g. forward computation of a model).\n",
      " |      \n",
      " |      If set, the local scope will use same initializers for node features and\n",
      " |      edge features.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Inplace operations do reflect to the original graph. This function also has little\n",
      " |      overhead when the number of feature tensors in this graph is small.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      Create a function for computation on graphs.\n",
      " |      \n",
      " |      >>> def foo(g):\n",
      " |      ...     with g.local_scope():\n",
      " |      ...         g.edata['h'] = torch.ones((g.num_edges(), 3))\n",
      " |      ...         g.edata['h2'] = torch.ones((g.num_edges(), 3))\n",
      " |      ...         return g.edata['h']\n",
      " |      \n",
      " |      ``local_scope`` avoids changing the graph features when exiting the function.\n",
      " |      \n",
      " |      >>> g = dgl.graph((torch.tensor([0, 1, 1]), torch.tensor([0, 0, 2])))\n",
      " |      >>> g.edata['h'] = torch.zeros((g.num_edges(), 3))\n",
      " |      >>> newh = foo(g)\n",
      " |      >>> print(g.edata['h'])  # still get tensor of all zeros\n",
      " |      tensor([[0., 0., 0.],\n",
      " |              [0., 0., 0.],\n",
      " |              [0., 0., 0.]])\n",
      " |      >>> 'h2' in g.edata      # new feature set in the function scope is not found\n",
      " |      False\n",
      " |      \n",
      " |      In-place operations will still reflect to the original graph.\n",
      " |      \n",
      " |      >>> def foo(g):\n",
      " |      ...     with g.local_scope():\n",
      " |      ...         # in-place operation\n",
      " |      ...         g.edata['h'] += 1\n",
      " |      ...         return g.edata['h']\n",
      " |      \n",
      " |      >>> g = dgl.graph((torch.tensor([0, 1, 1]), torch.tensor([0, 0, 2])))\n",
      " |      >>> g.edata['h'] = torch.zeros((g.num_edges(), 1))\n",
      " |      >>> newh = foo(g)\n",
      " |      >>> print(g.edata['h'])  # the result changes\n",
      " |      tensor([[1.],\n",
      " |              [1.],\n",
      " |              [1.]])\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      local_var\n",
      " |  \n",
      " |  local_var(self)\n",
      " |      Return a graph object for usage in a local function scope.\n",
      " |      \n",
      " |      The returned graph object shares the feature data and graph structure of this graph.\n",
      " |      However, any out-place mutation to the feature data will not reflect to this graph,\n",
      " |      thus making it easier to use in a function scope (e.g. forward computation of a model).\n",
      " |      \n",
      " |      If set, the local graph object will use same initializers for node features and\n",
      " |      edge features.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DGLGraph\n",
      " |          The graph object for a local variable.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Inplace operations do reflect to the original graph. This function also has little\n",
      " |      overhead when the number of feature tensors in this graph is small.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      Create a function for computation on graphs.\n",
      " |      \n",
      " |      >>> def foo(g):\n",
      " |      ...     g = g.local_var()\n",
      " |      ...     g.edata['h'] = torch.ones((g.num_edges(), 3))\n",
      " |      ...     g.edata['h2'] = torch.ones((g.num_edges(), 3))\n",
      " |      ...     return g.edata['h']\n",
      " |      \n",
      " |      ``local_var`` avoids changing the graph features when exiting the function.\n",
      " |      \n",
      " |      >>> g = dgl.graph((torch.tensor([0, 1, 1]), torch.tensor([0, 0, 2])))\n",
      " |      >>> g.edata['h'] = torch.zeros((g.num_edges(), 3))\n",
      " |      >>> newh = foo(g)\n",
      " |      >>> print(g.edata['h'])  # still get tensor of all zeros\n",
      " |      tensor([[0., 0., 0.],\n",
      " |              [0., 0., 0.],\n",
      " |              [0., 0., 0.]])\n",
      " |      >>> 'h2' in g.edata      # new feature set in the function scope is not found\n",
      " |      False\n",
      " |      \n",
      " |      In-place operations will still reflect to the original graph.\n",
      " |      \n",
      " |      >>> def foo(g):\n",
      " |      ...     g = g.local_var()\n",
      " |      ...     # in-place operation\n",
      " |      ...     g.edata['h'] += 1\n",
      " |      ...     return g.edata['h']\n",
      " |      \n",
      " |      >>> g = dgl.graph((torch.tensor([0, 1, 1]), torch.tensor([0, 0, 2])))\n",
      " |      >>> g.edata['h'] = torch.zeros((g.num_edges(), 1))\n",
      " |      >>> newh = foo(g)\n",
      " |      >>> print(g.edata['h'])  # the result changes\n",
      " |      tensor([[1.],\n",
      " |              [1.],\n",
      " |              [1.]])\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      local_scope\n",
      " |  \n",
      " |  long(self)\n",
      " |      Cast the graph to one with idtype int64\n",
      " |      \n",
      " |      If the graph already has idtype int64, the function directly returns it. Otherwise,\n",
      " |      it returns a cloned graph of idtype int64 with features copied (shallow copy).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DGLGraph\n",
      " |          The graph of idtype int64.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      Create a graph of idtype int32.\n",
      " |      \n",
      " |      >>> # (0, 1), (0, 2), (1, 2)\n",
      " |      >>> g = dgl.graph((torch.tensor([0, 0, 1]).int(), torch.tensor([1, 2, 2]).int()))\n",
      " |      >>> g.ndata['feat'] = torch.ones(3, 1)\n",
      " |      >>> g.idtype\n",
      " |      torch.int32\n",
      " |      \n",
      " |      Cast the graph to one of idtype int64.\n",
      " |      \n",
      " |      >>> # A cloned graph with an idtype of int64\n",
      " |      >>> g_long = g.long()\n",
      " |      >>> g_long.idtype\n",
      " |      torch.int64\n",
      " |      >>> # The idtype of the original graph does not change.\n",
      " |      >>> g.idtype\n",
      " |      torch.int32\n",
      " |      >>> g_long.edges()\n",
      " |      (tensor([0, 0, 1]), tensor([1, 2, 2]))\n",
      " |      >>> g_long.ndata\n",
      " |      {'feat': tensor([[1.],\n",
      " |                       [1.],\n",
      " |                       [1.]])}\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      int\n",
      " |      idtype\n",
      " |  \n",
      " |  metagraph(self)\n",
      " |      Return the metagraph of the heterograph.\n",
      " |      \n",
      " |      The metagraph (or network schema) of a heterogeneous network specifies type constraints\n",
      " |      on the sets of nodes and edges between the nodes. For a formal definition, refer to\n",
      " |      `Yizhou et al. <https://www.kdd.org/exploration_files/V14-02-03-Sun.pdf>`_.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      networkx.MultiDiGraph\n",
      " |          The metagraph.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({\n",
      " |      ...     ('user', 'follows', 'user'): (torch.tensor([0, 1]), torch.tensor([1, 2])),\n",
      " |      ...     ('user', 'follows', 'game'): (torch.tensor([0, 1, 2]), torch.tensor([1, 2, 3])),\n",
      " |      ...     ('user', 'plays', 'game'): (torch.tensor([1, 3]), torch.tensor([2, 3]))\n",
      " |      ... })\n",
      " |      >>> meta_g = g.metagraph()\n",
      " |      >>> meta_g.nodes()\n",
      " |      NodeView(('user', 'game'))\n",
      " |      >>> meta_g.edges()\n",
      " |      OutMultiEdgeDataView([('user', 'user'), ('user', 'game'), ('user', 'game')])\n",
      " |  \n",
      " |  multi_pull(self, v, etype_dict, cross_reducer, apply_node_func=None, inplace=False)\n",
      " |      **DEPRECATED**: The API is removed in v0.5.\n",
      " |  \n",
      " |  multi_recv(self, v, reducer_dict, cross_reducer, apply_node_func=None, inplace=False)\n",
      " |      Receive messages from multiple edge types and perform aggregation.\n",
      " |      \n",
      " |      DEPRECATE: please use multi_send_and_recv, multi_update_all.\n",
      " |  \n",
      " |  multi_send_and_recv(self, etype_dict, cross_reducer, apply_node_func=None, inplace=False)\n",
      " |      **DEPRECATED**: The API is removed in v0.5.\n",
      " |  \n",
      " |  multi_update_all(self, etype_dict, cross_reducer, apply_node_func=None)\n",
      " |      Send messages along all the edges, reduce them by first type-wisely\n",
      " |      then across different types, and then update the node features of all\n",
      " |      the nodes.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      etype_dict : dict\n",
      " |          Arguments for edge-type-wise message passing. The keys are edge types\n",
      " |          while the values are message passing arguments.\n",
      " |      \n",
      " |          The allowed key formats are:\n",
      " |      \n",
      " |          * ``(str, str, str)`` for source node type, edge type and destination node type.\n",
      " |          * or one ``str`` edge type name if the name can uniquely identify a\n",
      " |            triplet format in the graph.\n",
      " |      \n",
      " |          The value must be a tuple ``(message_func, reduce_func, [apply_node_func])``, where\n",
      " |      \n",
      " |          * message_func : dgl.function.BuiltinFunction or callable\n",
      " |              The message function to generate messages along the edges.\n",
      " |              It must be either a :ref:`api-built-in` or a :ref:`apiudf`.\n",
      " |          * reduce_func : dgl.function.BuiltinFunction or callable\n",
      " |              The reduce function to aggregate the messages.\n",
      " |              It must be either a :ref:`api-built-in` or a :ref:`apiudf`.\n",
      " |          * apply_node_func : callable, optional\n",
      " |              An optional apply function to further update the node features\n",
      " |              after the message reduction. It must be a :ref:`apiudf`.\n",
      " |      \n",
      " |      cross_reducer : str or callable function\n",
      " |          Cross type reducer. One of ``\"sum\"``, ``\"min\"``, ``\"max\"``, ``\"mean\"``, ``\"stack\"``\n",
      " |          or a callable function. If a callable function is provided, the input argument must be\n",
      " |          a single list of tensors containing aggregation results from each edge type, and the\n",
      " |          output of function must be a single tensor.\n",
      " |      apply_node_func : callable, optional\n",
      " |          An optional apply function after the messages are reduced both\n",
      " |          type-wisely and across different types.\n",
      " |          It must be a :ref:`apiudf`.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      DGL recommends using DGL's bulit-in function for the message_func\n",
      " |      and the reduce_func in the type-wise message passing arguments,\n",
      " |      because DGL will invoke efficient kernels that avoids copying node features to\n",
      " |      edge features in this case.\n",
      " |      \n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> import dgl\n",
      " |      >>> import dgl.function as fn\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      Instantiate a heterograph.\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({\n",
      " |      ...     ('user', 'follows', 'user'): ([0, 1], [1, 1]),\n",
      " |      ...     ('game', 'attracts', 'user'): ([0], [1])\n",
      " |      ... })\n",
      " |      >>> g.nodes['user'].data['h'] = torch.tensor([[1.], [2.]])\n",
      " |      >>> g.nodes['game'].data['h'] = torch.tensor([[1.]])\n",
      " |      \n",
      " |      Update all.\n",
      " |      \n",
      " |      >>> g.multi_update_all(\n",
      " |      ...     {'follows': (fn.copy_src('h', 'm'), fn.sum('m', 'h')),\n",
      " |      ...      'attracts': (fn.copy_src('h', 'm'), fn.sum('m', 'h'))},\n",
      " |      ... \"sum\")\n",
      " |      >>> g.nodes['user'].data['h']\n",
      " |      tensor([[0.],\n",
      " |              [4.]])\n",
      " |      \n",
      " |      User-defined cross reducer equivalent to \"sum\".\n",
      " |      \n",
      " |      >>> def cross_sum(flist):\n",
      " |      ...     return torch.sum(torch.stack(flist, dim=0), dim=0) if len(flist) > 1 else flist[0]\n",
      " |      \n",
      " |      Use the user-defined cross reducer.\n",
      " |      \n",
      " |      >>> g.multi_update_all(\n",
      " |      ...     {'follows': (fn.copy_src('h', 'm'), fn.sum('m', 'h')),\n",
      " |      ...      'attracts': (fn.copy_src('h', 'm'), fn.sum('m', 'h'))},\n",
      " |      ... cross_sum)\n",
      " |  \n",
      " |  node_attr_schemes(self, ntype=None)\n",
      " |      Return the node feature schemes for the specified type.\n",
      " |      \n",
      " |      The scheme of a feature describes the shape and data type of it.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      ntype : str, optional\n",
      " |          The node type name. Can be omitted if there is only one type of nodes\n",
      " |          in the graph.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      dict[str, Scheme]\n",
      " |          A dictionary mapping a feature name to its associated feature scheme.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      Query for a homogeneous graph.\n",
      " |      \n",
      " |      >>> g = dgl.graph((torch.tensor([0, 1]), torch.tensor([1, 2])))\n",
      " |      >>> g.ndata['h1'] = torch.randn(3, 1)\n",
      " |      >>> g.ndata['h2'] = torch.randn(3, 2)\n",
      " |      >>> g.node_attr_schemes()\n",
      " |      {'h1': Scheme(shape=(1,), dtype=torch.float32),\n",
      " |       'h2': Scheme(shape=(2,), dtype=torch.float32)}\n",
      " |      \n",
      " |      Query for a heterogeneous graph of multiple node types.\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({('user', 'plays', 'game'):\n",
      " |      ...                      (torch.tensor([1, 2]), torch.tensor([3, 4]))})\n",
      " |      >>> g.nodes['user'].data['h1'] = torch.randn(3, 1)\n",
      " |      >>> g.nodes['user'].data['h2'] = torch.randn(3, 2)\n",
      " |      >>> g.node_attr_schemes('user')\n",
      " |      {'h1': Scheme(shape=(1,), dtype=torch.float32),\n",
      " |       'h2': Scheme(shape=(2,), dtype=torch.float32)}\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      edge_attr_schemes\n",
      " |  \n",
      " |  node_type_subgraph(graph, ntypes, output_device=None)\n",
      " |      Alias of :func:`dgl.node_type_subgraph`.\n",
      " |  \n",
      " |  num_dst_nodes(self, ntype=None)\n",
      " |      Return the number of destination nodes in the graph.\n",
      " |      \n",
      " |      If the graph can further divide its node types into two subsets A and B where\n",
      " |      all the edeges are from nodes of types in A to nodes of types in B, we call\n",
      " |      this graph a *uni-bipartite* graph and the nodes in A being the *source*\n",
      " |      nodes and the ones in B being the *destination* nodes. If the graph is not\n",
      " |      uni-bipartite, the source and destination nodes are just the entire set of\n",
      " |      nodes in the graph.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      ntype : str, optional\n",
      " |          The destination node type name. If given, it returns the number of nodes of\n",
      " |          the destination node type. If not given (default), it returns the number of\n",
      " |          nodes summed over all the destination node types.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      int\n",
      " |          The number of nodes\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      num_src_nodes\n",
      " |      is_unibipartite\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      Create a homogeneous graph for query.\n",
      " |      \n",
      " |      >>> g = dgl.graph((torch.tensor([0, 1]), torch.tensor([1, 2])))\n",
      " |      >>> g.num_dst_nodes()\n",
      " |      3\n",
      " |      \n",
      " |      Create a heterogeneous graph with two destination node types -- 'user' and 'game'.\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({\n",
      " |      ...     ('user', 'follows', 'user'): (torch.tensor([0, 1]), torch.tensor([1, 2])),\n",
      " |      ...     ('user', 'plays', 'game'): (torch.tensor([3, 4]), torch.tensor([5, 6]))\n",
      " |      ... })\n",
      " |      \n",
      " |      Query for the number of nodes.\n",
      " |      \n",
      " |      >>> g.num_dst_nodes('user')\n",
      " |      5\n",
      " |      >>> g.num_dst_nodes('game')\n",
      " |      7\n",
      " |      >>> g.num_dst_nodes()\n",
      " |      12\n",
      " |  \n",
      " |  num_edges(self, etype=None)\n",
      " |      Return the number of edges in the graph.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      etype : str or (str, str, str), optional\n",
      " |          The type name of the edges. The allowed type name formats are:\n",
      " |      \n",
      " |          * ``(str, str, str)`` for source node type, edge type and destination node type.\n",
      " |          * or one ``str`` edge type name if the name can uniquely identify a\n",
      " |            triplet format in the graph.\n",
      " |      \n",
      " |          If not provided, return the total number of edges regardless of the types\n",
      " |          in the graph.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      int\n",
      " |          The number of edges.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      Create a graph with three canonical edge types.\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({\n",
      " |      ...     ('user', 'follows', 'user'): (torch.tensor([0, 1]), torch.tensor([1, 2])),\n",
      " |      ...     ('user', 'follows', 'game'): (torch.tensor([0, 1, 2]), torch.tensor([1, 2, 3])),\n",
      " |      ...     ('user', 'plays', 'game'): (torch.tensor([1, 3]), torch.tensor([2, 3]))\n",
      " |      ... })\n",
      " |      \n",
      " |      Query for the number of edges.\n",
      " |      \n",
      " |      >>> g.num_edges('plays')\n",
      " |      2\n",
      " |      >>> g.num_edges()\n",
      " |      7\n",
      " |      \n",
      " |      Use a canonical edge type instead when there is ambiguity for an edge type.\n",
      " |      \n",
      " |      >>> g.num_edges(('user', 'follows', 'user'))\n",
      " |      2\n",
      " |      >>> g.num_edges(('user', 'follows', 'game'))\n",
      " |      3\n",
      " |  \n",
      " |  num_nodes(self, ntype=None)\n",
      " |      Return the number of nodes in the graph.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      ntype : str, optional\n",
      " |          The node type name. If given, it returns the number of nodes of the\n",
      " |          type. If not given (default), it returns the total number of nodes of all types.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      int\n",
      " |          The number of nodes.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      Create a graph with two node types -- 'user' and 'game'.\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({\n",
      " |      ...     ('user', 'follows', 'user'): (torch.tensor([0, 1]), torch.tensor([1, 2])),\n",
      " |      ...     ('user', 'plays', 'game'): (torch.tensor([3, 4]), torch.tensor([5, 6]))\n",
      " |      ... })\n",
      " |      \n",
      " |      Query for the number of nodes.\n",
      " |      \n",
      " |      >>> g.num_nodes('user')\n",
      " |      5\n",
      " |      >>> g.num_nodes('game')\n",
      " |      7\n",
      " |      >>> g.num_nodes()\n",
      " |      12\n",
      " |  \n",
      " |  num_src_nodes(self, ntype=None)\n",
      " |      Return the number of source nodes in the graph.\n",
      " |      \n",
      " |      If the graph can further divide its node types into two subsets A and B where\n",
      " |      all the edeges are from nodes of types in A to nodes of types in B, we call\n",
      " |      this graph a *uni-bipartite* graph and the nodes in A being the *source*\n",
      " |      nodes and the ones in B being the *destination* nodes. If the graph is not\n",
      " |      uni-bipartite, the source and destination nodes are just the entire set of\n",
      " |      nodes in the graph.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      ntype : str, optional\n",
      " |          The source node type name. If given, it returns the number of nodes for\n",
      " |          the source node type. If not given (default), it returns the number of\n",
      " |          nodes summed over all source node types.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      int\n",
      " |          The number of nodes\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      num_dst_nodes\n",
      " |      is_unibipartite\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      Create a homogeneous graph for query.\n",
      " |      \n",
      " |      >>> g = dgl.graph((torch.tensor([0, 1]), torch.tensor([1, 2])))\n",
      " |      >>> g.num_src_nodes()\n",
      " |      3\n",
      " |      \n",
      " |      Create a heterogeneous graph with two source node types -- 'developer' and 'user'.\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({\n",
      " |      ...     ('developer', 'develops', 'game'): (torch.tensor([0, 1]), torch.tensor([1, 2])),\n",
      " |      ...     ('user', 'plays', 'game'): (torch.tensor([3, 4]), torch.tensor([5, 6]))\n",
      " |      ... })\n",
      " |      \n",
      " |      Query for the number of nodes.\n",
      " |      \n",
      " |      >>> g.num_src_nodes('developer')\n",
      " |      2\n",
      " |      >>> g.num_src_nodes('user')\n",
      " |      5\n",
      " |      >>> g.num_src_nodes()\n",
      " |      7\n",
      " |  \n",
      " |  number_of_dst_nodes(self, ntype=None)\n",
      " |      Alias of :func:`num_dst_nodes`\n",
      " |  \n",
      " |  number_of_edges(self, etype=None)\n",
      " |      Alias of :func:`num_edges`\n",
      " |  \n",
      " |  number_of_nodes(self, ntype=None)\n",
      " |      Alias of :meth:`num_nodes`\n",
      " |  \n",
      " |  number_of_src_nodes(self, ntype=None)\n",
      " |      Alias of :meth:`num_src_nodes`\n",
      " |  \n",
      " |  out_degree(self, u, etype=None)\n",
      " |      Return the out-degree of node `u` with edges of type ``etype``.\n",
      " |      \n",
      " |      DEPRECATED: please use DGL.out_degrees\n",
      " |  \n",
      " |  out_degrees(self, u='__ALL__', etype=None)\n",
      " |      Return the out-degree(s) of the given nodes.\n",
      " |      \n",
      " |      It computes the out-degree(s) w.r.t. to the edges of the given edge type.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      u : node IDs\n",
      " |          The node IDs. The allowed formats are:\n",
      " |      \n",
      " |          * ``int``: A single node.\n",
      " |          * Int Tensor: Each element is a node ID. The tensor must have the same device type\n",
      " |            and ID data type as the graph's.\n",
      " |          * iterable[int]: Each element is a node ID.\n",
      " |      \n",
      " |          If not given, return the in-degrees of all the nodes.\n",
      " |      etype : str or (str, str, str), optional\n",
      " |          The type names of the edges. The allowed type name formats are:\n",
      " |      \n",
      " |          * ``(str, str, str)`` for source node type, edge type and destination node type.\n",
      " |          * or one ``str`` edge type name if the name can uniquely identify a\n",
      " |            triplet format in the graph.\n",
      " |      \n",
      " |          Can be omitted if the graph has only one type of edges.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      int or Tensor\n",
      " |          The out-degree(s) of the node(s) in a Tensor. The i-th element is the out-degree\n",
      " |          of the i-th input node. If :attr:`v` is an ``int``, return an ``int`` too.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      Create a homogeneous graph.\n",
      " |      \n",
      " |      >>> g = dgl.graph((torch.tensor([0, 0, 1, 1]), torch.tensor([1, 1, 2, 3])))\n",
      " |      \n",
      " |      Query for all nodes.\n",
      " |      \n",
      " |      >>> g.out_degrees()\n",
      " |      tensor([2, 2, 0, 0])\n",
      " |      \n",
      " |      Query for nodes 1 and 2.\n",
      " |      \n",
      " |      >>> g.out_degrees(torch.tensor([1, 2]))\n",
      " |      tensor([2, 0])\n",
      " |      \n",
      " |      For a graph of multiple edge types, it is required to specify the edge type in query.\n",
      " |      \n",
      " |      >>> hg = dgl.heterograph({\n",
      " |      ...     ('user', 'follows', 'user'): (torch.tensor([0, 1]), torch.tensor([1, 2])),\n",
      " |      ...     ('user', 'plays', 'game'): (torch.tensor([3, 4]), torch.tensor([5, 6]))\n",
      " |      ... })\n",
      " |      >>> hg.out_degrees(torch.tensor([1, 0]), etype='follows')\n",
      " |      tensor([1, 1])\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      in_degrees\n",
      " |  \n",
      " |  out_edges(self, u, form='uv', etype=None)\n",
      " |      Return the outgoing edges of the given nodes.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      u : node ID(s)\n",
      " |          The node IDs. The allowed formats are:\n",
      " |      \n",
      " |          * ``int``: A single node.\n",
      " |          * Int Tensor: Each element is a node ID. The tensor must have the same device type\n",
      " |            and ID data type as the graph's.\n",
      " |          * iterable[int]: Each element is a node ID.\n",
      " |      form : str, optional\n",
      " |          The return form, which can be one of the following:\n",
      " |      \n",
      " |          - ``'eid'``: The returned result is a 1D tensor :math:`EID`, representing\n",
      " |            the IDs of all edges.\n",
      " |          - ``'uv'`` (default): The returned result is a 2-tuple of 1D tensors :math:`(U, V)`,\n",
      " |            representing the source and destination nodes of all edges. For each :math:`i`,\n",
      " |            :math:`(U[i], V[i])` forms an edge.\n",
      " |          - ``'all'``: The returned result is a 3-tuple of 1D tensors :math:`(U, V, EID)`,\n",
      " |            representing the source nodes, destination nodes and IDs of all edges.\n",
      " |            For each :math:`i`, :math:`(U[i], V[i])` forms an edge with ID :math:`EID[i]`.\n",
      " |      etype : str or (str, str, str), optional\n",
      " |          The type names of the edges. The allowed type name formats are:\n",
      " |      \n",
      " |          * ``(str, str, str)`` for source node type, edge type and destination node type.\n",
      " |          * or one ``str`` edge type name if the name can uniquely identify a\n",
      " |            triplet format in the graph.\n",
      " |      \n",
      " |          Can be omitted if the graph has only one type of edges.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Tensor or (Tensor, Tensor) or (Tensor, Tensor, Tensor)\n",
      " |          All outgoing edges of the nodes with the specified type. For a description of the\n",
      " |          returned result, see the description of :attr:`form`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      Create a homogeneous graph.\n",
      " |      \n",
      " |      >>> g = dgl.graph((torch.tensor([0, 0, 1, 1]), torch.tensor([1, 0, 2, 3])))\n",
      " |      \n",
      " |      Query for the nodes 1 and 2.\n",
      " |      \n",
      " |      >>> g.out_edges(torch.tensor([1, 2]))\n",
      " |      (tensor([1, 1]), tensor([2, 3]))\n",
      " |      \n",
      " |      Specify a different value for :attr:`form`.\n",
      " |      \n",
      " |      >>> g.out_edges(torch.tensor([1, 2]), form='all')\n",
      " |      (tensor([1, 1]), tensor([2, 3]), tensor([2, 3]))\n",
      " |      \n",
      " |      For a graph of multiple edge types, it is required to specify the edge type in query.\n",
      " |      \n",
      " |      >>> hg = dgl.heterograph({\n",
      " |      ...     ('user', 'follows', 'user'): (torch.tensor([0, 1]), torch.tensor([1, 2])),\n",
      " |      ...     ('user', 'plays', 'game'): (torch.tensor([3, 4]), torch.tensor([5, 6]))\n",
      " |      ... })\n",
      " |      >>> hg.out_edges(torch.tensor([1, 2]), etype='follows')\n",
      " |      (tensor([1]), tensor([2]))\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      edges\n",
      " |      in_edges\n",
      " |  \n",
      " |  out_subgraph(graph, nodes, *, relabel_nodes=False, store_ids=True, output_device=None)\n",
      " |      Alias of :func:`dgl.out_subgraph`.\n",
      " |  \n",
      " |  pin_memory_(self)\n",
      " |      Pin the graph structure and node/edge data to the page-locked memory for\n",
      " |      GPU zero-copy access.\n",
      " |      \n",
      " |      This is an **inplace** method. The graph structure must be on CPU to be pinned.\n",
      " |      If the graph struture is already pinned, the function directly returns it.\n",
      " |      \n",
      " |      Materialization of new sparse formats for pinned graphs is not allowed.\n",
      " |      To avoid implicit formats materialization during training,\n",
      " |      you should create all the needed formats before pinning.\n",
      " |      But cloning and materialization is fine. See the examples below.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DGLGraph\n",
      " |          The pinned graph.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      >>> g = dgl.graph((torch.tensor([1, 0]), torch.tensor([1, 2])))\n",
      " |      >>> g.pin_memory_()\n",
      " |      \n",
      " |      Materialization of new sparse formats is not allowed for pinned graphs.\n",
      " |      \n",
      " |      >>> g.create_formats_()  # This would raise an error! You should do this before pinning.\n",
      " |      \n",
      " |      Cloning and materializing new formats is allowed. The returned graph is **not** pinned.\n",
      " |      \n",
      " |      >>> g1 = g.formats(['csc'])\n",
      " |      >>> assert not g1.is_pinned()\n",
      " |      \n",
      " |      The pinned graph can be access from both CPU and GPU. The concrete device depends\n",
      " |      on the context of ``query``. For example, ``eid`` in ``find_edges()`` is a query.\n",
      " |      When ``eid`` is on CPU, ``find_edges()`` is executed on CPU, and the returned\n",
      " |      values are CPU tensors\n",
      " |      \n",
      " |      >>> g.unpin_memory_()\n",
      " |      >>> g.create_formats_()\n",
      " |      >>> g.pin_memory_()\n",
      " |      >>> eid = torch.tensor([1])\n",
      " |      >>> g.find_edges(eids)\n",
      " |      (tensor([0]), tensor([2]))\n",
      " |      \n",
      " |      Moving ``eid`` to GPU, ``find_edges()`` will be executed on GPU, and the returned\n",
      " |      values are GPU tensors.\n",
      " |      \n",
      " |      >>> eid = eid.to('cuda:0')\n",
      " |      >>> g.find_edges(eids)\n",
      " |      (tensor([0], device='cuda:0'), tensor([2], device='cuda:0'))\n",
      " |      \n",
      " |      If you don't provide a ``query``, methods will be executed on CPU by default.\n",
      " |      \n",
      " |      >>> g.in_degrees()\n",
      " |      tensor([0, 1, 1])\n",
      " |  \n",
      " |  predecessors(self, v, etype=None)\n",
      " |      Return the predecessor(s) of a particular node with the specified edge type.\n",
      " |      \n",
      " |      Node ``u`` is a predecessor of node ``v`` if there is an edge ``(u, v)`` with type\n",
      " |      ``etype`` in the graph.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      v : int\n",
      " |          The node ID. If the graph has multiple edge types, the ID is for the destination\n",
      " |          type corresponding to the edge type.\n",
      " |      etype : str or (str, str, str), optional\n",
      " |          The type names of the edges. The allowed type name formats are:\n",
      " |      \n",
      " |          * ``(str, str, str)`` for source node type, edge type and destination node type.\n",
      " |          * or one ``str`` edge type name if the name can uniquely identify a\n",
      " |            triplet format in the graph.\n",
      " |      \n",
      " |          Can be omitted if the graph has only one type of edges.\n",
      " |      \n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Tensor\n",
      " |          The predecessors of :attr:`v` with the specified edge type.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      Create a homogeneous graph.\n",
      " |      \n",
      " |      >>> g = dgl.graph((torch.tensor([0, 0, 1, 1]), torch.tensor([1, 1, 2, 3])))\n",
      " |      \n",
      " |      Query for node 1.\n",
      " |      \n",
      " |      >>> g.predecessors(1)\n",
      " |      tensor([0, 0])\n",
      " |      \n",
      " |      For a graph of multiple edge types, it is required to specify the edge type in query.\n",
      " |      \n",
      " |      >>> hg = dgl.heterograph({\n",
      " |      ...     ('user', 'follows', 'user'): (torch.tensor([0, 1]), torch.tensor([1, 2])),\n",
      " |      ...     ('user', 'plays', 'game'): (torch.tensor([3, 4]), torch.tensor([5, 6]))\n",
      " |      ... })\n",
      " |      >>> hg.predecessors(1, etype='follows')\n",
      " |      tensor([0])\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      successors\n",
      " |  \n",
      " |  prop_edges(self, edges_generator, message_func, reduce_func, apply_node_func=None, etype=None)\n",
      " |      Propagate messages using graph traversal by sequentially triggering\n",
      " |      :func:`send_and_recv()` on edges.\n",
      " |      \n",
      " |      The traversal order is specified by the ``edges_generator``. It generates\n",
      " |      edge frontiers. The edge frontiers should be of *valid edges type*.\n",
      " |      See :func:`send` for more details.\n",
      " |      \n",
      " |      Edges in the same frontier will be triggered together, and edges in\n",
      " |      different frontiers will be triggered according to the generating order.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      edges_generator : generator\n",
      " |          The generator of edge frontiers.\n",
      " |      message_func : dgl.function.BuiltinFunction or callable\n",
      " |          The message function to generate messages along the edges.\n",
      " |          It must be either a :ref:`api-built-in` or a :ref:`apiudf`.\n",
      " |      reduce_func : dgl.function.BuiltinFunction or callable\n",
      " |          The reduce function to aggregate the messages.\n",
      " |          It must be either a :ref:`api-built-in` or a :ref:`apiudf`.\n",
      " |      apply_node_func : callable, optional\n",
      " |          An optional apply function to further update the node features\n",
      " |          after the message reduction. It must be a :ref:`apiudf`.\n",
      " |      etype : str or (str, str, str), optional\n",
      " |          The type name of the edges. The allowed type name formats are:\n",
      " |      \n",
      " |          * ``(str, str, str)`` for source node type, edge type and destination node type.\n",
      " |          * or one ``str`` edge type name if the name can uniquely identify a\n",
      " |            triplet format in the graph.\n",
      " |      \n",
      " |          Can be omitted if the graph has only one type of edges.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> import torch\n",
      " |      >>> import dgl\n",
      " |      >>> import dgl.function as fn\n",
      " |      \n",
      " |      Instantiate a heterogrph and perform multiple rounds of message passing.\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({('user', 'follows', 'user'): ([0, 1, 2, 3], [2, 3, 4, 4])})\n",
      " |      >>> g.nodes['user'].data['h'] = torch.tensor([[1.], [2.], [3.], [4.], [5.]])\n",
      " |      >>> g['follows'].prop_edges([[0, 1], [2, 3]], fn.copy_src('h', 'm'),\n",
      " |      ...                         fn.sum('m', 'h'), etype='follows')\n",
      " |      >>> g.nodes['user'].data['h']\n",
      " |      tensor([[1.],\n",
      " |              [2.],\n",
      " |              [1.],\n",
      " |              [2.],\n",
      " |              [3.]])\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      prop_nodes\n",
      " |  \n",
      " |  prop_nodes(self, nodes_generator, message_func, reduce_func, apply_node_func=None, etype=None)\n",
      " |      Propagate messages using graph traversal by sequentially triggering\n",
      " |      :func:`pull()` on nodes.\n",
      " |      \n",
      " |      The traversal order is specified by the ``nodes_generator``. It generates\n",
      " |      node frontiers, which is a list or a tensor of nodes. The nodes in the\n",
      " |      same frontier will be triggered together, while nodes in different frontiers\n",
      " |      will be triggered according to the generating order.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      nodes_generator : iterable[node IDs]\n",
      " |          The generator of node frontiers. Each frontier is a set of node IDs\n",
      " |          stored in Tensor or python iterables.\n",
      " |          It specifies which nodes perform :func:`pull` at each step.\n",
      " |      message_func : dgl.function.BuiltinFunction or callable\n",
      " |          The message function to generate messages along the edges.\n",
      " |          It must be either a :ref:`api-built-in` or a :ref:`apiudf`.\n",
      " |      reduce_func : dgl.function.BuiltinFunction or callable\n",
      " |          The reduce function to aggregate the messages.\n",
      " |          It must be either a :ref:`api-built-in` or a :ref:`apiudf`.\n",
      " |      apply_node_func : callable, optional\n",
      " |          An optional apply function to further update the node features\n",
      " |          after the message reduction. It must be a :ref:`apiudf`.\n",
      " |      etype : str or (str, str, str), optional\n",
      " |          The type name of the edges. The allowed type name formats are:\n",
      " |      \n",
      " |          * ``(str, str, str)`` for source node type, edge type and destination node type.\n",
      " |          * or one ``str`` edge type name if the name can uniquely identify a\n",
      " |            triplet format in the graph.\n",
      " |      \n",
      " |          Can be omitted if the graph has only one type of edges.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> import torch\n",
      " |      >>> import dgl\n",
      " |      >>> import dgl.function as fn\n",
      " |      \n",
      " |      Instantiate a heterogrph and perform multiple rounds of message passing.\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({('user', 'follows', 'user'): ([0, 1, 2, 3], [2, 3, 4, 4])})\n",
      " |      >>> g.nodes['user'].data['h'] = torch.tensor([[1.], [2.], [3.], [4.], [5.]])\n",
      " |      >>> g['follows'].prop_nodes([[2, 3], [4]], fn.copy_src('h', 'm'),\n",
      " |      ...                         fn.sum('m', 'h'), etype='follows')\n",
      " |      tensor([[1.],\n",
      " |              [2.],\n",
      " |              [1.],\n",
      " |              [2.],\n",
      " |              [3.]])\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      prop_edges\n",
      " |  \n",
      " |  pull(self, v, message_func, reduce_func, apply_node_func=None, etype=None, inplace=False)\n",
      " |      Pull messages from the specified node(s)' predecessors along the\n",
      " |      specified edge type, aggregate them to update the node features.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      v : node IDs\n",
      " |          The node IDs. The allowed formats are:\n",
      " |      \n",
      " |          * ``int``: A single node.\n",
      " |          * Int Tensor: Each element is a node ID. The tensor must have the same device type\n",
      " |            and ID data type as the graph's.\n",
      " |          * iterable[int]: Each element is a node ID.\n",
      " |      \n",
      " |      message_func : dgl.function.BuiltinFunction or callable\n",
      " |          The message function to generate messages along the edges.\n",
      " |          It must be either a :ref:`api-built-in` or a :ref:`apiudf`.\n",
      " |      reduce_func : dgl.function.BuiltinFunction or callable\n",
      " |          The reduce function to aggregate the messages.\n",
      " |          It must be either a :ref:`api-built-in` or a :ref:`apiudf`.\n",
      " |      apply_node_func : callable, optional\n",
      " |          An optional apply function to further update the node features\n",
      " |          after the message reduction. It must be a :ref:`apiudf`.\n",
      " |      etype : str or (str, str, str), optional\n",
      " |          The type name of the edges. The allowed type name formats are:\n",
      " |      \n",
      " |          * ``(str, str, str)`` for source node type, edge type and destination node type.\n",
      " |          * or one ``str`` edge type name if the name can uniquely identify a\n",
      " |            triplet format in the graph.\n",
      " |      \n",
      " |          Can be omitted if the graph has only one type of edges.\n",
      " |      \n",
      " |      inplace: bool, optional\n",
      " |          **DEPRECATED**.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      * If some of the given nodes :attr:`v` has no in-edges, DGL does not invoke\n",
      " |        message and reduce functions for these nodes and fill their aggregated messages\n",
      " |        with zero. Users can control the filled values via :meth:`set_n_initializer`.\n",
      " |        DGL still invokes :attr:`apply_node_func` if provided.\n",
      " |      * DGL recommends using DGL's bulit-in function for the :attr:`message_func`\n",
      " |        and the :attr:`reduce_func` arguments,\n",
      " |        because DGL will invoke efficient kernels that avoids copying node features to\n",
      " |        edge features in this case.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import dgl.function as fn\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      **Homogeneous graph**\n",
      " |      \n",
      " |      >>> g = dgl.graph(([0, 1, 2, 3], [1, 2, 3, 4]))\n",
      " |      >>> g.ndata['x'] = torch.ones(5, 2)\n",
      " |      >>> g.pull([0, 3, 4], fn.copy_u('x', 'm'), fn.sum('m', 'h'))\n",
      " |      >>> g.ndata['h']\n",
      " |      tensor([[0., 0.],\n",
      " |              [0., 0.],\n",
      " |              [0., 0.],\n",
      " |              [1., 1.],\n",
      " |              [1., 1.]])\n",
      " |      \n",
      " |      **Heterogeneous graph**\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({\n",
      " |      ...     ('user', 'follows', 'user'): ([0, 1], [1, 2]),\n",
      " |      ...     ('user', 'plays', 'game'): ([0, 2], [0, 1])\n",
      " |      ... })\n",
      " |      >>> g.nodes['user'].data['h'] = torch.tensor([[0.], [1.], [2.]])\n",
      " |      \n",
      " |      Pull.\n",
      " |      \n",
      " |      >>> g['follows'].pull(2, fn.copy_src('h', 'm'), fn.sum('m', 'h'), etype='follows')\n",
      " |      >>> g.nodes['user'].data['h']\n",
      " |      tensor([[0.],\n",
      " |              [1.],\n",
      " |              [1.]])\n",
      " |  \n",
      " |  push(self, u, message_func, reduce_func, apply_node_func=None, etype=None, inplace=False)\n",
      " |      Send message from the specified node(s) to their successors\n",
      " |      along the specified edge type and update their node features.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      v : node IDs\n",
      " |          The node IDs. The allowed formats are:\n",
      " |      \n",
      " |          * ``int``: A single node.\n",
      " |          * Int Tensor: Each element is a node ID. The tensor must have the same device type\n",
      " |            and ID data type as the graph's.\n",
      " |          * iterable[int]: Each element is a node ID.\n",
      " |      \n",
      " |      message_func : dgl.function.BuiltinFunction or callable\n",
      " |          The message function to generate messages along the edges.\n",
      " |          It must be either a :ref:`api-built-in` or a :ref:`apiudf`.\n",
      " |      reduce_func : dgl.function.BuiltinFunction or callable\n",
      " |          The reduce function to aggregate the messages.\n",
      " |          It must be either a :ref:`api-built-in` or a :ref:`apiudf`.\n",
      " |      apply_node_func : callable, optional\n",
      " |          An optional apply function to further update the node features\n",
      " |          after the message reduction. It must be a :ref:`apiudf`.\n",
      " |      etype : str or (str, str, str), optional\n",
      " |          The type name of the edges. The allowed type name formats are:\n",
      " |      \n",
      " |          * ``(str, str, str)`` for source node type, edge type and destination node type.\n",
      " |          * or one ``str`` edge type name if the name can uniquely identify a\n",
      " |            triplet format in the graph.\n",
      " |      \n",
      " |          Can be omitted if the graph has only one type of edges.\n",
      " |      \n",
      " |      inplace: bool, optional\n",
      " |          **DEPRECATED**.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      DGL recommends using DGL's bulit-in function for the :attr:`message_func`\n",
      " |      and the :attr:`reduce_func` arguments,\n",
      " |      because DGL will invoke efficient kernels that avoids copying node features to\n",
      " |      edge features in this case.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import dgl.function as fn\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      **Homogeneous graph**\n",
      " |      \n",
      " |      >>> g = dgl.graph(([0, 1, 2, 3], [1, 2, 3, 4]))\n",
      " |      >>> g.ndata['x'] = torch.ones(5, 2)\n",
      " |      >>> g.push([0, 1], fn.copy_u('x', 'm'), fn.sum('m', 'h'))\n",
      " |      >>> g.ndata['h']\n",
      " |      tensor([[0., 0.],\n",
      " |              [1., 1.],\n",
      " |              [1., 1.],\n",
      " |              [0., 0.],\n",
      " |              [0., 0.]])\n",
      " |      \n",
      " |      **Heterogeneous graph**\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({('user', 'follows', 'user'): ([0, 0], [1, 2])})\n",
      " |      >>> g.nodes['user'].data['h'] = torch.tensor([[0.], [1.], [2.]])\n",
      " |      \n",
      " |      Push.\n",
      " |      \n",
      " |      >>> g['follows'].push(0, fn.copy_src('h', 'm'), fn.sum('m', 'h'), etype='follows')\n",
      " |      >>> g.nodes['user'].data['h']\n",
      " |      tensor([[0.],\n",
      " |              [0.],\n",
      " |              [0.]])\n",
      " |  \n",
      " |  readonly(self, readonly_state=True)\n",
      " |      Deprecated: DGLGraph will always be mutable.\n",
      " |  \n",
      " |  record_stream(self, stream)\n",
      " |      Record the stream that is using this graph.\n",
      " |      This method only supports the PyTorch backend and requires graphs on the GPU.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      stream : torch.cuda.Stream\n",
      " |          The stream that is using this graph.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DGLGraph\n",
      " |          self.\n",
      " |  \n",
      " |  recv(self, v, reduce_func, apply_node_func=None, etype=None, inplace=False)\n",
      " |      Receive and reduce incoming messages and update the features of node(s) :math:`v`.\n",
      " |      \n",
      " |      DEPRECATE: please use send_and_recv, update_all.\n",
      " |  \n",
      " |  register_apply_edge_func(self, func)\n",
      " |      Deprecated: please directly call :func:`apply_edges` with ``func``\n",
      " |      as argument.\n",
      " |  \n",
      " |  register_apply_node_func(self, func)\n",
      " |      Deprecated: please directly call :func:`apply_nodes` with ``func``\n",
      " |      as argument.\n",
      " |  \n",
      " |  register_message_func(self, func)\n",
      " |      Deprecated: please directly call :func:`update_all` with ``func``\n",
      " |      as argument.\n",
      " |  \n",
      " |  register_reduce_func(self, func)\n",
      " |      Deprecated: please directly call :func:`update_all` with ``func``\n",
      " |      as argument.\n",
      " |  \n",
      " |  remove_edges(self, eids, etype=None, store_ids=False)\n",
      " |      Remove multiple edges with the specified edge type\n",
      " |      \n",
      " |      Nodes will not be removed. After removing edges, the rest\n",
      " |      edges will be re-indexed using consecutive integers from 0,\n",
      " |      with their relative order preserved.\n",
      " |      \n",
      " |      The features for the removed edges will be removed accordingly.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      eids : int, tensor, numpy.ndarray, list\n",
      " |          IDs for the edges to remove.\n",
      " |      etype : str or tuple of str, optional\n",
      " |          The type of the edges to remove. Can be omitted if there is\n",
      " |          only one edge type in the graph.\n",
      " |      store_ids : bool, optional\n",
      " |          If True, it will store the raw IDs of the extracted nodes and edges in the ``ndata``\n",
      " |          and ``edata`` of the resulting graph under name ``dgl.NID`` and ``dgl.EID``,\n",
      " |          respectively.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This function preserves the batch information.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      **Homogeneous Graphs or Heterogeneous Graphs with A Single Edge Type**\n",
      " |      \n",
      " |      >>> g = dgl.graph((torch.tensor([0, 0, 2]), torch.tensor([0, 1, 2])))\n",
      " |      >>> g.edata['he'] = torch.arange(3).float().reshape(-1, 1)\n",
      " |      >>> g.remove_edges(torch.tensor([0, 1]))\n",
      " |      >>> g\n",
      " |      Graph(num_nodes=3, num_edges=1,\n",
      " |          ndata_schemes={}\n",
      " |          edata_schemes={'he': Scheme(shape=(1,), dtype=torch.float32)})\n",
      " |      >>> g.edges('all')\n",
      " |      (tensor([2]), tensor([2]), tensor([0]))\n",
      " |      >>> g.edata['he']\n",
      " |      tensor([[2.]])\n",
      " |      \n",
      " |      Removing edges from a batched graph preserves batch information.\n",
      " |      \n",
      " |      >>> g = dgl.graph((torch.tensor([0, 0, 2]), torch.tensor([0, 1, 2])))\n",
      " |      >>> g2 = dgl.graph((torch.tensor([1, 2, 3]), torch.tensor([1, 3, 4])))\n",
      " |      >>> bg = dgl.batch([g, g2])\n",
      " |      >>> bg.batch_num_edges()\n",
      " |      tensor([3, 3])\n",
      " |      >>> bg.remove_edges([1, 4])\n",
      " |      >>> bg.batch_num_edges()\n",
      " |      tensor([2, 2])\n",
      " |      \n",
      " |      **Heterogeneous Graphs with Multiple Edge Types**\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({\n",
      " |      ...     ('user', 'plays', 'game'): (torch.tensor([0, 1, 1, 2]),\n",
      " |      ...                                 torch.tensor([0, 0, 1, 1])),\n",
      " |      ...     ('developer', 'develops', 'game'): (torch.tensor([0, 1]),\n",
      " |      ...                                         torch.tensor([0, 1]))\n",
      " |      ...     })\n",
      " |      >>> g.remove_edges(torch.tensor([0, 1]))\n",
      " |      DGLError: Edge type name must be specified\n",
      " |      if there are more than one edge types.\n",
      " |      >>> g.remove_edges(torch.tensor([0, 1]), 'plays')\n",
      " |      >>> g.edges('all', etype='plays')\n",
      " |      (tensor([0, 1]), tensor([0, 0]), tensor([0, 1]))\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      add_nodes\n",
      " |      add_edges\n",
      " |      remove_nodes\n",
      " |  \n",
      " |  remove_nodes(self, nids, ntype=None, store_ids=False)\n",
      " |      Remove multiple nodes with the specified node type\n",
      " |      \n",
      " |      Edges that connect to the nodes will be removed as well. After removing\n",
      " |      nodes and edges, the rest nodes and edges will be re-indexed using\n",
      " |      consecutive integers from 0, with their relative order preserved.\n",
      " |      \n",
      " |      The features for the removed nodes/edges will be removed accordingly.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      nids : int, tensor, numpy.ndarray, list\n",
      " |          Nodes to remove.\n",
      " |      ntype : str, optional\n",
      " |          The type of the nodes to remove. Can be omitted if there is\n",
      " |          only one node type in the graph.\n",
      " |      store_ids : bool, optional\n",
      " |          If True, it will store the raw IDs of the extracted nodes and edges in the ``ndata``\n",
      " |          and ``edata`` of the resulting graph under name ``dgl.NID`` and ``dgl.EID``,\n",
      " |          respectively.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This function preserves the batch information.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      **Homogeneous Graphs or Heterogeneous Graphs with A Single Node Type**\n",
      " |      \n",
      " |      >>> g = dgl.graph((torch.tensor([0, 0, 2]), torch.tensor([0, 1, 2])))\n",
      " |      >>> g.ndata['hv'] = torch.arange(3).float().reshape(-1, 1)\n",
      " |      >>> g.edata['he'] = torch.arange(3).float().reshape(-1, 1)\n",
      " |      >>> g.remove_nodes(torch.tensor([0, 1]))\n",
      " |      >>> g\n",
      " |      Graph(num_nodes=1, num_edges=1,\n",
      " |          ndata_schemes={'hv': Scheme(shape=(1,), dtype=torch.float32)}\n",
      " |          edata_schemes={'he': Scheme(shape=(1,), dtype=torch.float32)})\n",
      " |      >>> g.ndata['hv']\n",
      " |      tensor([[2.]])\n",
      " |      >>> g.edata['he']\n",
      " |      tensor([[2.]])\n",
      " |      \n",
      " |      Removing nodes from a batched graph preserves batch information.\n",
      " |      \n",
      " |      >>> g = dgl.graph((torch.tensor([0, 0, 2]), torch.tensor([0, 1, 2])))\n",
      " |      >>> g2 = dgl.graph((torch.tensor([1, 2, 3]), torch.tensor([1, 3, 4])))\n",
      " |      >>> bg = dgl.batch([g, g2])\n",
      " |      >>> bg.batch_num_nodes()\n",
      " |      tensor([3, 5])\n",
      " |      >>> bg.remove_nodes([1, 4])\n",
      " |      >>> bg.batch_num_nodes()\n",
      " |      tensor([2, 4])\n",
      " |      >>> bg.batch_num_edges()\n",
      " |      tensor([2, 2])\n",
      " |      \n",
      " |      **Heterogeneous Graphs with Multiple Node Types**\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({\n",
      " |      ...     ('user', 'plays', 'game'): (torch.tensor([0, 1, 1, 2]),\n",
      " |      ...                                 torch.tensor([0, 0, 1, 1])),\n",
      " |      ...     ('developer', 'develops', 'game'): (torch.tensor([0, 1]),\n",
      " |      ...                                         torch.tensor([0, 1]))\n",
      " |      ...     })\n",
      " |      >>> g.remove_nodes(torch.tensor([0, 1]))\n",
      " |      DGLError: Node type name must be specified\n",
      " |      if there are more than one node types.\n",
      " |      >>> g.remove_nodes(torch.tensor([0, 1]), ntype='game')\n",
      " |      >>> g.num_nodes('user')\n",
      " |      3\n",
      " |      >>> g.num_nodes('game')\n",
      " |      0\n",
      " |      >>> g.num_edges('plays')\n",
      " |      0\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      add_nodes\n",
      " |      add_edges\n",
      " |      remove_edges\n",
      " |  \n",
      " |  remove_self_loop(g, etype=None)\n",
      " |      Alias of :func:`dgl.remove_self_loop`.\n",
      " |  \n",
      " |  reorder_graph(g, node_permute_algo=None, edge_permute_algo='src', store_ids=True, permute_config=None)\n",
      " |      Alias of :func:`dgl.reorder_graph`.\n",
      " |  \n",
      " |  reverse(g, copy_ndata=True, copy_edata=False, *, share_ndata=None, share_edata=None)\n",
      " |      Alias of :func:`dgl.reverse`.\n",
      " |  \n",
      " |  sample_etype_neighbors(g, nodes, etype_field, fanout, edge_dir='in', prob=None, replace=False, copy_ndata=True, copy_edata=True, etype_sorted=False, _dist_training=False, output_device=None)\n",
      " |      Alias of :func:`dgl.sample_etype_neighbors`.\n",
      " |  \n",
      " |  sample_neighbors(g, nodes, fanout, edge_dir='in', prob=None, replace=False, copy_ndata=True, copy_edata=True, _dist_training=False, exclude_edges=None, output_device=None)\n",
      " |      Alias of :func:`dgl.sample_neighbors`.\n",
      " |  \n",
      " |  sample_neighbors_biased(g, nodes, fanout, bias, edge_dir='in', tag_offset_name='_TAG_OFFSET', replace=False, copy_ndata=True, copy_edata=True, output_device=None)\n",
      " |      Alias of :func:`dgl.sample_neighbors_biased`.\n",
      " |  \n",
      " |  select_topk(g, k, weight, nodes=None, edge_dir='in', ascending=False, copy_ndata=True, copy_edata=True, output_device=None)\n",
      " |      Alias of :func:`dgl.select_topk`.\n",
      " |  \n",
      " |  send(self, edges, message_func, etype=None)\n",
      " |      Send messages along the given edges with the same edge type.\n",
      " |      \n",
      " |      DEPRECATE: please use send_and_recv, update_all.\n",
      " |  \n",
      " |  send_and_recv(self, edges, message_func, reduce_func, apply_node_func=None, etype=None, inplace=False)\n",
      " |      Send messages along the specified edges and reduce them on\n",
      " |      the destination nodes to update their features.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      edges : edges\n",
      " |          The edges to send and receive messages on. The allowed input formats are:\n",
      " |      \n",
      " |          * ``int``: A single edge ID.\n",
      " |          * Int Tensor: Each element is an edge ID.  The tensor must have the same device type\n",
      " |            and ID data type as the graph's.\n",
      " |          * iterable[int]: Each element is an edge ID.\n",
      " |          * (Tensor, Tensor): The node-tensors format where the i-th elements\n",
      " |            of the two tensors specify an edge.\n",
      " |          * (iterable[int], iterable[int]): Similar to the node-tensors format but\n",
      " |            stores edge endpoints in python iterables.\n",
      " |      \n",
      " |      message_func : dgl.function.BuiltinFunction or callable\n",
      " |          The message function to generate messages along the edges.\n",
      " |          It must be either a :ref:`api-built-in` or a :ref:`apiudf`.\n",
      " |      reduce_func : dgl.function.BuiltinFunction or callable\n",
      " |          The reduce function to aggregate the messages.\n",
      " |          It must be either a :ref:`api-built-in` or a :ref:`apiudf`.\n",
      " |      apply_node_func : callable, optional\n",
      " |          An optional apply function to further update the node features\n",
      " |          after the message reduction. It must be a :ref:`apiudf`.\n",
      " |      etype : str or (str, str, str), optional\n",
      " |          The type name of the edges. The allowed type name formats are:\n",
      " |      \n",
      " |          * ``(str, str, str)`` for source node type, edge type and destination node type.\n",
      " |          * or one ``str`` edge type name if the name can uniquely identify a\n",
      " |            triplet format in the graph.\n",
      " |      \n",
      " |          Can be omitted if the graph has only one type of edges.\n",
      " |      \n",
      " |      inplace: bool, optional\n",
      " |          **DEPRECATED**.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      DGL recommends using DGL's bulit-in function for the :attr:`message_func`\n",
      " |      and the :attr:`reduce_func` arguments,\n",
      " |      because DGL will invoke efficient kernels that avoids copying node features to\n",
      " |      edge features in this case.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import dgl.function as fn\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      **Homogeneous graph**\n",
      " |      \n",
      " |      >>> g = dgl.graph(([0, 1, 2, 3], [1, 2, 3, 4]))\n",
      " |      >>> g.ndata['x'] = torch.ones(5, 2)\n",
      " |      >>> # Specify edges using (Tensor, Tensor).\n",
      " |      >>> g.send_and_recv(([1, 2], [2, 3]), fn.copy_u('x', 'm'), fn.sum('m', 'h'))\n",
      " |      >>> g.ndata['h']\n",
      " |      tensor([[0., 0.],\n",
      " |              [0., 0.],\n",
      " |              [1., 1.],\n",
      " |              [1., 1.],\n",
      " |              [0., 0.]])\n",
      " |      >>> # Specify edges using IDs.\n",
      " |      >>> g.send_and_recv([0, 2, 3], fn.copy_u('x', 'm'), fn.sum('m', 'h'))\n",
      " |      >>> g.ndata['h']\n",
      " |      tensor([[0., 0.],\n",
      " |              [1., 1.],\n",
      " |              [0., 0.],\n",
      " |              [1., 1.],\n",
      " |              [1., 1.]])\n",
      " |      \n",
      " |      **Heterogeneous graph**\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({\n",
      " |      ...     ('user', 'follows', 'user'): ([0, 1], [1, 2]),\n",
      " |      ...     ('user', 'plays', 'game'): ([0, 1, 1, 2], [0, 0, 1, 1])\n",
      " |      ... })\n",
      " |      >>> g.nodes['user'].data['h'] = torch.tensor([[0.], [1.], [2.]])\n",
      " |      >>> g.send_and_recv(g['follows'].edges(), fn.copy_src('h', 'm'),\n",
      " |      ...                 fn.sum('m', 'h'), etype='follows')\n",
      " |      >>> g.nodes['user'].data['h']\n",
      " |      tensor([[0.],\n",
      " |              [0.],\n",
      " |              [1.]])\n",
      " |      \n",
      " |      **``send_and_recv`` using user-defined functions**\n",
      " |      \n",
      " |      >>> import torch as th\n",
      " |      >>> g = dgl.graph(([0, 1], [1, 2]))\n",
      " |      >>> g.ndata['x'] = th.tensor([[1.], [2.], [3.]])\n",
      " |      \n",
      " |      >>> # Define the function for sending node features as messages.\n",
      " |      >>> def send_source(edges):\n",
      " |      ...     return {'m': edges.src['x']}\n",
      " |      >>> # Sum the messages received and use this to replace the original node feature.\n",
      " |      >>> def simple_reduce(nodes):\n",
      " |      ...     return {'x': nodes.mailbox['m'].sum(1)}\n",
      " |      \n",
      " |      Send and receive messages.\n",
      " |      \n",
      " |      >>> g.send_and_recv(g.edges())\n",
      " |      >>> g.ndata['x']\n",
      " |      tensor([[1.],\n",
      " |              [1.],\n",
      " |              [2.]])\n",
      " |      \n",
      " |      Note that the feature of node 0 remains the same as it has no incoming edges.\n",
      " |  \n",
      " |  set_batch_num_edges(self, val)\n",
      " |      Manually set the number of edges for each graph in the batch with the specified edge\n",
      " |      type.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      val : Tensor or Mapping[str, Tensor]\n",
      " |          The dictionary storing number of edges for each graph in the batch for all edge types.\n",
      " |          If the graph has only one edge type, ``val`` can also be a single array indicating the\n",
      " |          number of edges per graph in the batch.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This API is always used together with ``set_batch_num_nodes`` to specify batching\n",
      " |      information of a graph, it also do not check the correspondance between the graph structure\n",
      " |      and batching information and user must guarantee there will be no cross-graph edges in the\n",
      " |      batch.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      Create a homogeneous graph.\n",
      " |      \n",
      " |      >>> g = dgl.graph(([0, 1, 2, 3, 4, 5], [1, 2, 0, 4, 5, 3]))\n",
      " |      \n",
      " |      Manually set batch information\n",
      " |      \n",
      " |      >>> g.set_batch_num_nodes(torch.tensor([3, 3]))\n",
      " |      >>> g.set_batch_num_edges(torch.tensor([3, 3]))\n",
      " |      \n",
      " |      Unbatch the graph.\n",
      " |      \n",
      " |      >>> dgl.unbatch(g)\n",
      " |      [Graph(num_nodes=3, num_edges=3,\n",
      " |            ndata_schemes={}\n",
      " |            edata_schemes={}), Graph(num_nodes=3, num_edges=3,\n",
      " |            ndata_schemes={}\n",
      " |            edata_schemes={})]\n",
      " |      \n",
      " |      Create a heterogeneous graph.\n",
      " |      \n",
      " |      >>> hg = dgl.heterograph({\n",
      " |      ...      ('user', 'plays', 'game') : ([0, 1, 2, 3, 4, 5], [0, 1, 1, 3, 3, 2]),\n",
      " |      ...      ('developer', 'develops', 'game') : ([0, 1, 2, 3], [1, 0, 3, 2])})\n",
      " |      \n",
      " |      Manually set batch information.\n",
      " |      \n",
      " |      >>> hg.set_batch_num_nodes({\n",
      " |      ...     'user': torch.tensor([3, 3]),\n",
      " |      ...     'game': torch.tensor([2, 2]),\n",
      " |      ...     'developer': torch.tensor([2, 2])})\n",
      " |      >>> hg.set_batch_num_edges(\n",
      " |      ...     {('user', 'plays', 'game'): torch.tensor([3, 3]),\n",
      " |      ...     ('developer', 'develops', 'game'): torch.tensor([2, 2])})\n",
      " |      \n",
      " |      Unbatch the graph.\n",
      " |      \n",
      " |      >>> g1, g2 = dgl.unbatch(hg)\n",
      " |      >>> g1\n",
      " |      Graph(num_nodes={'developer': 2, 'game': 2, 'user': 3},\n",
      " |            num_edges={('developer', 'develops', 'game'): 2, ('user', 'plays', 'game'): 3},\n",
      " |            metagraph=[('developer', 'game', 'develops'), ('user', 'game', 'plays')])\n",
      " |      >>> g2\n",
      " |      Graph(num_nodes={'developer': 2, 'game': 2, 'user': 3},\n",
      " |            num_edges={('developer', 'develops', 'game'): 2, ('user', 'plays', 'game'): 3},\n",
      " |            metagraph=[('developer', 'game', 'develops'), ('user', 'game', 'plays')])\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      set_batch_num_nodes\n",
      " |      batch\n",
      " |      unbatch\n",
      " |  \n",
      " |  set_batch_num_nodes(self, val)\n",
      " |      Manually set the number of nodes for each graph in the batch with the specified node\n",
      " |      type.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      val : Tensor or Mapping[str, Tensor]\n",
      " |          The dictionary storing number of nodes for each graph in the batch for all node types.\n",
      " |          If the graph has only one node type, ``val`` can also be a single array indicating the\n",
      " |          number of nodes per graph in the batch.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This API is always used together with ``set_batch_num_edges`` to specify batching\n",
      " |      information of a graph, it also do not check the correspondance between the graph structure\n",
      " |      and batching information and user must guarantee there will be no cross-graph edges in the\n",
      " |      batch.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      Create a homogeneous graph.\n",
      " |      \n",
      " |      >>> g = dgl.graph(([0, 1, 2, 3, 4, 5], [1, 2, 0, 4, 5, 3]))\n",
      " |      \n",
      " |      Manually set batch information\n",
      " |      \n",
      " |      >>> g.set_batch_num_nodes(torch.tensor([3, 3]))\n",
      " |      >>> g.set_batch_num_edges(torch.tensor([3, 3]))\n",
      " |      \n",
      " |      Unbatch the graph.\n",
      " |      \n",
      " |      >>> dgl.unbatch(g)\n",
      " |      [Graph(num_nodes=3, num_edges=3,\n",
      " |            ndata_schemes={}\n",
      " |            edata_schemes={}), Graph(num_nodes=3, num_edges=3,\n",
      " |            ndata_schemes={}\n",
      " |            edata_schemes={})]\n",
      " |      \n",
      " |      Create a heterogeneous graph.\n",
      " |      \n",
      " |      >>> hg = dgl.heterograph({\n",
      " |      ...      ('user', 'plays', 'game') : ([0, 1, 2, 3, 4, 5], [0, 1, 1, 3, 3, 2]),\n",
      " |      ...      ('developer', 'develops', 'game') : ([0, 1, 2, 3], [1, 0, 3, 2])})\n",
      " |      \n",
      " |      Manually set batch information.\n",
      " |      \n",
      " |      >>> hg.set_batch_num_nodes({\n",
      " |      ...     'user': torch.tensor([3, 3]),\n",
      " |      ...     'game': torch.tensor([2, 2]),\n",
      " |      ...     'developer': torch.tensor([2, 2])})\n",
      " |      >>> hg.set_batch_num_edges({\n",
      " |      ...     ('user', 'plays', 'game'): torch.tensor([3, 3]),\n",
      " |      ...     ('developer', 'develops', 'game'): torch.tensor([2, 2])})\n",
      " |      \n",
      " |      Unbatch the graph.\n",
      " |      \n",
      " |      >>> g1, g2 = dgl.unbatch(hg)\n",
      " |      >>> g1\n",
      " |      Graph(num_nodes={'developer': 2, 'game': 2, 'user': 3},\n",
      " |            num_edges={('developer', 'develops', 'game'): 2, ('user', 'plays', 'game'): 3},\n",
      " |            metagraph=[('developer', 'game', 'develops'), ('user', 'game', 'plays')])\n",
      " |      >>> g2\n",
      " |      Graph(num_nodes={'developer': 2, 'game': 2, 'user': 3},\n",
      " |            num_edges={('developer', 'develops', 'game'): 2, ('user', 'plays', 'game'): 3},\n",
      " |            metagraph=[('developer', 'game', 'develops'), ('user', 'game', 'plays')])\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      set_batch_num_edges\n",
      " |      batch\n",
      " |      unbatch\n",
      " |  \n",
      " |  set_e_initializer(self, initializer, field=None, etype=None)\n",
      " |      Set the initializer for edge features.\n",
      " |      \n",
      " |      When only part of the edges have a feature (e.g. new edges are added,\n",
      " |      features are set for a subset of edges), the initializer initializes\n",
      " |      features for the rest edges.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      initializer : callable\n",
      " |          A function of signature ``func(shape, dtype, ctx, id_range) -> Tensor``.\n",
      " |          The tensor will be the initialized features. The arguments are:\n",
      " |      \n",
      " |          - ``shape``: The shape of the tensor to return, which is a tuple of int.\n",
      " |            The first dimension is the number of edges for feature initialization.\n",
      " |          - ``dtype``: The data type of the tensor to return, which is a\n",
      " |            framework-specific data type object.\n",
      " |          - ``ctx``: The device of the tensor to return, which is a framework-specific\n",
      " |            device object.\n",
      " |          - ``id_range``: The start and end ID of the edges for feature initialization,\n",
      " |            which is a slice.\n",
      " |      field : str, optional\n",
      " |          The name of the feature that the initializer applies. If not given, the\n",
      " |          initializer applies to all features.\n",
      " |      etype : str or (str, str, str), optional\n",
      " |          The type names of the edges. The allowed type name formats are:\n",
      " |      \n",
      " |          * ``(str, str, str)`` for source node type, edge type and destination node type.\n",
      " |          * or one ``str`` edge type name if the name can uniquely identify a\n",
      " |            triplet format in the graph.\n",
      " |      \n",
      " |          Can be omitted if the graph has only one type of edges.\n",
      " |      \n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Without setting an edge feature initializer, zero tensors are generated\n",
      " |      for edges without a feature.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      Define a function for initializer.\n",
      " |      \n",
      " |      >>> def init_feats(shape, dtype, device, id_range):\n",
      " |      ...     return torch.ones(shape, dtype=dtype, device=device)\n",
      " |      \n",
      " |      An example for a homogeneous graph.\n",
      " |      \n",
      " |      >>> g = dgl.graph((torch.tensor([0]), torch.tensor([1])))\n",
      " |      >>> g.edata['h1'] = torch.zeros(1, 2)\n",
      " |      >>> g.edata['h2'] = torch.ones(1, 1)\n",
      " |      >>> # Apply the initializer to feature 'h2' only.\n",
      " |      >>> g.set_e_initializer(init_feats, field='h2')\n",
      " |      >>> g.add_edges(torch.tensor([1]), torch.tensor([1]))\n",
      " |      >>> print(g.edata['h1'])\n",
      " |      tensor([[0., 0.],\n",
      " |              [0., 0.]])\n",
      " |      >>> print(g.edata['h2'])\n",
      " |      tensor([[1.], [1.]])\n",
      " |      \n",
      " |      An example for a heterogeneous graph of multiple edge types.\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({\n",
      " |      ...     ('user', 'plays', 'game'): (torch.tensor([0, 1]),\n",
      " |      ...                                 torch.tensor([0, 0])),\n",
      " |      ...     ('developer', 'develops', 'game'): (torch.tensor([0, 1]),\n",
      " |      ...                                         torch.tensor([0, 1]))\n",
      " |      ...     })\n",
      " |      >>> g.edges['plays'].data['h'] = torch.zeros(2, 2)\n",
      " |      >>> g.edges['develops'].data['w'] = torch.ones(2, 2)\n",
      " |      >>> g.set_e_initializer(init_feats, etype='plays')\n",
      " |      >>> # Initializer not set for 'develops', use zero tensors by default\n",
      " |      >>> g.add_edges(torch.tensor([1]), torch.tensor([1]), etype='develops')\n",
      " |      >>> g.edges['develops'].data['w']\n",
      " |      tensor([[1., 1.],\n",
      " |              [1., 1.],\n",
      " |              [0., 0.]])\n",
      " |      >>> # Initializer set for 'plays'\n",
      " |      >>> g.add_edges(torch.tensor([1]), torch.tensor([1]), etype='plays')\n",
      " |      >>> g.edges['plays'].data['h']\n",
      " |      tensor([[0., 0.],\n",
      " |              [0., 0.],\n",
      " |              [1., 1.]])\n",
      " |  \n",
      " |  set_n_initializer(self, initializer, field=None, ntype=None)\n",
      " |      Set the initializer for node features.\n",
      " |      \n",
      " |      When only part of the nodes have a feature (e.g. new nodes are added,\n",
      " |      features are set for a subset of nodes), the initializer initializes\n",
      " |      features for the rest nodes.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      initializer : callable\n",
      " |          A function of signature ``func(shape, dtype, ctx, id_range) -> Tensor``.\n",
      " |          The tensor will be the initialized features. The arguments are:\n",
      " |      \n",
      " |          - ``shape``: The shape of the tensor to return, which is a tuple of int.\n",
      " |            The first dimension is the number of nodes for feature initialization.\n",
      " |          - ``dtype``: The data type of the tensor to return, which is a\n",
      " |            framework-specific data type object.\n",
      " |          - ``ctx``: The device of the tensor to return, which is a framework-specific\n",
      " |            device object.\n",
      " |          - ``id_range``: The start and end ID of the nodes for feature initialization,\n",
      " |            which is a slice.\n",
      " |      field : str, optional\n",
      " |          The name of the feature that the initializer applies. If not given, the\n",
      " |          initializer applies to all features.\n",
      " |      ntype : str, optional\n",
      " |          The type name of the nodes. Can be omitted if the graph has only one type of nodes.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Without setting a node feature initializer, zero tensors are generated\n",
      " |      for nodes without a feature.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      Define a function for initializer.\n",
      " |      \n",
      " |      >>> def init_feats(shape, dtype, device, id_range):\n",
      " |      ...     return torch.ones(shape, dtype=dtype, device=device)\n",
      " |      \n",
      " |      An example for a homogeneous graph.\n",
      " |      \n",
      " |      >>> g = dgl.graph((torch.tensor([0]), torch.tensor([1])))\n",
      " |      >>> g.ndata['h1'] = torch.zeros(2, 2)\n",
      " |      >>> g.ndata['h2'] = torch.ones(2, 1)\n",
      " |      >>> # Apply the initializer to feature 'h2' only.\n",
      " |      >>> g.set_n_initializer(init_feats, field='h2')\n",
      " |      >>> g.add_nodes(1)\n",
      " |      >>> print(g.ndata['h1'])\n",
      " |      tensor([[0., 0.],\n",
      " |              [0., 0.],\n",
      " |              [0., 0.]])\n",
      " |      >>> print(g.ndata['h2'])\n",
      " |      tensor([[1.], [1.], [1.]])\n",
      " |      \n",
      " |      An example for a heterogeneous graph of multiple node types.\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({\n",
      " |      ...     ('user', 'plays', 'game'): (torch.tensor([0, 1, 1, 2]),\n",
      " |      ...                                 torch.tensor([0, 0, 1, 1])),\n",
      " |      ...     ('developer', 'develops', 'game'): (torch.tensor([0, 1]),\n",
      " |      ...                                         torch.tensor([0, 1]))\n",
      " |      ...     })\n",
      " |      >>> g.nodes['user'].data['h'] = torch.zeros(3, 2)\n",
      " |      >>> g.nodes['game'].data['w'] = torch.ones(2, 2)\n",
      " |      >>> g.set_n_initializer(init_feats, ntype='game')\n",
      " |      >>> g.add_nodes(1, ntype='user')\n",
      " |      >>> # Initializer not set for 'user', use zero tensors by default\n",
      " |      >>> g.nodes['user'].data['h']\n",
      " |      tensor([[0., 0.],\n",
      " |              [0., 0.],\n",
      " |              [0., 0.],\n",
      " |              [0., 0.]])\n",
      " |      >>> # Initializer set for 'game'\n",
      " |      >>> g.add_nodes(1, ntype='game')\n",
      " |      >>> g.nodes['game'].data['w']\n",
      " |      tensor([[1., 1.],\n",
      " |              [1., 1.],\n",
      " |              [1., 1.]])\n",
      " |  \n",
      " |  shared_memory(self, name, formats=('coo', 'csr', 'csc'))\n",
      " |      Return a copy of this graph in shared memory, without node data or edge data.\n",
      " |      \n",
      " |      It moves the graph index to shared memory and returns a DGLHeterograph object which\n",
      " |      has the same graph structure, node types and edge types but does not contain node data\n",
      " |      or edge data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      name : str\n",
      " |          The name of the shared memory.\n",
      " |      formats : str or a list of str (optional)\n",
      " |          Desired formats to be materialized.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      HeteroGraph\n",
      " |          The graph in shared memory\n",
      " |  \n",
      " |  subgraph = node_subgraph(graph, nodes, *, relabel_nodes=True, store_ids=True, output_device=None)\n",
      " |      Alias of :func:`dgl.node_subgraph`.\n",
      " |  \n",
      " |  successors(self, v, etype=None)\n",
      " |      Return the successor(s) of a particular node with the specified edge type.\n",
      " |      \n",
      " |      Node ``u`` is a successor of node ``v`` if there is an edge ``(v, u)`` with type\n",
      " |      ``etype`` in the graph.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      v : int\n",
      " |          The node ID. If the graph has multiple edge types, the ID is for the source\n",
      " |          type corresponding to the edge type.\n",
      " |      etype : str or (str, str, str), optional\n",
      " |          The type names of the edges. The allowed type name formats are:\n",
      " |      \n",
      " |          * ``(str, str, str)`` for source node type, edge type and destination node type.\n",
      " |          * or one ``str`` edge type name if the name can uniquely identify a\n",
      " |            triplet format in the graph.\n",
      " |      \n",
      " |          Can be omitted if the graph has only one type of edges.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Tensor\n",
      " |          The successors of :attr:`v` with the specified edge type.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      Create a homogeneous graph.\n",
      " |      \n",
      " |      >>> g = dgl.graph((torch.tensor([0, 0, 1, 1]), torch.tensor([1, 1, 2, 3])))\n",
      " |      \n",
      " |      Query for node 1.\n",
      " |      \n",
      " |      >>> g.successors(1)\n",
      " |      tensor([2, 3])\n",
      " |      \n",
      " |      For a graph of multiple edge types, it is required to specify the edge type in query.\n",
      " |      \n",
      " |      >>> hg = dgl.heterograph({\n",
      " |      ...     ('user', 'follows', 'user'): (torch.tensor([0, 1]), torch.tensor([1, 2])),\n",
      " |      ...     ('user', 'plays', 'game'): (torch.tensor([3, 4]), torch.tensor([5, 6]))\n",
      " |      ... })\n",
      " |      >>> hg.successors(1, etype='follows')\n",
      " |      tensor([2])\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      predecessors\n",
      " |  \n",
      " |  to(self, device, **kwargs)\n",
      " |      Move ndata, edata and graph structure to the targeted device (cpu/gpu).\n",
      " |      \n",
      " |      If the graph is already on the specified device, the function directly returns it.\n",
      " |      Otherwise, it returns a cloned graph on the specified device.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      device : Framework-specific device context object\n",
      " |          The context to move data to (e.g., ``torch.device``).\n",
      " |      kwargs : Key-word arguments.\n",
      " |          Key-word arguments fed to the framework copy function.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DGLGraph\n",
      " |          The graph on the specified device.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      >>> g = dgl.graph((torch.tensor([1, 0]), torch.tensor([1, 2])))\n",
      " |      >>> g.ndata['h'] = torch.ones(3, 1)\n",
      " |      >>> g.edata['h'] = torch.zeros(2, 2)\n",
      " |      >>> g1 = g.to(torch.device('cuda:0'))\n",
      " |      >>> print(g1.device)\n",
      " |      device(type='cuda', index=0)\n",
      " |      >>> print(g1.ndata['h'].device)\n",
      " |      device(type='cuda', index=0)\n",
      " |      >>> print(g1.nodes().device)\n",
      " |      device(type='cuda', index=0)\n",
      " |      \n",
      " |      The original graph is still on CPU.\n",
      " |      \n",
      " |      >>> print(g.device)\n",
      " |      device(type='cpu')\n",
      " |      >>> print(g.ndata['h'].device)\n",
      " |      device(type='cpu')\n",
      " |      >>> print(g.nodes().device)\n",
      " |      device(type='cpu')\n",
      " |      \n",
      " |      The case of heterogeneous graphs is the same.\n",
      " |  \n",
      " |  to_canonical_etype(self, etype)\n",
      " |      Convert an edge type to the corresponding canonical edge type in the graph.\n",
      " |      \n",
      " |      A canonical edge type is a string triplet ``(str, str, str)``\n",
      " |      for source node type, edge type and destination node type.\n",
      " |      \n",
      " |      The function expects the given edge type name can uniquely identify a canonical edge\n",
      " |      type. DGL will raise error if this is not the case.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      etype : str or (str, str, str)\n",
      " |          If :attr:`etype` is an edge type (str), it returns the corresponding canonical edge\n",
      " |          type in the graph. If :attr:`etype` is already a canonical edge type,\n",
      " |          it directly returns the input unchanged.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      (str, str, str)\n",
      " |          The canonical edge type corresponding to the edge type.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      Create a heterograph.\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({\n",
      " |      ...     ('user', 'follows', 'user'): ([0, 1], [1, 2]),\n",
      " |      ...     ('user', 'plays', 'game'): ([0, 1, 1, 2], [0, 0, 1, 1]),\n",
      " |      ...     ('developer', 'follows', 'game'): ([0, 1], [0, 1])\n",
      " |      ... })\n",
      " |      \n",
      " |      Map an edge type to its corresponding canonical edge type.\n",
      " |      \n",
      " |      >>> g.to_canonical_etype('plays')\n",
      " |      ('user', 'plays', 'game')\n",
      " |      >>> g.to_canonical_etype(('user', 'plays', 'game'))\n",
      " |      ('user', 'plays', 'game')\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      canonical_etypes\n",
      " |  \n",
      " |  to_cugraph(g)\n",
      " |      Convert a DGL graph to a :class:`cugraph.Graph` and return.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      g : DGLGraph\n",
      " |          A homogeneous graph.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      cugraph.Graph\n",
      " |          The converted cugraph graph.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The function only supports GPU graph input.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import cugraph\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      >>> g = dgl.graph((torch.tensor([1, 2]), torch.tensor([1, 3]))).to('cuda')\n",
      " |      >>> cugraph_g = g.to_cugraph()\n",
      " |      >>> cugraph_g.edges()\n",
      " |          src  dst\n",
      " |      0    2    3\n",
      " |      1    1    1\n",
      " |  \n",
      " |  to_networkx(g, node_attrs=None, edge_attrs=None)\n",
      " |      Convert a homogeneous graph to a NetworkX graph and return.\n",
      " |      \n",
      " |      The resulting NetworkX graph also contains the node/edge features of the input graph.\n",
      " |      Additionally, DGL saves the edge IDs as the ``'id'`` edge attribute in the\n",
      " |      returned NetworkX graph.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      g : DGLGraph\n",
      " |          A homogeneous graph.\n",
      " |      node_attrs : iterable of str, optional\n",
      " |          The node attributes to copy from ``g.ndata``. (Default: None)\n",
      " |      edge_attrs : iterable of str, optional\n",
      " |          The edge attributes to copy from ``g.edata``. (Default: None)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      networkx.DiGraph\n",
      " |          The converted NetworkX graph.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The function only supports CPU graph input.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      >>> g = dgl.graph((torch.tensor([1, 2]), torch.tensor([1, 3])))\n",
      " |      >>> g.ndata['h'] = torch.zeros(4, 1)\n",
      " |      >>> g.edata['h1'] = torch.ones(2, 1)\n",
      " |      >>> g.edata['h2'] = torch.zeros(2, 2)\n",
      " |      >>> nx_g = dgl.to_networkx(g, node_attrs=['h'], edge_attrs=['h1', 'h2'])\n",
      " |      >>> nx_g.nodes(data=True)\n",
      " |      NodeDataView({0: {'h': tensor([0.])},\n",
      " |                    1: {'h': tensor([0.])},\n",
      " |                    2: {'h': tensor([0.])},\n",
      " |                    3: {'h': tensor([0.])}})\n",
      " |      >>> nx_g.edges(data=True)\n",
      " |      OutMultiEdgeDataView([(1, 1, {'id': 0, 'h1': tensor([1.]), 'h2': tensor([0., 0.])}),\n",
      " |                            (2, 3, {'id': 1, 'h1': tensor([1.]), 'h2': tensor([0., 0.])})])\n",
      " |  \n",
      " |  to_simple(g, return_counts='count', writeback_mapping=False, copy_ndata=True, copy_edata=False, aggregator='arbitrary')\n",
      " |      Alias of :func:`dgl.to_simple`.\n",
      " |  \n",
      " |  unpin_memory_(self)\n",
      " |      Unpin the graph structure and node/edge data from the page-locked memory.\n",
      " |      \n",
      " |      This is an **inplace** method. If the graph struture is not pinned,\n",
      " |      e.g., on CPU or GPU, the function directly returns it.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DGLGraph\n",
      " |          The unpinned graph.\n",
      " |  \n",
      " |  update_all(self, message_func, reduce_func, apply_node_func=None, etype=None)\n",
      " |      Send messages along all the edges of the specified type\n",
      " |      and update all the nodes of the corresponding destination type.\n",
      " |      \n",
      " |      For heterogeneous graphs with number of relation types > 1, send messages\n",
      " |      along all the edges, reduce them by type-wisely and across different types\n",
      " |      at the same time. Then, update the node features of all the nodes.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      message_func : dgl.function.BuiltinFunction or callable\n",
      " |          The message function to generate messages along the edges.\n",
      " |          It must be either a :ref:`api-built-in` or a :ref:`apiudf`.\n",
      " |      reduce_func : dgl.function.BuiltinFunction or callable\n",
      " |          The reduce function to aggregate the messages.\n",
      " |          It must be either a :ref:`api-built-in` or a :ref:`apiudf`.\n",
      " |      apply_node_func : callable, optional\n",
      " |          An optional apply function to further update the node features\n",
      " |          after the message reduction. It must be a :ref:`apiudf`.\n",
      " |      etype : str or (str, str, str), optional\n",
      " |          The type name of the edges. The allowed type name formats are:\n",
      " |      \n",
      " |          * ``(str, str, str)`` for source node type, edge type and destination node type.\n",
      " |          * or one ``str`` edge type name if the name can uniquely identify a\n",
      " |            triplet format in the graph.\n",
      " |      \n",
      " |          Can be omitted if the graph has only one type of edges.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      * If some of the nodes in the graph has no in-edges, DGL does not invoke\n",
      " |        message and reduce functions for these nodes and fill their aggregated messages\n",
      " |        with zero. Users can control the filled values via :meth:`set_n_initializer`.\n",
      " |        DGL still invokes :attr:`apply_node_func` if provided.\n",
      " |      * DGL recommends using DGL's bulit-in function for the :attr:`message_func`\n",
      " |        and the :attr:`reduce_func` arguments,\n",
      " |        because DGL will invoke efficient kernels that avoids copying node features to\n",
      " |        edge features in this case.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> import dgl\n",
      " |      >>> import dgl.function as fn\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      **Homogeneous graph**\n",
      " |      \n",
      " |      >>> g = dgl.graph(([0, 1, 2, 3], [1, 2, 3, 4]))\n",
      " |      >>> g.ndata['x'] = torch.ones(5, 2)\n",
      " |      >>> g.update_all(fn.copy_u('x', 'm'), fn.sum('m', 'h'))\n",
      " |      >>> g.ndata['h']\n",
      " |      tensor([[0., 0.],\n",
      " |              [1., 1.],\n",
      " |              [1., 1.],\n",
      " |              [1., 1.],\n",
      " |              [1., 1.]])\n",
      " |      \n",
      " |      **Heterogeneous graph**\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({('user', 'follows', 'user'): ([0, 1, 2], [1, 2, 2])})\n",
      " |      \n",
      " |      Update all.\n",
      " |      \n",
      " |      >>> g.nodes['user'].data['h'] = torch.tensor([[0.], [1.], [2.]])\n",
      " |      >>> g['follows'].update_all(fn.copy_src('h', 'm'), fn.sum('m', 'h'), etype='follows')\n",
      " |      >>> g.nodes['user'].data['h']\n",
      " |      tensor([[0.],\n",
      " |              [0.],\n",
      " |              [3.]])\n",
      " |      \n",
      " |      **Heterogenenous graph (number relation types > 1)**\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({\n",
      " |      ...     ('user', 'follows', 'user'): ([0, 1], [1, 1]),\n",
      " |      ...     ('game', 'attracts', 'user'): ([0], [1])\n",
      " |      ... })\n",
      " |      \n",
      " |      Update all.\n",
      " |      \n",
      " |      >>> g.nodes['user'].data['h'] = torch.tensor([[1.], [2.]])\n",
      " |      >>> g.nodes['game'].data['h'] = torch.tensor([[1.]])\n",
      " |      >>> g.update_all(fn.copy_src('h', 'm'), fn.sum('m', 'h'))\n",
      " |      >>> g.nodes['user'].data['h']\n",
      " |      tensor([[0.],\n",
      " |              [4.]])\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |  \n",
      " |  batch_size\n",
      " |      Return the number of graphs in the batched graph.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      int\n",
      " |          The Number of graphs in the batch. If the graph is not a batched one,\n",
      " |          it will return 1.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      Query for homogeneous graphs.\n",
      " |      \n",
      " |      >>> g1 = dgl.graph((torch.tensor([0, 1, 2]), torch.tensor([1, 2, 3])))\n",
      " |      >>> g1.batch_size\n",
      " |      1\n",
      " |      >>> g2 = dgl.graph((torch.tensor([0, 0, 0, 1]), torch.tensor([0, 1, 2, 0])))\n",
      " |      >>> bg = dgl.batch([g1, g2])\n",
      " |      >>> bg.batch_size\n",
      " |      2\n",
      " |      \n",
      " |      Query for heterogeneous graphs.\n",
      " |      \n",
      " |      >>> hg1 = dgl.heterograph({\n",
      " |      ...       ('user', 'plays', 'game') : (torch.tensor([0, 1]), torch.tensor([0, 0]))})\n",
      " |      >>> hg1.batch_size\n",
      " |      1\n",
      " |      >>> hg2 = dgl.heterograph({\n",
      " |      ...       ('user', 'plays', 'game') : (torch.tensor([0, 0]), torch.tensor([1, 0]))})\n",
      " |      >>> bg = dgl.batch([hg1, hg2])\n",
      " |      >>> bg.batch_size\n",
      " |      2\n",
      " |  \n",
      " |  canonical_etypes\n",
      " |      Return all the canonical edge types in the graph.\n",
      " |      \n",
      " |      A canonical edge type is a string triplet ``(str, str, str)``\n",
      " |      for source node type, edge type and destination node type.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      list[(str, str, str)]\n",
      " |          All the canonical edge type triplets in a list.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      DGL internally assigns an integer ID for each edge type. The returned\n",
      " |      edge type names are sorted according to their IDs.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      etypes\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({\n",
      " |      ...     ('user', 'follows', 'user'): (torch.tensor([0, 1]), torch.tensor([1, 2])),\n",
      " |      ...     ('user', 'follows', 'game'): (torch.tensor([0, 1, 2]), torch.tensor([1, 2, 3])),\n",
      " |      ...     ('user', 'plays', 'game'): (torch.tensor([1, 3]), torch.tensor([2, 3]))\n",
      " |      ... })\n",
      " |      >>> g.canonical_etypes\n",
      " |      [('user', 'follows', 'user'),\n",
      " |       ('user', 'follows', 'game'),\n",
      " |       ('user', 'plays', 'game')]\n",
      " |  \n",
      " |  device\n",
      " |      Get the device of the graph.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      device context\n",
      " |          The device of the graph, which should be a framework-specific device object\n",
      " |          (e.g., ``torch.device``).\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      Create a homogeneous graph for demonstration.\n",
      " |      \n",
      " |      >>> g = dgl.graph((torch.tensor([0, 1]), torch.tensor([1, 2])))\n",
      " |      >>> print(g.device)\n",
      " |      device(type='cpu')\n",
      " |      \n",
      " |      The case of heterogeneous graphs is the same.\n",
      " |  \n",
      " |  dstdata\n",
      " |      Return a node data view for setting/getting destination node features.\n",
      " |      \n",
      " |      Let ``g`` be a DGLGraph. If ``g`` is a graph of a single destination node type,\n",
      " |      ``g.dstdata[feat]`` returns the destination node feature associated with the name\n",
      " |      ``feat``. One can also set a destination node feature associated with the name\n",
      " |      ``feat`` by setting ``g.dstdata[feat]`` to a tensor.\n",
      " |      \n",
      " |      If ``g`` is a graph of multiple destination node types, ``g.dstdata[feat]`` returns a\n",
      " |      dict[str, Tensor] mapping destination node types to the node features associated with\n",
      " |      the name ``feat`` for the corresponding type. One can also set a node feature\n",
      " |      associated with the name ``feat`` for some destination node type(s) by setting\n",
      " |      ``g.dstdata[feat]`` to a dictionary as described.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For setting features, the device of the features must be the same as the device\n",
      " |      of the graph.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      Set and get feature 'h' for a graph of a single destination node type.\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({\n",
      " |      ...     ('user', 'plays', 'game'): (torch.tensor([0, 1]), torch.tensor([1, 2]))})\n",
      " |      >>> g.dstdata['h'] = torch.ones(3, 1)\n",
      " |      >>> g.dstdata['h']\n",
      " |      tensor([[1.],\n",
      " |              [1.],\n",
      " |              [1.]])\n",
      " |      \n",
      " |      Set and get feature 'h' for a graph of multiple destination node types.\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({\n",
      " |      ...     ('user', 'plays', 'game'): (torch.tensor([1, 2]), torch.tensor([1, 2])),\n",
      " |      ...     ('user', 'watches', 'movie'): (torch.tensor([2, 2]), torch.tensor([1, 1]))\n",
      " |      ... })\n",
      " |      >>> g.dstdata['h'] = {'game': torch.zeros(3, 1), 'movie': torch.ones(2, 1)}\n",
      " |      >>> g.dstdata['h']\n",
      " |      {'game': tensor([[0.], [0.], [0.]]),\n",
      " |       'movie': tensor([[1.], [1.]])}\n",
      " |      >>> g.dstdata['h'] = {'game': torch.ones(3, 1)}\n",
      " |      >>> g.dstdata['h']\n",
      " |      {'game': tensor([[1.], [1.], [1.]]),\n",
      " |       'movie': tensor([[1.], [1.]])}\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      nodes\n",
      " |      ndata\n",
      " |      dstnodes\n",
      " |  \n",
      " |  dstnodes\n",
      " |      Return a node view for destination nodes\n",
      " |      \n",
      " |      If the graph is a uni-bipartite graph (see :func:`is_unibipartite` for reference),\n",
      " |      this is :func:`nodes` restricted to destination node types. Otherwise, it is an alias\n",
      " |      for :func:`nodes`.\n",
      " |      \n",
      " |      One can use it for:\n",
      " |      \n",
      " |      1. Getting the node IDs for a single node type.\n",
      " |      2. Setting/getting features for all nodes of a single node type.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      Create a uni-bipartite graph.\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({\n",
      " |      ...     ('user', 'plays', 'game'): (torch.tensor([0]), torch.tensor([1])),\n",
      " |      ...     ('developer', 'develops', 'game'): (torch.tensor([1]), torch.tensor([2]))\n",
      " |      ... })\n",
      " |      \n",
      " |      Get the node IDs for destination node types.\n",
      " |      \n",
      " |      >>> g.dstnodes('game')\n",
      " |      tensor([0, 1, 2])\n",
      " |      \n",
      " |      Set/get features for destination node types.\n",
      " |      \n",
      " |      >>> g.dstnodes['game'].data['h'] = torch.ones(3, 1)\n",
      " |      >>> g.dstnodes['game'].data['h']\n",
      " |      tensor([[1.],\n",
      " |              [1.],\n",
      " |              [1.]])\n",
      " |      \n",
      " |      Create a graph that is not uni-bipartite.\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({\n",
      " |      ...     ('user', 'follows', 'user'): (torch.tensor([0]), torch.tensor([1])),\n",
      " |      ...     ('developer', 'develops', 'game'): (torch.tensor([1]), torch.tensor([2]))\n",
      " |      ... })\n",
      " |      \n",
      " |      :func:`dgl.DGLGraph.dstnodes` falls back to :func:`dgl.DGLGraph.nodes` and one can\n",
      " |      get the node IDs for both source and destination node types.\n",
      " |      \n",
      " |      >>> g.dstnodes('developer')\n",
      " |      tensor([0, 1])\n",
      " |      \n",
      " |      One can also set/get features for source node types in this case.\n",
      " |      \n",
      " |      >>> g.dstnodes['developer'].data['h'] = torch.ones(2, 1)\n",
      " |      >>> g.dstnodes['developer'].data['h']\n",
      " |      tensor([[1.],\n",
      " |              [1.]])\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      dstdata\n",
      " |  \n",
      " |  dsttypes\n",
      " |      Return all the destination node type names in this graph.\n",
      " |      \n",
      " |      If the graph can further divide its node types into two subsets A and B where\n",
      " |      all the edeges are from nodes of types in A to nodes of types in B, we call\n",
      " |      this graph a *uni-bipartite* graph and the nodes in A being the *source*\n",
      " |      nodes and the ones in B being the *destination* nodes. If the graph is not\n",
      " |      uni-bipartite, the source and destination nodes are just the entire set of\n",
      " |      nodes in the graph.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      list[str]\n",
      " |          All the destination node type names in a list.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      srctypes\n",
      " |      is_unibipartite\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      Query for a uni-bipartite graph.\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({\n",
      " |      ...     ('user', 'plays', 'game'): (torch.tensor([0]), torch.tensor([1])),\n",
      " |      ...     ('developer', 'develops', 'game'): (torch.tensor([1]), torch.tensor([2]))\n",
      " |      ... })\n",
      " |      >>> g.dsttypes\n",
      " |      ['game']\n",
      " |      \n",
      " |      Query for a graph that is not uni-bipartite.\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({\n",
      " |      ...     ('user', 'follows', 'user'): (torch.tensor([0]), torch.tensor([1])),\n",
      " |      ...     ('developer', 'develops', 'game'): (torch.tensor([1]), torch.tensor([2]))\n",
      " |      ... })\n",
      " |      >>> g.dsttypes\n",
      " |      ['developer', 'game', 'user']\n",
      " |  \n",
      " |  edata\n",
      " |      Return an edge data view for setting/getting edge features.\n",
      " |      \n",
      " |      Let ``g`` be a DGLGraph. If ``g`` is a graph of a single edge type, ``g.edata[feat]``\n",
      " |      returns the edge feature associated with the name ``feat``. One can also set an\n",
      " |      edge feature associated with the name ``feat`` by setting ``g.edata[feat]`` to a tensor.\n",
      " |      \n",
      " |      If ``g`` is a graph of multiple edge types, ``g.edata[feat]`` returns a\n",
      " |      dict[str, Tensor] mapping canonical edge types to the edge features associated with\n",
      " |      the name ``feat`` for the corresponding type. One can also set an edge feature\n",
      " |      associated with the name ``feat`` for some edge type(s) by setting\n",
      " |      ``g.edata[feat]`` to a dictionary as described.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For setting features, the device of the features must be the same as the device\n",
      " |      of the graph.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      Set and get feature 'h' for a graph of a single edge type.\n",
      " |      \n",
      " |      >>> g = dgl.graph((torch.tensor([0, 1]), torch.tensor([1, 2])))\n",
      " |      >>> g.edata['h'] = torch.ones(2, 1)\n",
      " |      >>> g.edata['h']\n",
      " |      tensor([[1.],\n",
      " |              [1.]])\n",
      " |      \n",
      " |      Set and get feature 'h' for a graph of multiple edge types.\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({\n",
      " |      ...     ('user', 'follows', 'user'): (torch.tensor([1, 2]), torch.tensor([3, 4])),\n",
      " |      ...     ('user', 'plays', 'user'): (torch.tensor([2, 2]), torch.tensor([1, 1])),\n",
      " |      ...     ('player', 'plays', 'game'): (torch.tensor([2, 2]), torch.tensor([1, 1]))\n",
      " |      ... })\n",
      " |      >>> g.edata['h'] = {('user', 'follows', 'user'): torch.zeros(2, 1),\n",
      " |      ...                 ('user', 'plays', 'user'): torch.ones(2, 1)}\n",
      " |      >>> g.edata['h']\n",
      " |      {('user', 'follows', 'user'): tensor([[0.], [0.]]),\n",
      " |       ('user', 'plays', 'user'): tensor([[1.], [1.]])}\n",
      " |      >>> g.edata['h'] = {('user', 'follows', 'user'): torch.ones(2, 1)}\n",
      " |      >>> g.edata['h']\n",
      " |      {('user', 'follows', 'user'): tensor([[1.], [1.]]),\n",
      " |       ('user', 'plays', 'user'): tensor([[1.], [1.]])}\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      edges\n",
      " |  \n",
      " |  edges\n",
      " |      Return an edge view\n",
      " |      \n",
      " |      One can use it for:\n",
      " |      \n",
      " |      1. Getting the edges for a single edge type. In this case, it can take the\n",
      " |         following optional arguments:\n",
      " |      \n",
      " |          - form : str, optional\n",
      " |                The return form, which can be one of the following:\n",
      " |      \n",
      " |                - ``'uv'`` (default): The returned result is a 2-tuple of 1D tensors\n",
      " |                  :math:`(U, V)`, representing the source and destination nodes of all edges.\n",
      " |                  For each :math:`i`, :math:`(U[i], V[i])` forms an edge.\n",
      " |                - ``'eid'``: The returned result is a 1D tensor :math:`EID`, representing\n",
      " |                  the IDs of all edges.\n",
      " |                - ``'all'``: The returned result is a 3-tuple of 1D tensors :math:`(U, V, EID)`,\n",
      " |                  representing the source nodes, destination nodes and IDs of all edges.\n",
      " |                  For each :math:`i`, :math:`(U[i], V[i])` forms an edge with ID :math:`EID[i]`.\n",
      " |          - order : str, optional\n",
      " |                The order of the returned edges, which can be one of the following:\n",
      " |      \n",
      " |                - ``'eid'`` (default): The edges are sorted by their IDs.\n",
      " |                - ``'srcdst'``: The edges are sorted first by their source node IDs and then\n",
      " |                  by their destination node IDs to break ties.\n",
      " |          - etype : str or tuple of str, optional\n",
      " |                The edge type for query, which can be an edge type (str) or a canonical edge\n",
      " |                type (3-tuple of str). When an edge type appears in multiple canonical edge\n",
      " |                types, one must use a canonical edge type. If the graph has multiple edge\n",
      " |                types, one must specify the argument. Otherwise, it can be omitted.\n",
      " |      2. Setting/getting features for all edges of a single edge type. To set/get a feature\n",
      " |         ``feat`` for edges of type ``etype`` in a graph ``g``, one can use\n",
      " |         ``g.edges[etype].data[feat]``.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      **Get the Edges for a Single Edge Type**\n",
      " |      \n",
      " |      Create a graph with a single edge type.\n",
      " |      \n",
      " |      >>> g = dgl.graph((torch.tensor([1, 0, 0]), torch.tensor([1, 1, 0])))\n",
      " |      >>> g.edges()\n",
      " |      (tensor([1, 0, 0]), tensor([1, 1, 0]))\n",
      " |      \n",
      " |      Specify a different value for :attr:`form` and :attr:`order`.\n",
      " |      \n",
      " |      >>> g.edges(form='all', order='srcdst')\n",
      " |      (tensor([0, 0, 1]), tensor([0, 1, 1]), tensor([2, 1, 0]))\n",
      " |      \n",
      " |      For a graph of multiple edge types, it is required to specify the edge type in query.\n",
      " |      \n",
      " |      >>> hg = dgl.heterograph({\n",
      " |      ...     ('user', 'follows', 'user'): (torch.tensor([0, 1]), torch.tensor([1, 2])),\n",
      " |      ...     ('user', 'plays', 'game'): (torch.tensor([3, 4]), torch.tensor([5, 6]))\n",
      " |      ... })\n",
      " |      >>> hg.edges(etype='plays')\n",
      " |      (tensor([3, 4]), tensor([5, 6]))\n",
      " |      \n",
      " |      **Set/get Features for All Edges of a Single Edge Type**\n",
      " |      \n",
      " |      Create a heterogeneous graph of two edge types.\n",
      " |      \n",
      " |      >>> hg = dgl.heterograph({\n",
      " |      ...     ('user', 'follows', 'user'): (torch.tensor([0, 1]), torch.tensor([1, 2])),\n",
      " |      ...     ('user', 'plays', 'game'): (torch.tensor([3, 4]), torch.tensor([5, 6]))\n",
      " |      ... })\n",
      " |      \n",
      " |      Set and get a feature 'h' for all edges of a single type in the heterogeneous graph.\n",
      " |      \n",
      " |      >>> hg.edges['follows'].data['h'] = torch.ones(2, 1)\n",
      " |      >>> hg.edges['follows'].data['h']\n",
      " |      tensor([[1.], [1.]])\n",
      " |      \n",
      " |      To set edge features for a graph with a single edge type, use :func:`DGLGraph.edata`.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      edata\n",
      " |  \n",
      " |  etypes\n",
      " |      Return all the edge type names in the graph.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      list[str]\n",
      " |          All the edge type names in a list.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      DGL internally assigns an integer ID for each edge type. The returned\n",
      " |      edge type names are sorted according to their IDs.\n",
      " |      \n",
      " |      The complete format to specify an relation is a string triplet ``(str, str, str)``\n",
      " |      for source node type, edge type and destination node type. DGL calls this\n",
      " |      format *canonical edge type*. An edge type can appear in multiple canonical edge types.\n",
      " |      For example, ``'interacts'`` can appear in two canonical edge types\n",
      " |      ``('drug', 'interacts', 'drug')`` and ``('protein', 'interacts', 'protein')``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      canonical_etypes\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({\n",
      " |      ...     ('user', 'follows', 'user'): (torch.tensor([0, 1]), torch.tensor([1, 2])),\n",
      " |      ...     ('user', 'follows', 'game'): (torch.tensor([0, 1, 2]), torch.tensor([1, 2, 3])),\n",
      " |      ...     ('user', 'plays', 'game'): (torch.tensor([1, 3]), torch.tensor([2, 3]))\n",
      " |      ... })\n",
      " |      >>> g.etypes\n",
      " |      ['follows', 'follows', 'plays']\n",
      " |  \n",
      " |  idtype\n",
      " |      The data type for storing the structure-related graph information\n",
      " |      such as node and edge IDs.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Framework-specific device object\n",
      " |          For example, this can be ``torch.int32`` or ``torch.int64`` for PyTorch.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      >>> src_ids = torch.tensor([0, 0, 1])\n",
      " |      >>> dst_ids = torch.tensor([1, 2, 2])\n",
      " |      >>> g = dgl.graph((src_ids, dst_ids))\n",
      " |      >>> g.idtype\n",
      " |      torch.int64\n",
      " |      >>> g = dgl.graph((src_ids, dst_ids), idtype=torch.int32)\n",
      " |      >>> g.idtype\n",
      " |      torch.int32\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      long\n",
      " |      int\n",
      " |  \n",
      " |  is_homogeneous\n",
      " |      Return whether the graph is a homogeneous graph.\n",
      " |      \n",
      " |      A homogeneous graph only has one node type and one edge type.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      bool\n",
      " |          True if the graph is a homogeneous graph.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      Create a homogeneous graph for check.\n",
      " |      \n",
      " |      >>> g = dgl.graph((torch.tensor([0, 0, 1, 1]), torch.tensor([1, 0, 2, 3])))\n",
      " |      >>> g.is_homogeneous\n",
      " |      True\n",
      " |      \n",
      " |      Create a heterogeneous graph for check.\n",
      " |      \n",
      " |      If the graph has multiple edge types, one need to specify the edge type.\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({\n",
      " |      ...     ('user', 'follows', 'game'): (torch.tensor([0, 1, 2]), torch.tensor([1, 2, 3]))})\n",
      " |      >>> g.is_homogeneous\n",
      " |      False\n",
      " |  \n",
      " |  is_multigraph\n",
      " |      Return whether the graph is a multigraph with parallel edges.\n",
      " |      \n",
      " |      A multigraph has more than one edges between the same pair of nodes, called\n",
      " |      *parallel edges*.  For heterogeneous graphs, parallel edge further requires\n",
      " |      the canonical edge type to be the same (see :meth:`canonical_etypes` for the\n",
      " |      definition).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      bool\n",
      " |          True if the graph is a multigraph.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Checking whether the graph is a multigraph could be expensive for a large one.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      Check for homogeneous graphs.\n",
      " |      \n",
      " |      >>> g = dgl.graph((torch.tensor([0, 1]), torch.tensor([1, 3])))\n",
      " |      >>> g.is_multigraph\n",
      " |      False\n",
      " |      >>> g = dgl.graph((torch.tensor([0, 1, 1]), torch.tensor([1, 3, 3])))\n",
      " |      >>> g.is_multigraph\n",
      " |      True\n",
      " |      \n",
      " |      Check for heterogeneous graphs.\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({\n",
      " |      ...     ('user', 'follows', 'user'): (torch.tensor([0, 1]), torch.tensor([1, 2])),\n",
      " |      ...     ('user', 'follows', 'game'): (torch.tensor([0, 1, 2]), torch.tensor([1, 2, 3]))\n",
      " |      ... })\n",
      " |      >>> g.is_multigraph\n",
      " |      False\n",
      " |      >>> g = dgl.heterograph({\n",
      " |      ...     ('user', 'follows', 'user'): (torch.tensor([0, 1, 1]), torch.tensor([1, 2, 2])),\n",
      " |      ...     ('user', 'follows', 'game'): (torch.tensor([0, 1, 2]), torch.tensor([1, 2, 3]))\n",
      " |      ... })\n",
      " |      >>> g.is_multigraph\n",
      " |      True\n",
      " |  \n",
      " |  is_readonly\n",
      " |      **DEPRECATED**: DGLGraph will always be mutable.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      bool\n",
      " |          True if the graph is readonly, False otherwise.\n",
      " |  \n",
      " |  is_unibipartite\n",
      " |      Return whether the graph is a uni-bipartite graph.\n",
      " |      \n",
      " |      A uni-bipartite heterograph can further divide its node types into two sets:\n",
      " |      SRC and DST. All edges are from nodes in SRC to nodes in DST. The following APIs\n",
      " |      can be used to get the type, data, and nodes that belong to SRC and DST sets:\n",
      " |      \n",
      " |      * :func:`srctype` and :func:`dsttype`\n",
      " |      * :func:`srcdata` and :func:`dstdata`\n",
      " |      * :func:`srcnodes` and :func:`dstnodes`\n",
      " |      \n",
      " |      Note that we allow two node types to have the same name as long as one\n",
      " |      belongs to SRC while the other belongs to DST. To distinguish them, prepend\n",
      " |      the name with ``\"SRC/\"`` or ``\"DST/\"`` when specifying a node type.\n",
      " |  \n",
      " |  ndata\n",
      " |      Return a node data view for setting/getting node features\n",
      " |      \n",
      " |      Let ``g`` be a DGLGraph. If ``g`` is a graph of a single node type, ``g.ndata[feat]``\n",
      " |      returns the node feature associated with the name ``feat``. One can also set a node\n",
      " |      feature associated with the name ``feat`` by setting ``g.ndata[feat]`` to a tensor.\n",
      " |      \n",
      " |      If ``g`` is a graph of multiple node types, ``g.ndata[feat]`` returns a\n",
      " |      dict[str, Tensor] mapping node types to the node features associated with the name\n",
      " |      ``feat`` for the corresponding type. One can also set a node feature associated\n",
      " |      with the name ``feat`` for some node type(s) by setting ``g.ndata[feat]`` to a\n",
      " |      dictionary as described.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For setting features, the device of the features must be the same as the device\n",
      " |      of the graph.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      Set and get feature 'h' for a graph of a single node type.\n",
      " |      \n",
      " |      >>> g = dgl.graph((torch.tensor([0, 1]), torch.tensor([1, 2])))\n",
      " |      >>> g.ndata['h'] = torch.ones(3, 1)\n",
      " |      >>> g.ndata['h']\n",
      " |      tensor([[1.],\n",
      " |              [1.],\n",
      " |              [1.]])\n",
      " |      \n",
      " |      Set and get feature 'h' for a graph of multiple node types.\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({\n",
      " |      ...     ('user', 'follows', 'user'): (torch.tensor([1, 2]), torch.tensor([3, 4])),\n",
      " |      ...     ('player', 'plays', 'game'): (torch.tensor([2, 2]), torch.tensor([1, 1]))\n",
      " |      ... })\n",
      " |      >>> g.ndata['h'] = {'game': torch.zeros(2, 1), 'player': torch.ones(3, 1)}\n",
      " |      >>> g.ndata['h']\n",
      " |      {'game': tensor([[0.], [0.]]),\n",
      " |       'player': tensor([[1.], [1.], [1.]])}\n",
      " |      >>> g.ndata['h'] = {'game': torch.ones(2, 1)}\n",
      " |      >>> g.ndata['h']\n",
      " |      {'game': tensor([[1.], [1.]]),\n",
      " |       'player': tensor([[1.], [1.], [1.]])}\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      nodes\n",
      " |  \n",
      " |  nodes\n",
      " |      Return a node view\n",
      " |      \n",
      " |      One can use it for:\n",
      " |      \n",
      " |      1. Getting the node IDs for a single node type.\n",
      " |      2. Setting/getting features for all nodes of a single node type.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      Create a homogeneous graph and a heterogeneous graph of two node types.\n",
      " |      \n",
      " |      >>> g = dgl.graph((torch.tensor([0, 1]), torch.tensor([1, 2])))\n",
      " |      >>> hg = dgl.heterograph({\n",
      " |      ...     ('user', 'follows', 'user'): (torch.tensor([0, 1]), torch.tensor([1, 2])),\n",
      " |      ...     ('user', 'plays', 'game'): (torch.tensor([3, 4]), torch.tensor([5, 6]))\n",
      " |      ... })\n",
      " |      \n",
      " |      Get the node IDs of the homogeneous graph.\n",
      " |      \n",
      " |      >>> g.nodes()\n",
      " |      tensor([0, 1, 2])\n",
      " |      \n",
      " |      Get the node IDs of the heterogeneous graph. With multiple node types introduced,\n",
      " |      one needs to specify the node type for query.\n",
      " |      \n",
      " |      >>> hg.nodes('user')\n",
      " |      tensor([0, 1, 2, 3, 4])\n",
      " |      \n",
      " |      Set and get a feature 'h' for all nodes of a single type in the heterogeneous graph.\n",
      " |      \n",
      " |      >>> hg.nodes['user'].data['h'] = torch.ones(5, 1)\n",
      " |      >>> hg.nodes['user'].data['h']\n",
      " |      tensor([[1.], [1.], [1.], [1.], [1.]])\n",
      " |      \n",
      " |      To set node features for a graph with a single node type, use :func:`DGLGraph.ndata`.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      ndata\n",
      " |  \n",
      " |  ntypes\n",
      " |      Return all the node type names in the graph.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      list[str]\n",
      " |          All the node type names in a list.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      DGL internally assigns an integer ID for each node type. The returned\n",
      " |      node type names are sorted according to their IDs.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({\n",
      " |      ...     ('user', 'follows', 'user'): (torch.tensor([0, 1]), torch.tensor([1, 2])),\n",
      " |      ...     ('user', 'follows', 'game'): (torch.tensor([0, 1, 2]), torch.tensor([1, 2, 3])),\n",
      " |      ...     ('user', 'plays', 'game'): (torch.tensor([1, 3]), torch.tensor([2, 3]))\n",
      " |      ... })\n",
      " |      >>> g.ntypes\n",
      " |      ['game', 'user']\n",
      " |  \n",
      " |  srcdata\n",
      " |      Return a node data view for setting/getting source node features.\n",
      " |      \n",
      " |      Let ``g`` be a DGLGraph. If ``g`` is a graph of a single source node type,\n",
      " |      ``g.srcdata[feat]`` returns the source node feature associated with the name ``feat``.\n",
      " |      One can also set a source node feature associated with the name ``feat`` by\n",
      " |      setting ``g.srcdata[feat]`` to a tensor.\n",
      " |      \n",
      " |      If ``g`` is a graph of multiple source node types, ``g.srcdata[feat]`` returns a\n",
      " |      dict[str, Tensor] mapping source node types to the node features associated with\n",
      " |      the name ``feat`` for the corresponding type. One can also set a node feature\n",
      " |      associated with the name ``feat`` for some source node type(s) by setting\n",
      " |      ``g.srcdata[feat]`` to a dictionary as described.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For setting features, the device of the features must be the same as the device\n",
      " |      of the graph.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      Set and get feature 'h' for a graph of a single source node type.\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({\n",
      " |      ...     ('user', 'plays', 'game'): (torch.tensor([0, 1]), torch.tensor([1, 2]))})\n",
      " |      >>> g.srcdata['h'] = torch.ones(2, 1)\n",
      " |      >>> g.srcdata['h']\n",
      " |      tensor([[1.],\n",
      " |              [1.]])\n",
      " |      \n",
      " |      Set and get feature 'h' for a graph of multiple source node types.\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({\n",
      " |      ...     ('user', 'plays', 'game'): (torch.tensor([1, 2]), torch.tensor([3, 4])),\n",
      " |      ...     ('player', 'plays', 'game'): (torch.tensor([2, 2]), torch.tensor([1, 1]))\n",
      " |      ... })\n",
      " |      >>> g.srcdata['h'] = {'user': torch.zeros(3, 1), 'player': torch.ones(3, 1)}\n",
      " |      >>> g.srcdata['h']\n",
      " |      {'player': tensor([[1.], [1.], [1.]]),\n",
      " |       'user': tensor([[0.], [0.], [0.]])}\n",
      " |      >>> g.srcdata['h'] = {'user': torch.ones(3, 1)}\n",
      " |      >>> g.srcdata['h']\n",
      " |      {'player': tensor([[1.], [1.], [1.]]),\n",
      " |       'user': tensor([[1.], [1.], [1.]])}\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      nodes\n",
      " |      ndata\n",
      " |      srcnodes\n",
      " |  \n",
      " |  srcnodes\n",
      " |      Return a node view for source nodes\n",
      " |      \n",
      " |      If the graph is a uni-bipartite graph (see :func:`is_unibipartite` for reference),\n",
      " |      this is :func:`nodes` restricted to source node types. Otherwise, it is an alias\n",
      " |      for :func:`nodes`.\n",
      " |      \n",
      " |      One can use it for:\n",
      " |      \n",
      " |      1. Getting the node IDs for a single node type.\n",
      " |      2. Setting/getting features for all nodes of a single node type.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      Create a uni-bipartite graph.\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({\n",
      " |      ...     ('user', 'plays', 'game'): (torch.tensor([0]), torch.tensor([1])),\n",
      " |      ...     ('developer', 'develops', 'game'): (torch.tensor([1]), torch.tensor([2]))\n",
      " |      ... })\n",
      " |      \n",
      " |      Get the node IDs for source node types.\n",
      " |      \n",
      " |      >>> g.srcnodes('user')\n",
      " |      tensor([0])\n",
      " |      >>> g.srcnodes('developer')\n",
      " |      tensor([0, 1])\n",
      " |      \n",
      " |      Set/get features for source node types.\n",
      " |      \n",
      " |      >>> g.srcnodes['user'].data['h'] = torch.ones(1, 1)\n",
      " |      >>> g.srcnodes['user'].data['h']\n",
      " |      tensor([[1.]])\n",
      " |      \n",
      " |      Create a graph that is not uni-bipartite.\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({\n",
      " |      ...     ('user', 'follows', 'user'): (torch.tensor([0]), torch.tensor([1])),\n",
      " |      ...     ('developer', 'develops', 'game'): (torch.tensor([1]), torch.tensor([2]))\n",
      " |      ... })\n",
      " |      \n",
      " |      :func:`dgl.DGLGraph.srcnodes` falls back to :func:`dgl.DGLGraph.nodes` and one can\n",
      " |      get the node IDs for both source and destination node types.\n",
      " |      \n",
      " |      >>> g.srcnodes('game')\n",
      " |      tensor([0, 1, 2])\n",
      " |      \n",
      " |      One can also set/get features for destination node types in this case.\n",
      " |      \n",
      " |      >>> g.srcnodes['game'].data['h'] = torch.ones(3, 1)\n",
      " |      >>> g.srcnodes['game'].data['h']\n",
      " |      tensor([[1.],\n",
      " |              [1.],\n",
      " |              [1.]])\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      srcdata\n",
      " |  \n",
      " |  srctypes\n",
      " |      Return all the source node type names in this graph.\n",
      " |      \n",
      " |      If the graph can further divide its node types into two subsets A and B where\n",
      " |      all the edeges are from nodes of types in A to nodes of types in B, we call\n",
      " |      this graph a *uni-bipartite* graph and the nodes in A being the *source*\n",
      " |      nodes and the ones in B being the *destination* nodes. If the graph is not\n",
      " |      uni-bipartite, the source and destination nodes are just the entire set of\n",
      " |      nodes in the graph.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      list[str]\n",
      " |          All the source node type names in a list.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      dsttypes\n",
      " |      is_unibipartite\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      The following example uses PyTorch backend.\n",
      " |      \n",
      " |      >>> import dgl\n",
      " |      >>> import torch\n",
      " |      \n",
      " |      Query for a uni-bipartite graph.\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({\n",
      " |      ...     ('user', 'plays', 'game'): (torch.tensor([0]), torch.tensor([1])),\n",
      " |      ...     ('developer', 'develops', 'game'): (torch.tensor([1]), torch.tensor([2]))\n",
      " |      ... })\n",
      " |      >>> g.srctypes\n",
      " |      ['developer', 'user']\n",
      " |      \n",
      " |      Query for a graph that is not uni-bipartite.\n",
      " |      \n",
      " |      >>> g = dgl.heterograph({\n",
      " |      ...     ('user', 'follows', 'user'): (torch.tensor([0]), torch.tensor([1])),\n",
      " |      ...     ('developer', 'develops', 'game'): (torch.tensor([1]), torch.tensor([2]))\n",
      " |      ... })\n",
      " |      >>> g.srctypes\n",
      " |      ['developer', 'game', 'user']\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  is_block = False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(batch_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "3c5ae454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(indices=tensor([[  1,   1,   1,  ..., 166, 166, 166],\n",
       "                       [  1,   2,   3,  ...,  44, 166, 166]]),\n",
       "       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),\n",
       "       size=(167, 167), nnz=17238, layout=torch.sparse_coo)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_graphs[0].adj()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b796e8a7",
   "metadata": {},
   "source": [
    "<h1> Training Loop </h1>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "140b3968",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_dif(start_time):\n",
    "    \"\"\"for calculating training time\"\"\"\n",
    "    end_time = time.time()\n",
    "    time_dif = end_time - start_time\n",
    "    return datetime.timedelta(seconds=int(round(time_dif)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f96ba792",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dev(model, val_data_helper, mode='val'):\n",
    "    #data_helper = DataHelper(dataset, mode='dev')\n",
    "\n",
    "    total_pred = 0\n",
    "    correct = 0\n",
    "    iteration = 0\n",
    "    preds = []\n",
    "    labels = []\n",
    "    for content, label, _ in val_data_helper.batch_iter(batch_size=batch_size, num_epoch=1):\n",
    "        iteration += 1\n",
    "        model.eval()\n",
    "\n",
    "        logits = model(content)\n",
    "        pred = torch.argmax(logits, dim=1)\n",
    "        preds.extend(pred)\n",
    "        labels.extend(label)\n",
    "        correct_pred = torch.sum(pred == label)\n",
    "\n",
    "        correct += correct_pred\n",
    "        total_pred += len(content)\n",
    "\n",
    "    total_pred = float(total_pred)\n",
    "    correct = correct.float()\n",
    "    acc = torch.div(correct, total_pred).to('cpu')\n",
    "    #print(torch.div(correct, total_pred))\n",
    "    if mode=='test':\n",
    "        print(acc)\n",
    "        return preds, labels\n",
    "    else:\n",
    "        return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7bd87e",
   "metadata": {},
   "source": [
    "ADD A LR SCHEDULER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "135c1916",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,\n",
    "          ngram, \n",
    "          name, \n",
    "          bar, \n",
    "          drop_out, \n",
    "          train_data_helper,\n",
    "          val_data_helper,\n",
    "          device, \n",
    "          edges=True):\n",
    "\n",
    "    print(model)\n",
    "    print('device: ', device)\n",
    "    model.to(device)\n",
    "    \n",
    "\n",
    "    iteration = 0\n",
    "    if bar:\n",
    "        pbar = tqdm.tqdm(total=NUM_ITER_EVAL)\n",
    "    best_acc = 0.0\n",
    "    last_best_epoch = 0\n",
    "    start_time = time.time()\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for content, label, epoch in train_data_helper.batch_iter(batch_size=batch_size, num_epoch=epochs):\n",
    "        improved = ''\n",
    "        model.train()\n",
    "\n",
    "        logits = model(content)\n",
    "        loss = loss_func(logits, label)\n",
    "\n",
    "        pred = torch.argmax(logits, dim=1)\n",
    "\n",
    "        correct = torch.sum(pred == label)\n",
    "\n",
    "        total_correct += correct\n",
    "        total += len(label)\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        iteration += 1\n",
    "        if bar:\n",
    "            pbar.update()\n",
    "        if iteration % NUM_ITER_EVAL == 0:\n",
    "            if bar:\n",
    "                pbar.close()\n",
    "\n",
    "            val_acc = dev(model, val_data_helper, mode='val')\n",
    "            if val_acc > best_acc:\n",
    "                best_acc = val_acc\n",
    "                last_best_epoch = epoch\n",
    "                improved = '*'\n",
    "\n",
    "                torch.save(model, name + '.pkl')\n",
    "\n",
    "            if epoch - last_best_epoch >= EARLY_STOP_EPOCH:\n",
    "                return name\n",
    "            msg = 'Epoch: {0:>6} Iter: {1:>6}, Train Loss: {5:>7.2}, Train Acc: {6:>7.2%}' \\\n",
    "                  + 'Val Acc: {2:>7.2%}, Time: {3}{4}'\n",
    "\n",
    "            print(msg.format(epoch, #0\n",
    "                             iteration, #1\n",
    "                             val_acc, #2\n",
    "                             get_time_dif(start_time), #3\n",
    "                             improved, #4\n",
    "                             total_loss / NUM_ITER_EVAL, #5\n",
    "                             float(total_correct) / float(total)))  #6\n",
    "\n",
    "            total_loss = 0.0\n",
    "            total_correct = 0\n",
    "            total = 0\n",
    "            if bar:\n",
    "                pbar = tqdm.tqdm(total=NUM_ITER_EVAL)\n",
    "\n",
    "    return name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff141ddb",
   "metadata": {},
   "source": [
    "<h1> Train </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "e2a4f652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GE    0.877503\n",
      "SP    0.925578\n",
      "CN    0.947032\n",
      "RU    1.051821\n",
      "JP    1.084146\n",
      "AR    1.113921\n",
      "Name: Target, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# training hyperparameters\n",
    "\n",
    "ngram = 60 # this is used for the doc-specific graphs\n",
    "window_size = 15 # this feeds the PMI and edge mappings\n",
    "dropout = 0.20\n",
    "batch_size = 2\n",
    "lr = 1e-4\n",
    "epochs = 30\n",
    "max_len = 512\n",
    "hidden_size_node = hidden_size\n",
    "edges = True # whether node edges are trainable\n",
    "n_classes = len(target_idx.keys())\n",
    "#mps = 'mps' if torch.has_mps else 'cpu'\n",
    "device = 'cpu' # torch.device(mps)\n",
    "weight_decay = 1e-2\n",
    "weights = get_weights(ds_tr, target_idx)\n",
    "\n",
    "NUM_ITER_EVAL = 5000\n",
    "EARLY_STOP_EPOCH = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "e5a7edcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.GCNDataHelper at 0x17b3ff850>"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b0a6c63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_helper = GCNDataHelper(ds_tr, \n",
    "                            tokenize_fn = tokenize_fn, \n",
    "                            target_idx=target_idx, \n",
    "                            device = device,\n",
    "                            mode='train')\n",
    "\n",
    "val_data_helper = GCNDataHelper(ds_vl,\n",
    "                            tokenize_fn = tokenize_fn, \n",
    "                            target_idx=target_idx, \n",
    "                            device = device,\n",
    "                            mode='dev')\n",
    "\n",
    "test_data_helper = GCNDataHelper(ds_ts,\n",
    "                               tokenize_fn = tokenize_fn, \n",
    "                            target_idx=target_idx, \n",
    "                            device = device,\n",
    "                            mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "80fe7f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5h/lrwcctsx1xv_r4qlss7b9mt80000gp/T/ipykernel_11251/871596858.py:38: RuntimeWarning: divide by zero encountered in log\n",
      "  pmi_matrix[i, j] = np.log(\n"
     ]
    }
   ],
   "source": [
    "edges_weights, edges_mappings, count = cal_PMI(train_data_helper, window_size = window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "fc0eed67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6112\n",
      "5898917\n",
      "torch.Size([5898917, 1])\n"
     ]
    }
   ],
   "source": [
    "model = Model(helper = train_data_helper,\n",
    "              class_num=n_classes, \n",
    "              hidden_size_node=hidden_size_node,\n",
    "              n_gram=ngram, \n",
    "              drop_out=dropout, \n",
    "              edges_num=count,\n",
    "              edges_matrix=edges_mappings,   \n",
    "              embeddings_file = glove_file,\n",
    "              device = device,\n",
    "              max_length = max_len,\n",
    "              trainable_edges=edges, \n",
    "              pmi=edges_weights,\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "97e94570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weighted cross entropy\n",
    "loss_func = torch.nn.CrossEntropyLoss(weight = weights)\n",
    "#loss_func = torch.nn.CrossEntropyLoss()\n",
    "optim = torch.optim.Adam(model.parameters(), lr = lr, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "600b0c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (seq_edge_w): Embedding(5898917, 1)\n",
      "  (node_hidden): Embedding(6112, 300)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (activation): ReLU()\n",
      "  (norm): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
      "  (Linear): Linear(in_features=300, out_features=6, bias=True)\n",
      ")\n",
      "device:  cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                                                         | 12/5000 [00:10<1:12:34,  1.15it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 5000/5000 [11:40<00:00,  7.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:      0 Iter:   5000, Train Loss:     1.6, Train Acc:  37.96%Val Acc:  18.91%, Time: 0:13:13*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5000/5000 [14:04<00:00,  5.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:      1 Iter:  10000, Train Loss:     1.6, Train Acc:  35.30%Val Acc:  25.57%, Time: 0:28:51*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5000/5000 [14:34<00:00,  5.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:      2 Iter:  15000, Train Loss:     1.6, Train Acc:  37.95%Val Acc:  26.45%, Time: 0:44:56*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5000/5000 [11:47<00:00,  7.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:      2 Iter:  20000, Train Loss:     1.6, Train Acc:  35.84%Val Acc:  23.49%, Time: 0:58:13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5000/5000 [12:06<00:00,  6.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:      3 Iter:  25000, Train Loss:     1.5, Train Acc:  43.23%Val Acc:  27.05%, Time: 1:11:52*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5000/5000 [14:10<00:00,  5.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:      4 Iter:  30000, Train Loss:     1.3, Train Acc:  49.82%Val Acc:  23.96%, Time: 1:27:33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5000/5000 [13:54<00:00,  5.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:      5 Iter:  35000, Train Loss:     1.2, Train Acc:  58.72%Val Acc:  23.76%, Time: 1:42:57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5000/5000 [10:52<00:00,  7.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:      5 Iter:  40000, Train Loss:     1.2, Train Acc:  57.34%Val Acc:  24.50%, Time: 1:55:19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5000/5000 [12:48<00:00,  6.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:      6 Iter:  45000, Train Loss:    0.95, Train Acc:  66.92%Val Acc:  26.04%, Time: 2:09:39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5000/5000 [14:12<00:00,  5.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:      7 Iter:  50000, Train Loss:    0.81, Train Acc:  73.10%Val Acc:  24.43%, Time: 2:25:22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5000/5000 [12:14<00:00,  6.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:      7 Iter:  55000, Train Loss:    0.85, Train Acc:  70.60%Val Acc:  24.50%, Time: 2:39:05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5000/5000 [11:25<00:00,  7.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:      8 Iter:  60000, Train Loss:    0.84, Train Acc:  70.63%Val Acc:  23.76%, Time: 2:52:01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5000/5000 [13:45<00:00,  6.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:      9 Iter:  65000, Train Loss:    0.66, Train Acc:  78.61%Val Acc:  24.43%, Time: 3:07:16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5000/5000 [13:57<00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:     10 Iter:  70000, Train Loss:     0.6, Train Acc:  80.71%Val Acc:  24.43%, Time: 3:22:39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5000/5000 [10:52<00:00,  7.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:     10 Iter:  75000, Train Loss:    0.76, Train Acc:  73.58%Val Acc:  24.56%, Time: 3:34:57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5000/5000 [11:43<00:00,  7.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:     11 Iter:  80000, Train Loss:    0.66, Train Acc:  77.76%Val Acc:  25.37%, Time: 3:48:07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5000/5000 [13:41<00:00,  6.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:     12 Iter:  85000, Train Loss:    0.53, Train Acc:  82.99%Val Acc:  22.41%, Time: 4:03:15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5000/5000 [13:07<00:00,  6.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:     13 Iter:  90000, Train Loss:    0.55, Train Acc:  81.77%Val Acc:  24.02%, Time: 4:17:50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5000/5000 [10:37<00:00,  7.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:     13 Iter:  95000, Train Loss:    0.66, Train Acc:  77.18%Val Acc:  25.10%, Time: 4:29:54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5000/5000 [12:35<00:00,  6.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:     14 Iter: 100000, Train Loss:    0.54, Train Acc:  81.86%Val Acc:  24.70%, Time: 4:43:55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5000/5000 [13:46<00:00,  6.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:     15 Iter: 105000, Train Loss:    0.47, Train Acc:  85.13%Val Acc:  21.67%, Time: 4:59:09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5000/5000 [11:39<00:00,  7.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:     15 Iter: 110000, Train Loss:    0.56, Train Acc:  81.14%Val Acc:  25.37%, Time: 5:12:14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5000/5000 [11:05<00:00,  7.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:     16 Iter: 115000, Train Loss:    0.58, Train Acc:  80.55%Val Acc:  24.23%, Time: 5:24:45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5000/5000 [13:29<00:00,  6.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:     17 Iter: 120000, Train Loss:    0.44, Train Acc:  86.24%Val Acc:  23.55%, Time: 5:39:42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5000/5000 [13:50<00:00,  6.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:     18 Iter: 125000, Train Loss:    0.42, Train Acc:  87.05%Val Acc:  25.17%, Time: 5:54:57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5000/5000 [10:38<00:00,  7.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:     18 Iter: 130000, Train Loss:    0.57, Train Acc:  80.80%Val Acc:  25.37%, Time: 6:07:02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5000/5000 [11:51<00:00,  7.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:     19 Iter: 135000, Train Loss:     0.5, Train Acc:  83.73%Val Acc:  24.56%, Time: 6:20:20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5000/5000 [13:41<00:00,  6.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:     20 Iter: 140000, Train Loss:     0.4, Train Acc:  87.49%Val Acc:  21.74%, Time: 6:35:28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5000/5000 [12:45<00:00,  6.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:     21 Iter: 145000, Train Loss:    0.44, Train Acc:  86.01%Val Acc:  24.97%, Time: 6:49:40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5000/5000 [10:40<00:00,  7.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:     21 Iter: 150000, Train Loss:    0.52, Train Acc:  82.21%Val Acc:  24.97%, Time: 7:01:47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5000/5000 [12:39<00:00,  6.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:     22 Iter: 155000, Train Loss:    0.42, Train Acc:  87.22%Val Acc:  24.97%, Time: 7:15:53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5000/5000 [13:48<00:00,  6.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:     23 Iter: 160000, Train Loss:    0.36, Train Acc:  89.03%Val Acc:  23.49%, Time: 7:31:07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5000/5000 [11:25<00:00,  7.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:     23 Iter: 165000, Train Loss:    0.47, Train Acc:  84.74%Val Acc:  26.18%, Time: 7:43:59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5000/5000 [11:04<00:00,  7.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:     24 Iter: 170000, Train Loss:    0.47, Train Acc:  84.26%Val Acc:  25.57%, Time: 7:56:29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5000/5000 [13:42<00:00,  6.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:     25 Iter: 175000, Train Loss:    0.36, Train Acc:  89.05%Val Acc:  24.56%, Time: 8:11:39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5000/5000 [13:51<00:00,  6.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:     26 Iter: 180000, Train Loss:    0.34, Train Acc:  89.59%Val Acc:  25.91%, Time: 8:26:54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5000/5000 [10:30<00:00,  7.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:     26 Iter: 185000, Train Loss:    0.48, Train Acc:  84.61%Val Acc:  26.18%, Time: 8:38:49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5000/5000 [11:55<00:00,  6.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:     27 Iter: 190000, Train Loss:    0.41, Train Acc:  86.92%Val Acc:  25.24%, Time: 8:52:11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5000/5000 [13:42<00:00,  6.08it/s]\n"
     ]
    }
   ],
   "source": [
    "training_1 = train(model,\n",
    "              ngram = ngram, \n",
    "              name = 'textGCN_initial_1',\n",
    "              bar = True,\n",
    "              drop_out=dropout, \n",
    "              train_data_helper=train_data_helper, \n",
    "              val_data_helper=val_data_helper,\n",
    "              device=device, \n",
    "              edges=edges\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2030e089",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, _, _, = next(train_data_helper.batch_iter(batch_size=batch_size, num_epoch=epochs))\n",
    "model.eval()\n",
    "_, h1 = model.forward(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ebb2df",
   "metadata": {},
   "source": [
    "<h1> Test </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "57834d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2026)\n"
     ]
    }
   ],
   "source": [
    "test_preds, test_labels = dev(model, test_data_helper, mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "69191741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GE    422\n",
       "SP    291\n",
       "CN    272\n",
       "RU    189\n",
       "JP    161\n",
       "AR    151\n",
       "Name: Target, dtype: int64"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_ts['Target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "5b97f553",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(test_preds, \n",
    "                      test_labels, \n",
    "                      idx_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "32f44db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = train_data_helper.batch_iter(2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "910c1bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = torch.load('textGCN_initial_1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "47abe44e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paulp/miniforge3/envs/pyto/lib/python3.9/site-packages/dgl/heterograph.py:72: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.\n",
      "  dgl_warning('Recommend creating graphs by `dgl.graph(data)`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2813)\n"
     ]
    }
   ],
   "source": [
    "b_test_preds, b_test_labels = dev(best_model, test_data_helper, mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "84ce5bc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(b_test_preds, \n",
    "                      b_test_labels, \n",
    "                      idx_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7766a1",
   "metadata": {},
   "source": [
    "Questions:\n",
    "\n",
    "Why isn't validation working?\n",
    "What is the relationship between Loss and train accuracty? Why don't these coincide?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2b9494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary?\n",
    "def edges_mapping(vocab_len, content, ngram):\n",
    "    count = 1\n",
    "    mapping = np.zeros(shape=(vocab_len, vocab_len), dtype=np.int32)\n",
    "    for doc in content:\n",
    "        for i, src in enumerate(doc):\n",
    "            for dst_id in range(max(0, i-ngram), min(len(doc), i+ngram+1)):\n",
    "                dst = doc[dst_id]\n",
    "\n",
    "                if mapping[src, dst] == 0:\n",
    "                    mapping[src, dst] = count\n",
    "                    count += 1\n",
    "\n",
    "    for word in range(vocab_len):\n",
    "        mapping[word, word] = count\n",
    "        count += 1\n",
    "\n",
    "    return count, mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e176ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_eval():\n",
    "    print('load model from file.')\n",
    "    data_helper = DataHelper('r8')\n",
    "    edges_num, edges_matrix = edges_mapping(len(data_helper.vocab), data_helper.content, 1)\n",
    "    model = torch.load(os.path.join('word_eval_1.pkl'))\n",
    "\n",
    "    edges_weights = model.seq_edge_w.weight.to('cpu').detach().numpy()\n",
    "\n",
    "    core_word = 'billion'\n",
    "    core_index = data_helper.vocab.index(core_word)\n",
    "\n",
    "    results = {}\n",
    "    for i in range(len(data_helper.vocab)):\n",
    "        word = data_helper.vocab[i]\n",
    "        n_word = edges_matrix[i, core_index]\n",
    "        # n_word = edges_matrix[i, i]\n",
    "        if n_word != 0:\n",
    "            results[word] = edges_weights[n_word][0]\n",
    "\n",
    "    sort_results = sorted(results.items(), key=lambda d: d[1])\n",
    "\n",
    "    print(sort_results)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyto_env",
   "language": "python",
   "name": "pyto"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
