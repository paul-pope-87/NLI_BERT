{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98dafdaf",
   "metadata": {},
   "source": [
    "<h1>Preprocessing and Exploratory Data Analysis</h1>\n",
    "\n",
    "With the ultimate goal of training a BERT text classifier to identify the nationality/L1  of non-native writers of English, the following project:\n",
    "\n",
    "1. Unifies and preprocesses data from multiple corpora \n",
    "2. Explores each corpus and L1 category quantitatively\n",
    "3. Examines limitations, design issues, and questions related to these findings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddef0320",
   "metadata": {},
   "source": [
    "<h1> Unifying Data from Multiple Corpora </h1>\n",
    "\n",
    "Corpora included:\n",
    "\n",
    "1. ICLE\n",
    "2. EFCAMDAT\n",
    "3. PELIC\n",
    "\n",
    "Access Pending for ETS Non-native, through LDC.\n",
    "\n",
    "The following code extracts samples from each corpus and unifies the labels and samples into a single dataset. Brief descriptions of each corpus are also provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83ac1145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script src=\"require.js\"></script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<script src=\"require.js\"></script>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd31fb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json \n",
    "\n",
    "#plotting\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly\n",
    "import plotly.io as pio\n",
    "pio.renderers.default='notebook'\n",
    "import kaleido\n",
    "\n",
    "#data handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "pd.set_option('display.max_rows', 150)\n",
    "pd.set_option('display.max_columns', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e41c3957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main directories\n",
    "project_dir = \"/Users/paulp/Library/CloudStorage/OneDrive-UniversityofEasternFinland/UEF/Thesis\"\n",
    "data_dir = os.path.join(project_dir, 'Data')\n",
    "\n",
    "# relative corpus directories\n",
    "ICLE_dir = os.path.join(data_dir, \"ICLE/split_texts\")\n",
    "EFCAMDAT_dir = os.path.join(data_dir, 'EFCAMDAT')\n",
    "PELIC = os.path.join(data_dir, 'PELIC/PELIC_compiled.csv')\n",
    "\n",
    "os.chdir(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4f3177",
   "metadata": {},
   "source": [
    "<h2> ICLE </h2>\n",
    "\n",
    "https://uclouvain.be/en/research-institutes/ilc/cecl/icle.html\n",
    "\n",
    "<h3> Description </h3>\n",
    "\n",
    "Version 2 of the International Corpus of Learner English from UC Louvain. Samples adhere closely to Atkins and Clear's (1992) corpus design criteria [ICLE]. Most samples in ICLE are argumentative essays collected from academic environments, representing a range of suggested topics as prompts.\n",
    "\n",
    "The data available to UEF users in V2 does not represent the full range of L1/nationalities of interest. It should also be noted that nationalities, not L1, stands in for the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef5a0e53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'GE': 281,\n",
       " 'CN': 757,\n",
       " 'JP': 365,\n",
       " 'SW': 255,\n",
       " 'PO': 350,\n",
       " 'FIN': 193,\n",
       " 'TR': 255,\n",
       " 'RU': 250,\n",
       " 'SP': 186}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = os.scandir(ICLE_dir)\n",
    "nationalities = {}\n",
    "for a in files:\n",
    "    b = re.split('-', a.name)[1]\n",
    "    if b not in nationalities.keys():\n",
    "        nationalities[b] = 1\n",
    "    else:\n",
    "        nationalities[b] += 1\n",
    "nationalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46b64619",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame(data = None, columns = ['Corpus','Target','Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4389061b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill dataframe with samples \n",
    "files = os.scandir(ICLE_dir)\n",
    "for b,a in enumerate(files):\n",
    "    target = re.split('-', a.name)[1]\n",
    "    c = open(a)\n",
    "    text = c.read()\n",
    "    dataset.loc[b,'Target'] = target\n",
    "    dataset.loc[b, 'Text'] = text\n",
    "    dataset.loc[b, 'Corpus'] = 'ICLE'\n",
    "    c.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbec5b1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1839"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove some L1s due to data sparsity \n",
    "dataset = dataset[dataset['Target'] != 'SW']\n",
    "dataset = dataset[dataset['Target'] != 'PO']\n",
    "dataset = dataset[dataset['Target'] != 'FIN']\n",
    "dataset = dataset[dataset['Target'] != 'TR']\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8917a20",
   "metadata": {},
   "source": [
    "<h2> EFCAMDAT </h2>\n",
    "\n",
    "https://philarion.mml.cam.ac.uk/\n",
    "\n",
    "<h3> Description </h3>\n",
    "\n",
    "This corpus is a collaboration between EF Education First and the Department of Theoretical and Applied Linguistics at the University of Cambridge. The samples were collected from English Live, EF's online language school. Samples are sortable by nationality, level, and other provided variables. As in ICLE, nationality is assumed to correlate with L1.\n",
    "\n",
    "<h3> Notes </h3>\n",
    "\n",
    "At first, levels 10-16 were selected for this project; based on the corpus documentation, this corresponds to B2+ CEFR levels [], which is harmonious with the ICLE corpus. However, after this initial exploration, it seemed that the levels were inflated, perhaps because they represent overall English competence rather than being distinctly reflective of writing skills. Ultimately, levels 12-16 were selected to filter out some of the lower quality samples. \n",
    "\n",
    "To address an under-representation of Spanish language data, Spanish was also sampled from a few Latin American countries. These varieties of Spanish may well impact the model's ability to pick up on 'general' characteristics of Spanish-influenced L2 English, but for now the increase in volume and balanced representation will be assumed a benefit rather than a drawback. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d98c43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the XML file from EFCAMDAT\n",
    "efcamdat = os.path.join(EFCAMDAT_dir, 'EF201403_selection1855.xml')\n",
    "with open(efcamdat) as fp:\n",
    "    soup = BeautifulSoup(fp, features='lxml-xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7840f446",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "efcamdat_ds = pd.DataFrame(data=None, columns = ['Corpus', 'Target', 'Text'])\n",
    "nationalities = {'cn':'CN', \n",
    "                 'de':'GE', \n",
    "                 'es':'SP',  \n",
    "                 'jp':'JP', \n",
    "                 'ru':'RU',\n",
    "                 'mx': 'SP',\n",
    "                 'ar':'SP',\n",
    "                 'co': 'SP',\n",
    "                 've':'SP',\n",
    "                 'kw':'AR',\n",
    "                 'om':'AR',\n",
    "                 'qa':'AR',\n",
    "                 'sa':'AR',\n",
    "                 'sy': 'AR'\n",
    "                }\n",
    "\n",
    "# Build the DataFrame\n",
    "for s in soup.find_all('writing'):\n",
    "    level = int(s.get('level'))\n",
    "    text = s.find_all('text')[0].text\n",
    "    #filter out lower level texts\n",
    "    if level >= 12:\n",
    "        nationality = s.find_all('learner')[0].get('nationality')\n",
    "        if nationality in nationalities:\n",
    "            d = pd.DataFrame(data = {'Corpus': ['EFCAM'], \n",
    "                                    'Target': [nationalities[nationality]],\n",
    "                                    'Text': [text]\n",
    "                                    }\n",
    "                            )\n",
    "            efcamdat_ds = pd.concat([efcamdat_ds, d])\n",
    "        else:\n",
    "            pass\n",
    "    else:\n",
    "        pass\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c9c5020",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([dataset, efcamdat_ds])\n",
    "dataset['Target'] = pd.Categorical(dataset['Target'])\n",
    "dataset['Corpus'] = pd.Categorical(dataset['Corpus'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6cf3d884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corpus</th>\n",
       "      <th>Target</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12063</td>\n",
       "      <td>12063</td>\n",
       "      <td>12063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>12005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>EFCAM</td>\n",
       "      <td>GE</td>\n",
       "      <td>\\n      You can learn how to be a good leader....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>10224</td>\n",
       "      <td>3889</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Corpus Target                                               Text\n",
       "count   12063  12063                                              12063\n",
       "unique      2      6                                              12005\n",
       "top     EFCAM     GE  \\n      You can learn how to be a good leader....\n",
       "freq    10224   3889                                                  6"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b60d47",
   "metadata": {},
   "source": [
    "<h2> PELIC </h2>\n",
    "\n",
    "https://eli-data-mining-group.github.io/Pitt-ELI-Corpus/\n",
    "\n",
    "<h3>Description</h3>\n",
    "\n",
    "PELIC contains writing samples from students in the University of Pittsburg English Language Institute, an intensive EAP program. \n",
    "\n",
    "<h3> Notes </h3>\n",
    "\n",
    "Because the data is longitudinal, only one writing sample per student was selected: this to prevent the model from identifying the characteristics of individual writers rather than the target group, although the number of samples per student is relatively small in relation to the corpus size. Levels 4-5, corresponding to B1+, were selected. This may later be narrowed to level 5 to better reflect the composition of the other corpora. \n",
    "\n",
    "In the case of PELIC, L1 (not nationality) is the variable label. Provided that the documentation of ICLE and EFCAMDAT are correct, it is reasonable to fuse nationality and L1 into a variable called 'Target' without significantly polluting the variable. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c91499bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pelic_ds = pd.read_csv(PELIC)\n",
    "\n",
    "pelic_nationality_map = {'Arabic':'AR', \n",
    "                         'Chinese':'CN', \n",
    "                         'Japanese':'JP', \n",
    "                         'Spanish':'SP',\n",
    "                         'Russian':'RU',\n",
    "                         'German':'GE'\n",
    "                        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbdaa857",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get one sample per learner\n",
    "reduced = pelic_ds.query('text_len > 170').groupby(\"anon_id\").sample(n=1, random_state=1)\n",
    "\n",
    "# Filter by level and L1\n",
    "reduced = reduced.filter(items=['level_id', 'L1', 'text'])\n",
    "reduced = reduced.query(\"level_id >= 4\")\n",
    "\n",
    "# get text and target, change target name\n",
    "reduced = reduced.filter(items=['L1', 'text'])\n",
    "reduced_pelic = reduced.apply(lambda row: row[reduced['L1'].isin(pelic_nationality_map.keys())])\n",
    "\n",
    "# add corpus label and rename columns\n",
    "reduced_pelic['Corpus'] = 'PELIC'\n",
    "reduced_pelic = reduced_pelic.rename(columns={'L1':'Target', 'text':'Text'})\n",
    "reduced_pelic['Target'] = reduced_pelic['Target'].apply(lambda row: pelic_nationality_map[row])\n",
    "\n",
    "#append to main data\n",
    "data = pd.concat([data, reduced_pelic])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cae01336",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EFCAM    10224\n",
       "ICLE      1839\n",
       "PELIC      553\n",
       "Name: Corpus, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Corpus'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63215f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this to save the data generated above\n",
    "data.to_csv('compiled_data_set.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f278655d",
   "metadata": {},
   "source": [
    "<h2> ETS Non-Native (TOEFL11) </h2>\n",
    "\n",
    "Compiled in association with the University of Pennsylvania with the task of native language identification (NLI) in mind, the 12,100 TOEFL essay responses in TOEFL11 address many shortcomings of ICLE: topical imbalances, character encodings, and other cues that make ICLE less suitable are controlled for. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d568d88",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Length'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcompiled_data_set.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLength\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/pyto/lib/python3.9/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/pyto/lib/python3.9/site-packages/pandas/core/frame.py:5388\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5240\u001b[0m \u001b[38;5;129m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, allowed_args\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m   5241\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[1;32m   5242\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5249\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   5250\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5251\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   5252\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   5253\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5386\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   5387\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5389\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5390\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5391\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5392\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5393\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5394\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5395\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5396\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/pyto/lib/python3.9/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/pyto/lib/python3.9/site-packages/pandas/core/generic.py:4505\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4503\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   4504\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 4505\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4507\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[1;32m   4508\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[0;32m~/miniforge3/envs/pyto/lib/python3.9/site-packages/pandas/core/generic.py:4546\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4544\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   4545\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4546\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4547\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[1;32m   4549\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   4550\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniforge3/envs/pyto/lib/python3.9/site-packages/pandas/core/indexes/base.py:6975\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6973\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m   6974\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 6975\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(labels[mask])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6976\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[1;32m   6977\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['Length'] not found in axis\""
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('compiled_data_set.csv', index_col=0).drop('Length', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4951a3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pd.read_csv(os.path.join(data_dir, 'ETS_Corpus_of_Non-Native_Written_English/data/text/index.csv'))\n",
    "ets_dir = os.path.join(data_dir, 'ETS_Corpus_of_Non-Native_Written_English/data/text/responses/original')\n",
    "index['Language'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f20f506",
   "metadata": {},
   "outputs": [],
   "source": [
    "language_ids = {'DEU':'GE',\n",
    "               'SPA':'SP',\n",
    "               'ARA':'AR',\n",
    "               'JPN':'JP',\n",
    "               'ZHO':'CN'} # no Russian )-:\n",
    "ids = language_ids.keys()\n",
    "\n",
    "index.rename(columns = {'Score Level':'Score_Level'}, inplace = True)\n",
    "index.query('Language in @ids', inplace = True)\n",
    "index.query(\"Score_Level in ('medium', 'high')\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa83068",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in index.iterrows():\n",
    "    j = i[1]\n",
    "    filename = j['Filename']\n",
    "    lang = j['Language']\n",
    "    corpus = 'TOEFL11'\n",
    "    with open(os.path.join(ets_dir, filename), 'r') as file:\n",
    "        text = file.read()\n",
    "    row = pd.DataFrame({'Corpus': [corpus],\n",
    "                       'Target': [language_ids[lang]],\n",
    "                       'Text': [text]})\n",
    "    data = pd.concat([data, row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6276b016",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.query('Corpus == \"TOEFL11\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c7d579",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('compiled_data_set.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662f38e5",
   "metadata": {},
   "source": [
    "<h1> Visualizing and Examining the Corpora </h1>\n",
    "\n",
    "Thus far, there are three corpora in the dataset with the number of samples noted above, but more detail about the nature and distribution of the samples is needed, along with insight as to how this may influence results and inform design. The code and visualizations below show:\n",
    "1. the number of samples in each corpus corresponding to each target group\n",
    "2. the distribution of sample lengths in tokens for each target in each subcorpus\n",
    "\n",
    "Note that the zoom feature can be used to isolate specific distributions in the visualizations for more clarity.\n",
    "\n",
    "Design-related questions are addressed both throughout and at the end of the section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8d31b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data from file if not generated above\n",
    "data = pd.read_csv('masked_data_set.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab887c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(data, \n",
    "             x='Target', \n",
    "             color='Corpus', \n",
    "             opacity=0.8, \n",
    "             title = 'Number of Texts by Nationality Group'\n",
    "            )\n",
    "\n",
    "fig.update_traces(dict(marker_line_width=0)) #run this line if the visualization looks cloudy\n",
    "fig.show(renderer='notebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c3ff70",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_image(os.path.join(data_dir, \"TARGET_COUNTS.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfeb3b95",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Calculate and Append text lengths using BERT tokenizer\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "spec_tokens = ['<?>', '<*>', '<R>'] #one of the corpora uses these\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', \n",
    "                                          additional_special_tokens = spec_tokens)\n",
    "data['Length'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386540c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the length of each sample in tokens and append to the main dataframe\n",
    "Length = [lambda x: len(tokenizer(x)['input_ids'])]\n",
    "data['Length'] = data['Text'].apply(func = Length, result_type='expand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af243b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = px.strip(data, \n",
    "                y=\"Length\", \n",
    "                x=\"Target\", \n",
    "                color=\"Corpus\", \n",
    "                hover_data=None,\n",
    "                title='Distribution of Text Lengths',\n",
    "               range_y = [0,2500]\n",
    "              )\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3449021",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_image(os.path.join(data_dir, \"TEXT_LENGTHS.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8447a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(data,\n",
    "             x='Length', \n",
    "             color = 'Corpus', \n",
    "             range_x = [0,1500],\n",
    "             opacity=1.0,\n",
    "             title= 'Distribution of Text Lengths Overall'\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b8cccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(data,\n",
    "             x='Length', \n",
    "             color = 'Target', \n",
    "             range_x = [0,1200],\n",
    "             opacity=1.0,\n",
    "             title= 'Distribution of Text Lengths Overall'\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b83078f",
   "metadata": {},
   "source": [
    "Notice the many tiny samples with length <= 50 in EFCAMDAT and PELIC. These are mostly non-informative entries that indicate the task was beyond the students' abilities or they did not have time to complete the task. These are filtered out at a threshold of 120 tokens to make the training samples more informative and training more efficient. \n",
    "\n",
    "This threshold was chosen to minimize the number of excluded samples while also making sure the samples are substantial and worth training on. More implications of sample length regarding BERT models will be mentioned later and discussed more fully in the next stage of the project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ce3fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trim below 120 tokens\n",
    "data = data.query('Length > 120')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac35ac80",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(data,\n",
    "             x='Length', \n",
    "             color = 'Corpus', \n",
    "             cumulative = True,\n",
    "             barmode = 'overlay',\n",
    "             histnorm = 'percent',\n",
    "             range_x = [120,1500],\n",
    "             opacity=0.4,\n",
    "             title = 'Cumulative Distribution of Text Lengths'\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8aff46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this to save the data generated above\n",
    "data.to_csv('compiled_data_set.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1826474",
   "metadata": {},
   "source": [
    "<h2> Findings, Impacts, and Decisions </h2>\n",
    "\n",
    "<h3> Target Representation </h3>\n",
    "\n",
    "There are some data imbalance issues, namely that Turkish is underrepresented. One option would be to find data from a separate Turkish learner corpus for inclusion. As can be seen above, however, corpora can vary greatly in composition, quality, and length of samples. Introducing a corpus that represents only one target group might have confounding impact.\n",
    "\n",
    "Another option is regularizing the model such that more prevalent target groups are not predicted arbitrarily: this approach 'punishes' the model for predicting German or Chinese or Arabic simply because they appear more frequently. \n",
    "\n",
    "A third option would be to drop Turkish from the data entirely. This would have the benefit of simplifying the classification problem, which is already quite complex, although it underscores a criticism of big data approaches to low-resource languages: although these are the languages in need of more research, they tend to be left out of data-heavy studies.  Although Turkish is not resource scarce, by comparison there is a lot less data at our disposal. \n",
    "\n",
    "<h3> Sample Lengths </h3>\n",
    "\n",
    "A principle design decision in BERT models is setting the maximum sample length in number of tokens. Although this can hypothetically be set as high or low as desired, it comes at performance costs. The standard medium-sized, pretrained BERT model has a max length of 512 tokens. If a training sample is shorter than the max length, mask tokens are passed to the model so it ignores the empty spaces at the end of the sample. If it is longer than the max length, it is truncated, and the end of the sample is lost. \n",
    "\n",
    "Doubling the max length incurs a computational cost of (at least) a power of 2, as attention weights have to be calculated for each pair of tokens. My machine can handle max_len = 1024, although a single training epoch takes about two hours. Max length of 256 trains faster, but clips quite a bit off of longer samples, leading to massive data loss. This decision will be explored in more detail at the next stage of the project. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428bee11",
   "metadata": {},
   "source": [
    "<h1> References </h1>\n",
    "\n",
    "Blanchard, Daniel, et al. ETS Corpus of Non-Native Written English LDC2014T06. Web Download. Philadelphia: Linguistic Data Consortium, 2014.\n",
    "\n",
    "The University of Pittsburgh English Language Institute Corpus (PELIC). (2022). PELIC. https://eli-data-mining-group.github.io/Pitt-ELI-Corpus/\n",
    "\n",
    "Huang, Y., Murakami, A., Alexopoulou, T., & Korhonen, A. (2018). Dependency parsing of learner English. International Journal of Corpus Linguistics, 23(1), 28-54.\n",
    "\n",
    "Geertzen, J. , Alexopoulou, T., & Korhonen, A. (2013). Automatic linguistic annotation of large scale L2 databases: The EF-Cambridge Open Language Database (EFCAMDAT). Selected Proceedings of the 31st Second Language Research Forum (SLRF), Cascadilla Press, MA.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyto_env",
   "language": "python",
   "name": "pyto"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
